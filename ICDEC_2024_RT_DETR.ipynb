{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhfxGlVx4xuj",
        "outputId": "55e47ee8-44a4-48b3-a606-10759b54b849"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base_path = '/content/drive/MyDrive/chumma1/new_repo/datasets_vehi'  # Change to your dataset path in Google Drive\n",
        "train_images_path = os.path.join(base_path, '/content/drive/MyDrive/chumma1/new_repo/datasets_vehi/Train/images')\n",
        "train_labels_path = os.path.join(base_path, '/content/drive/MyDrive/chumma1/new_repo/datasets_vehi/Train/labels')\n",
        "val_images_path = os.path.join(base_path, '/content/drive/MyDrive/chumma1/new_repo/datasets_vehi/val/images')\n",
        "val_labels_path = os.path.join(base_path, '/content/drive/MyDrive/chumma1/new_repo/datasets_vehi/val/labels')\n",
        "save_path = '/content/drive/MyDrive/chumma1/new_repo/yolov8_and_rt_detr_runs'  # Change to where you want to save the runs\n"
      ],
      "metadata": {
        "id": "fLVBdX7ttQTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics albumentations\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6p-TO4Jw1BK",
        "outputId": "3583c634-27a5-4d57-8d6c-6d3c53d48e7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.2.64-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m41.0/41.2 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m810.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.25.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.19.3)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.10.0.84)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations) (1.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (3.3)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2024.7.21)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (1.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.15.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Downloading ultralytics-8.2.64-py3-none-any.whl (824 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m824.8/824.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading ultralytics_thop-2.0.0-py3-none-any.whl (25 kB)\n",
            "Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 ultralytics-8.2.64 ultralytics-thop-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RT-DETR Model**"
      ],
      "metadata": {
        "id": "yTC1j8GC8_Gr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4LqIZQnTbnV",
        "outputId": "e60cf597-4371-45ce-a248-f350015c9f29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3h-4R_V8Tt0A",
        "outputId": "e55ab19f-6d6f-45ec-8a6c-35da960ad5ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.2.64-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.25.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Downloading ultralytics-8.2.64-py3-none-any.whl (824 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m824.8/824.8 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading ultralytics_thop-2.0.0-py3-none-any.whl (25 kB)\n",
            "Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 ultralytics-8.2.64 ultralytics-thop-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import RTDETR\n",
        "\n",
        "# Load a COCO-pretrained RT-DETR-l model\n",
        "model = RTDETR(\"rtdetr-l.pt\")\n",
        "\n",
        "# Display model information (optional)\n",
        "model.info()"
      ],
      "metadata": {
        "id": "HJFkZhXsLO5i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e695e55-c1bb-4ecd-bfd7-a152789c0d58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/rtdetr-l.pt to 'rtdetr-l.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63.4M/63.4M [00:00<00:00, 190MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rt-detr-l summary: 673 layers, 32,970,476 parameters, 0 gradients, 108.3 GFLOPs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(673, 32970476, 0, 108.3437056)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.train(data=\"/content/drive/MyDrive/chumma1/new_repo/data.yaml\", epochs=53, imgsz=640, project='/content/drive/MyDrive/chumma1/new_repo/yolov8_and_rt_detr_runs', name='rt-detr_runsnew1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmbN0i1sTcSy",
        "outputId": "56d5fbb1-6b32-4fbb-dcab-c552ceea28ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.2.64 🚀 Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=rtdetr-l.pt, data=/content/drive/MyDrive/chumma1/new_repo/data.yaml, epochs=80, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=/content/drive/MyDrive/chumma1/new_repo/yolov8_and_rt_detr_runs, name=rt-detr_runsnew1, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/drive/MyDrive/chumma1/new_repo/yolov8_and_rt_detr_runs/rt-detr_runsnew1\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 21.4MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overriding model.yaml nc=80 with nc=15\n",
            "WARNING ⚠️ no model scale passed. Assuming scale='l'.\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1     25248  ultralytics.nn.modules.block.HGStem          [3, 32, 48]                   \n",
            "  1                  -1  6    155072  ultralytics.nn.modules.block.HGBlock         [48, 48, 128, 3, 6]           \n",
            "  2                  -1  1      1408  ultralytics.nn.modules.conv.DWConv           [128, 128, 3, 2, 1, False]    \n",
            "  3                  -1  6    839296  ultralytics.nn.modules.block.HGBlock         [128, 96, 512, 3, 6]          \n",
            "  4                  -1  1      5632  ultralytics.nn.modules.conv.DWConv           [512, 512, 3, 2, 1, False]    \n",
            "  5                  -1  6   1695360  ultralytics.nn.modules.block.HGBlock         [512, 192, 1024, 5, 6, True, False]\n",
            "  6                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
            "  7                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
            "  8                  -1  1     11264  ultralytics.nn.modules.conv.DWConv           [1024, 1024, 3, 2, 1, False]  \n",
            "  9                  -1  6   6708480  ultralytics.nn.modules.block.HGBlock         [1024, 384, 2048, 5, 6, True, False]\n",
            " 10                  -1  1    524800  ultralytics.nn.modules.conv.Conv             [2048, 256, 1, 1, None, 1, 1, False]\n",
            " 11                  -1  1    789760  ultralytics.nn.modules.transformer.AIFI      [256, 1024, 8]                \n",
            " 12                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14                   7  1    262656  ultralytics.nn.modules.conv.Conv             [1024, 256, 1, 1, None, 1, 1, False]\n",
            " 15            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
            " 17                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
            " 18                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 19                   3  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1, None, 1, 1, False]\n",
            " 20            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
            " 22                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 23            [-1, 17]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 24                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
            " 25                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 26            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 27                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
            " 28        [21, 24, 27]  1   7332677  ultralytics.nn.modules.head.RTDETRDecoder    [15, [256, 256, 256]]         \n",
            "rt-detr-l summary: 673 layers, 32,836,901 parameters, 32,836,901 gradients, 108.1 GFLOPs\n",
            "\n",
            "Transferred 926/941 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/chumma1/new_repo/yolov8_and_rt_detr_runs/rt-detr_runsnew1', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6.25M/6.25M [00:00<00:00, 99.7MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1e2ePbmVjRNBB7ejUH7d4G6ptrTt4nPxV/chumma1/new_repo/datasets_vehi/Train/labels.cache... 2600 images, 2 backgrounds, 0 corrupt: 100%|██████████| 2600/2600 [00:00<?, ?it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/drive/.shortcut-targets-by-id/1e2ePbmVjRNBB7ejUH7d4G6ptrTt4nPxV/chumma1/new_repo/datasets_vehi/Train/images/rainy day (236).jpg: 1 duplicate labels removed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1e2ePbmVjRNBB7ejUH7d4G6ptrTt4nPxV/chumma1/new_repo/datasets_vehi/val/labels.cache... 200 images, 0 backgrounds, 0 corrupt: 100%|██████████| 200/200 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/chumma1/new_repo/yolov8_and_rt_detr_runs/rt-detr_runsnew1/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000526, momentum=0.9) with parameter groups 143 weight(decay=0.0), 206 weight(decay=0.0005), 226 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/chumma1/new_repo/yolov8_and_rt_detr_runs/rt-detr_runsnew1\u001b[0m\n",
            "Starting training for 80 epochs...\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       1/80      13.9G      1.177      3.843     0.4339         40        640: 100%|██████████| 163/163 [10:43<00:00,  3.95s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:08<00:00,  1.15s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        200       1199      0.724      0.148      0.144     0.0693\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       2/80      13.8G     0.7092     0.6509     0.1763         80        640: 100%|██████████| 163/163 [03:25<00:00,  1.26s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:05<00:00,  1.34it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        200       1199      0.577      0.365      0.364       0.19\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       3/80      13.9G      0.674      0.595     0.1659         56        640: 100%|██████████| 163/163 [03:22<00:00,  1.24s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:06<00:00,  1.15it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        200       1199      0.513      0.413      0.446      0.221\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       4/80        14G     0.6599     0.5675     0.1581         81        640: 100%|██████████| 163/163 [03:24<00:00,  1.25s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:06<00:00,  1.16it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        200       1199      0.764      0.424      0.462      0.233\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/80      13.1G     0.6497     0.5549     0.1567         90        640: 100%|██████████| 163/163 [03:23<00:00,  1.25s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:04<00:00,  1.45it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        200       1199      0.646      0.413      0.431       0.22\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/80      13.9G     0.6357     0.5503     0.1509         66        640: 100%|██████████| 163/163 [03:23<00:00,  1.25s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:04<00:00,  1.51it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        200       1199      0.658      0.376       0.39      0.214\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/80      13.9G     0.6334     0.5397     0.1493         72        640: 100%|██████████| 163/163 [03:22<00:00,  1.24s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:04<00:00,  1.50it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        200       1199      0.646      0.447      0.482      0.252\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/80      13.8G     0.6217     0.5281     0.1477         77        640: 100%|██████████| 163/163 [03:24<00:00,  1.25s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:05<00:00,  1.32it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        200       1199      0.688      0.403      0.458      0.248\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/80      13.8G     0.6154     0.5275     0.1427         81        640: 100%|██████████| 163/163 [03:20<00:00,  1.23s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:04<00:00,  1.42it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        200       1199      0.644      0.387      0.419      0.213\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/80        14G     0.6152     0.5123     0.1419         67        640: 100%|██████████| 163/163 [03:21<00:00,  1.24s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:06<00:00,  1.07it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        200       1199      0.652      0.463      0.498      0.261\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      11/80      13.9G     0.6042     0.5082     0.1387         64        640: 100%|██████████| 163/163 [03:22<00:00,  1.24s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:06<00:00,  1.06it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        200       1199      0.616      0.452       0.47      0.242\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      12/80      13.8G     0.6004     0.4966      0.135         41        640: 100%|██████████| 163/163 [03:21<00:00,  1.24s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:04<00:00,  1.52it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        200       1199      0.745      0.412      0.474      0.238\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      13/80      13.8G     0.5968     0.5006     0.1368         65        640: 100%|██████████| 163/163 [03:22<00:00,  1.24s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:04<00:00,  1.43it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        200       1199      0.669      0.365        0.4      0.196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      14/80        14G     0.5922     0.5044     0.1364         80        640: 100%|██████████| 163/163 [03:23<00:00,  1.25s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:04<00:00,  1.48it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        200       1199      0.712      0.397      0.456      0.236\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      15/80      13.2G     0.5891     0.4996     0.1368         98        640: 100%|██████████| 163/163 [03:23<00:00,  1.25s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:06<00:00,  1.16it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        200       1199      0.637      0.427      0.451      0.222\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      16/80      13.8G     0.5879     0.4974     0.1366        109        640: 100%|██████████| 163/163 [03:20<00:00,  1.23s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:06<00:00,  1.14it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        200       1199      0.589      0.438      0.475       0.24\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      17/80      13.7G       0.59     0.4894     0.1324         59        640: 100%|██████████| 163/163 [03:23<00:00,  1.25s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:06<00:00,  1.16it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        200       1199       0.73      0.407      0.472      0.241\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      18/80      13.3G     0.5913     0.4961     0.1298         83        640: 100%|██████████| 163/163 [03:23<00:00,  1.25s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:06<00:00,  1.11it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        200       1199      0.729      0.414       0.44      0.229\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      19/80      13.2G     0.5853     0.4958      0.137         36        640: 100%|██████████| 163/163 [03:21<00:00,  1.23s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:06<00:00,  1.06it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        200       1199      0.635      0.412      0.455      0.239\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      20/80      13.7G     0.5792     0.4887     0.1302         89        640: 100%|██████████| 163/163 [03:20<00:00,  1.23s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:06<00:00,  1.13it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        200       1199      0.662      0.432       0.48      0.253\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      21/80      13.3G     0.5702      0.487     0.1284         65        640: 100%|██████████| 163/163 [03:20<00:00,  1.23s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:06<00:00,  1.00it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        200       1199        0.7      0.425      0.474      0.259\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      22/80        14G     0.5706      0.482     0.1276         46        640: 100%|██████████| 163/163 [03:20<00:00,  1.23s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:06<00:00,  1.02it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        200       1199      0.808      0.467      0.532       0.28\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      23/80      13.7G     0.5658     0.4795     0.1272         81        640: 100%|██████████| 163/163 [03:20<00:00,  1.23s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:06<00:00,  1.02it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        200       1199      0.627      0.486      0.496      0.261\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      24/80      13.8G     0.5643     0.4778     0.1253        101        640: 100%|██████████| 163/163 [03:20<00:00,  1.23s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:06<00:00,  1.00it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        200       1199      0.585      0.495      0.514       0.28\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      25/80      13.9G     0.5598     0.4767     0.1259        107        640: 100%|██████████| 163/163 [03:21<00:00,  1.24s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:05<00:00,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.827      0.439      0.465      0.243\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      26/80      13.7G     0.5551     0.4722     0.1251         62        640: 100%|██████████| 163/163 [03:21<00:00,  1.23s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:06<00:00,  1.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.675      0.457      0.478      0.255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      27/80      13.8G     0.5517     0.4706      0.122         60        640: 100%|██████████| 163/163 [03:19<00:00,  1.23s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:04<00:00,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.721      0.468       0.48      0.258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      28/80      13.4G     0.5512     0.4728     0.1237         74        640: 100%|██████████| 163/163 [03:21<00:00,  1.23s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:04<00:00,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.691      0.459      0.477      0.264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      29/80      13.7G     0.5481     0.4704     0.1228         61        640: 100%|██████████| 163/163 [03:23<00:00,  1.25s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:04<00:00,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.675      0.465      0.479       0.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      30/80      13.8G     0.5482     0.4739     0.1227         45        640: 100%|██████████| 163/163 [03:22<00:00,  1.24s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:05<00:00,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.679      0.448      0.479      0.258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      31/80      13.8G     0.5452     0.4657     0.1217        105        640: 100%|██████████| 163/163 [03:19<00:00,  1.23s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:06<00:00,  1.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.732      0.474      0.502      0.263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      32/80      13.8G      0.542      0.464     0.1202        140        640: 100%|██████████| 163/163 [03:20<00:00,  1.23s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:06<00:00,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.707      0.453      0.483      0.251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      33/80      13.7G      0.531     0.4624     0.1197         50        640: 100%|██████████| 163/163 [03:21<00:00,  1.24s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:05<00:00,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.703      0.486      0.512       0.26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      34/80        14G     0.5372       0.46     0.1177         97        640: 100%|██████████| 163/163 [03:21<00:00,  1.24s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:04<00:00,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.756      0.453      0.493      0.261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      35/80      13.7G     0.5329     0.4597     0.1196         49        640: 100%|██████████| 163/163 [03:19<00:00,  1.22s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:04<00:00,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.712      0.471      0.505      0.262\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      36/80      13.4G     0.5318     0.4584     0.1145         46        640: 100%|██████████| 163/163 [03:22<00:00,  1.24s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:04<00:00,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.708       0.47      0.495      0.263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      37/80      13.3G     0.5291     0.4583     0.1143         58        640: 100%|██████████| 163/163 [03:21<00:00,  1.24s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:05<00:00,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.784      0.463      0.489      0.259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      38/80      13.8G     0.5303     0.4538     0.1159         71        640: 100%|██████████| 163/163 [03:23<00:00,  1.25s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:06<00:00,  1.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.778      0.485      0.506      0.264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      39/80      13.6G     0.5208     0.4523     0.1163        100        640: 100%|██████████| 163/163 [03:21<00:00,  1.24s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:06<00:00,  1.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.803      0.489      0.513      0.269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      40/80        14G     0.5275     0.4539     0.1146         30        640: 100%|██████████| 163/163 [03:23<00:00,  1.25s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:05<00:00,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.629      0.475      0.497      0.264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      41/80        14G     0.5263     0.4577     0.1118         65        640: 100%|██████████| 163/163 [03:22<00:00,  1.24s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:05<00:00,  1.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.635      0.483      0.495      0.258\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      42/80      13.3G     0.5235     0.4547      0.114        108        640: 100%|██████████| 163/163 [03:23<00:00,  1.25s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:04<00:00,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.671      0.498      0.516      0.268\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      43/80      13.8G     0.5196     0.4528     0.1137         99        640: 100%|██████████| 163/163 [03:21<00:00,  1.23s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:05<00:00,  1.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.656      0.461      0.485      0.255\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      44/80      13.9G     0.5182     0.4536     0.1128         72        640: 100%|██████████| 163/163 [03:23<00:00,  1.25s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:06<00:00,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.655      0.472      0.496      0.255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      45/80      13.2G     0.5174     0.4535     0.1109         85        640: 100%|██████████| 163/163 [03:22<00:00,  1.24s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:04<00:00,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199       0.78      0.488      0.508      0.274\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      46/80      13.8G     0.5103     0.4498     0.1121         58        640: 100%|██████████| 163/163 [03:22<00:00,  1.24s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:04<00:00,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.656       0.49      0.504      0.269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      47/80      13.7G     0.5082     0.4498     0.1099         74        640: 100%|██████████| 163/163 [03:25<00:00,  1.26s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:07<00:00,  1.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.791      0.483      0.512      0.274\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      48/80      13.3G     0.5133     0.4461     0.1091         60        640: 100%|██████████| 163/163 [03:30<00:00,  1.29s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:06<00:00,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199       0.69      0.487      0.502      0.258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      49/80      13.2G     0.5041     0.4456      0.108         55        640: 100%|██████████| 163/163 [03:23<00:00,  1.25s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:05<00:00,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.692      0.436      0.469      0.242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      50/80      13.8G     0.5052     0.4436     0.1086         54        640: 100%|██████████| 163/163 [03:21<00:00,  1.24s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:06<00:00,  1.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.663      0.487      0.508      0.274\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      51/80      13.7G        0.5     0.4447     0.1074         72        640: 100%|██████████| 163/163 [03:24<00:00,  1.25s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:05<00:00,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.694      0.472      0.488      0.257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      52/80      13.9G     0.4933     0.4378     0.1076         95        640: 100%|██████████| 163/163 [03:27<00:00,  1.27s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:05<00:00,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.778      0.482      0.524       0.27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/163 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      53/80      13.7G     0.5042     0.4435     0.1056        154        640:  48%|████▊     | 79/163 [01:40<01:38,  1.18s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import RTDETR\n",
        "\n",
        "# Load the trained model\n",
        "model = RTDETR(\"/content/drive/MyDrive/chumma1/new_repo/yolov8_and_rt_detr_runs/rt-detr_runsnew1/weights/best.pt\")\n",
        "\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "results = model.val(data=\"/content/drive/MyDrive/chumma1/new_repo/data.yaml\", imgsz=640)\n",
        "\n",
        "# Print evaluation results\n",
        "print(results)\n"
      ],
      "metadata": {
        "id": "G_HVHV2hUPid",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e098e753-ec4a-4324-b7a5-1fdd94588d03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.64 🚀 Python-3.10.12 torch-2.3.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "rt-detr-l summary: 498 layers, 32,014,565 parameters, 0 gradients, 103.5 GFLOPs\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 14.5MB/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1e2ePbmVjRNBB7ejUH7d4G6ptrTt4nPxV/chumma1/new_repo/datasets_vehi/val/labels.cache... 200 images, 0 backgrounds, 0 corrupt: 100%|██████████| 200/200 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [11:06<00:00, 51.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.791      0.473      0.533      0.277\n",
            "                   car        159        743      0.696      0.876       0.83      0.414\n",
            "                  bike         99        125      0.656       0.68      0.707      0.429\n",
            "                  auto         47         60      0.779       0.47      0.532      0.227\n",
            "                 cycle         29         46      0.445      0.087      0.107     0.0682\n",
            "                   bus         48         52      0.881      0.769      0.859       0.44\n",
            "             minitruck         54         58      0.709      0.379       0.37       0.18\n",
            "                 truck         32         47      0.868      0.532      0.603      0.316\n",
            "                   van         25         28          1          0          0          0\n",
            "                  taxi         10         10      0.881        0.9        0.9      0.582\n",
            "                  toto         28         30          1     0.0406      0.423      0.111\n",
            "Speed: 2.7ms preprocess, 3266.5ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n",
            "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
            "\n",
            "ap_class_index: array([ 0,  1,  2,  4,  5,  6,  7,  8,  9, 11])\n",
            "box: ultralytics.utils.metrics.Metric object\n",
            "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x797dbf0dca30>\n",
            "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
            "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,   0.0010441,  0.00052203,           0],\n",
            "       [          1,           1,           1, ...,  0.00013328,  6.6639e-05,           0],\n",
            "       [          1,           1,           1, ...,   0.0003465,  0.00017325,           0],\n",
            "       ...,\n",
            "       [          0,           0,           0, ...,           0,           0,           0],\n",
            "       [          1,           1,           1, ...,   0.0017325,  0.00086625,           0],\n",
            "       [          1,           1,           1, ...,     0.00154,     0.00077,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.049229,    0.049229,    0.049229, ...,           0,           0,           0],\n",
            "       [    0.01059,     0.01059,     0.01059, ...,           0,           0,           0],\n",
            "       [    0.12414,     0.12414,     0.12414, ...,           0,           0,           0],\n",
            "       ...,\n",
            "       [          0,           0,           0, ...,           0,           0,           0],\n",
            "       [    0.15789,     0.15789,     0.15789, ...,           0,           0,           0],\n",
            "       [    0.22222,     0.22222,     0.22222, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.025268,    0.025268,    0.025268, ...,           1,           1,           1],\n",
            "       [  0.0053258,   0.0053258,   0.0053258, ...,           1,           1,           1],\n",
            "       [   0.069231,    0.069231,    0.069231, ...,           1,           1,           1],\n",
            "       ...,\n",
            "       [          0,           0,           0, ...,           1,           1,           1],\n",
            "       [   0.086538,    0.086538,    0.086538, ...,           1,           1,           1],\n",
            "       [    0.66667,     0.66667,     0.66667, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.95155,     0.95155,     0.95155, ...,           0,           0,           0],\n",
            "       [       0.92,        0.92,        0.92, ...,           0,           0,           0],\n",
            "       [        0.6,         0.6,         0.6, ...,           0,           0,           0],\n",
            "       ...,\n",
            "       [          0,           0,           0, ...,           0,           0,           0],\n",
            "       [        0.9,         0.9,         0.9, ...,           0,           0,           0],\n",
            "       [    0.13333,     0.13333,     0.13333, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
            "fitness: 0.3024283796387376\n",
            "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
            "maps: array([     0.4142,     0.42877,     0.22722,      0.2768,    0.068239,     0.43974,     0.18038,     0.31606,           0,     0.58207,      0.2768,      0.1113,      0.2768,      0.2768,      0.2768])\n",
            "names: {0: 'car', 1: 'bike', 2: 'auto', 3: 'rickshaw', 4: 'cycle', 5: 'bus', 6: 'minitruck', 7: 'truck', 8: 'van', 9: 'taxi', 10: 'motorvan', 11: 'toto', 12: 'train', 13: 'boat', 14: 'cycle van'}\n",
            "plot: True\n",
            "results_dict: {'metrics/precision(B)': 0.7914353751893465, 'metrics/recall(B)': 0.47331337880435437, 'metrics/mAP50(B)': 0.5331136414496248, 'metrics/mAP50-95(B)': 0.27679668388197237, 'fitness': 0.3024283796387376}\n",
            "save_dir: PosixPath('runs/detect/val')\n",
            "speed: {'preprocess': 2.7092039585113525, 'inference': 3266.5273010730743, 'loss': 0.0002503395080566406, 'postprocess': 0.21796584129333496}\n",
            "task: 'detect'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the CSV file\n",
        "file_path = '/content/results.csv'\n",
        "results_df = pd.read_csv(file_path)\n",
        "\n",
        "# Extract relevant columns for plotting\n",
        "epochs = results_df['                  epoch']\n",
        "train_giou_loss = results_df['        train/giou_loss']\n",
        "train_cls_loss = results_df['         train/cls_loss']\n",
        "train_l1_loss = results_df['          train/l1_loss']\n",
        "val_giou_loss = results_df['          val/giou_loss']\n",
        "val_cls_loss = results_df['           val/cls_loss']\n",
        "val_l1_loss = results_df['            val/l1_loss']\n",
        "\n",
        "# Plot the losses against epochs\n",
        "plt.figure(figsize=(14, 8))\n",
        "\n",
        "plt.plot(epochs, train_giou_loss, label='Train GIoU Loss', marker='o')\n",
        "plt.plot(epochs, train_cls_loss, label='Train Classification Loss', marker='o')\n",
        "plt.plot(epochs, train_l1_loss, label='Train L1 Loss', marker='o')\n",
        "plt.plot(epochs, val_giou_loss, label='Validation GIoU Loss', marker='x')\n",
        "plt.plot(epochs, val_cls_loss, label='Validation Classification Loss', marker='x')\n",
        "plt.plot(epochs, val_l1_loss, label='Validation L1 Loss', marker='x')\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Losses vs Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EKrdYzWKBYJS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "outputId": "18cca6cf-ce9d-459c-fddd-48abbd3e4f54"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x800 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABIQAAAK9CAYAAABVd7dpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdeVyUVcPG8WvY18FdMBU33BX3EkutcMPILTUfSynNcsnKNPO1FDW13HLLsg3LMnPPUlM0zTWXDDNTc8fMpSxBVNa53z+IyRFQQBAZft/3Mx+Ye86cc+aG4/twdRaTYRiGAAAAAAAAUGg45HcHAAAAAAAAcGcRCAEAAAAAABQyBEIAAAAAAACFDIEQAAAAAABAIUMgBAAAAAAAUMgQCAEAAAAAABQyBEIAAAAAAACFDIEQAAAAAABAIUMgBAAAAAAAUMgQCAEAkEVhYWGqUKFCjt4bHh4uk8mUux26y5w8eVImk0nz5s27422bTCaFh4dbn8+bN08mk0knT5685XsrVKigsLCwXO3P7fyuANmR9ru+Z8+e/O4KAKCAIRACABR4JpMpS49Nmzbld1cLvcGDB8tkMuno0aOZlhk5cqRMJpN+/vnnO9iz7Pvjjz8UHh6uqKio/O6KVVooN2XKlPzuit1IC1wye/zwww/53UUAAHLEKb87AADA7Zo/f77N808//VSRkZHprteoUeO22vnggw9ksVhy9N7XXntNr7766m21bw969uypWbNmacGCBRo1alSGZb744gvVqVNHdevWzXE7Tz75pB5//HG5urrmuI5b+eOPPzRmzBhVqFBB9erVs3ntdn5XcHcaO3asKlasmO56lSpV8qE3AADcPgIhAECB98QTT9g8/+GHHxQZGZnu+o2uXr0qDw+PLLfj7Oyco/5JkpOTk5yc+H+79957r6pUqaIvvvgiw0Box44dOnHihN58883basfR0VGOjo63VcftuJ3fFdyd2rVrp0aNGuV3NwAAyDUsGQMAFAotW7ZU7dq19eOPP6p58+by8PDQ//3f/0mSvvrqK7Vv315lypSRq6urKleurHHjxiklJcWmjhv3hbl+ec7777+vypUry9XVVY0bN9bu3btt3pvRHkImk0mDBg3SihUrVLt2bbm6uqpWrVr69ttv0/V/06ZNatSokdzc3FS5cmXNnTs3y/sSbdmyRV27dlX58uXl6uqqcuXK6aWXXtK1a9fSfT4vLy+dOXNGHTt2lJeXl0qWLKmhQ4emuxeXLl1SWFiYfHx8VKRIEfXu3VuXLl26ZV+k1FlChw4d0t69e9O9tmDBAplMJvXo0UOJiYkaNWqUGjZsKB8fH3l6euqBBx7Qxo0bb9lGRnsIGYahN954Q2XLlpWHh4cefPBBHThwIN17//77bw0dOlR16tSRl5eXzGaz2rVrp3379lnLbNq0SY0bN5YkPfXUU9blQ2n7J2W0h9CVK1f08ssvq1y5cnJ1dVW1atU0ZcoUGYZhUy47vxc5deHCBfXp00elS5eWm5ubAgMD9cknn6Qrt3DhQjVs2FDe3t4ym82qU6eOZsyYYX09KSlJY8aMUUBAgNzc3FS8eHHdf//9ioyMtKnn0KFDeuyxx1SsWDG5ubmpUaNGWrlypU2ZrNZ1vT179shkMmXY97Vr18pkMumbb76RJF2+fFkvvviiKlSoIFdXV5UqVUqtWrXK8PcwJ67/9+Dtt9+Wv7+/3N3d1aJFC/3yyy/pyn/33Xd64IEH5OnpqSJFiqhDhw46ePBgunJnzpxRnz59rP8+VaxYUf3791diYqJNuYSEBA0ZMkQlS5aUp6enOnXqpD///NOmzJ49e9SmTRuVKFFC7u7uqlixop5++ulc+fwAgIKH/1QJACg0Ll68qHbt2unxxx/XE088odKlS0tKDQ+8vLw0ZMgQeXl56bvvvtOoUaMUGxuryZMn37LeBQsW6PLly3r22WdlMpk0adIkde7cWcePH7/lTJGtW7dq2bJlGjBggLy9vTVz5kx16dJF0dHRKl68uCTpp59+Utu2beXn56cxY8YoJSVFY8eOVcmSJbP0uRcvXqyrV6+qf//+Kl68uHbt2qVZs2bp999/1+LFi23KpqSkqE2bNrr33ns1ZcoUrV+/XlOnTlXlypXVv39/SanBSocOHbR161Y999xzqlGjhpYvX67evXtnqT89e/bUmDFjtGDBAjVo0MCm7UWLFumBBx5Q+fLl9ddff+nDDz9Ujx499Mwzz+jy5cv66KOP1KZNG+3atSvdMq1bGTVqlN544w2FhIQoJCREe/fuVevWrdP9YX38+HGtWLFCXbt2VcWKFXX+/HnNnTtXLVq00K+//qoyZcqoRo0aGjt2rEaNGqV+/frpgQcekCQFBQVl2LZhGHr00Ue1ceNG9enTR/Xq1dPatWs1bNgwnTlzRm+//bZN+az8XuTUtWvX1LJlSx09elSDBg1SxYoVtXjxYoWFhenSpUt64YUXJEmRkZHq0aOHHn74Yb311luSpIMHD2rbtm3WMuHh4Zo4caL69u2rJk2aKDY2Vnv27NHevXvVqlUrSdKBAwfUrFkz3XPPPXr11Vfl6empRYsWqWPHjlq6dKk6deqU5bpu1KhRI1WqVEmLFi1K9/v35ZdfqmjRomrTpo0k6bnnntOSJUs0aNAg1axZUxcvXtTWrVt18OBBm9/DzMTExOivv/6yuWYymdL9PD799FNdvnxZAwcOVHx8vGbMmKGHHnpI+/fvt/6bs379erVr106VKlVSeHi4rl27plmzZqlZs2bau3evNUz8448/1KRJE126dEn9+vVT9erVdebMGS1ZskRXr16Vi4uLtd3nn39eRYsW1ejRo3Xy5ElNnz5dgwYN0pdffikpNQRs3bq1SpYsqVdffVVFihTRyZMntWzZslt+dgCAnTIAALAzAwcONG78f3EtWrQwJBnvvfdeuvJXr15Nd+3ZZ581PDw8jPj4eOu13r17G/7+/tbnJ06cMCQZxYsXN/7++2/r9a+++sqQZHz99dfWa6NHj07XJ0mGi4uLcfToUeu1ffv2GZKMWbNmWa+FhoYaHh4expkzZ6zXjhw5Yjg5OaWrMyMZfb6JEycaJpPJOHXqlM3nk2SMHTvWpmz9+vWNhg0bWp+vWLHCkGRMmjTJei05Odl44IEHDElGRETELfvUuHFjo2zZskZKSor12rfffmtIMubOnWutMyEhweZ9//zzj1G6dGnj6aeftrkuyRg9erT1eUREhCHJOHHihGEYhnHhwgXDxcXFaN++vWGxWKzl/u///s+QZPTu3dt6LT4+3qZfhpH6s3Z1dbW5N7t378708974u5J2z9544w2bco899phhMplsfgey+nuRkbTfycmTJ2daZvr06YYk47PPPrNeS0xMNJo2bWp4eXkZsbGxhmEYxgsvvGCYzWYjOTk507oCAwON9u3b37RPDz/8sFGnTh2bsWSxWIygoCAjICAgW3VlZMSIEYazs7PNGExISDCKFCli83vi4+NjDBw4MNv1p/0uZfRwdXW1lku79+7u7sbvv/9uvb5z505DkvHSSy9Zr9WrV88oVaqUcfHiReu1ffv2GQ4ODkavXr2s13r16mU4ODgYu3fvTtevtN/jtP4FBwfb/G6/9NJLhqOjo3Hp0iXDMAxj+fLlhqQM6wIAFE4sGQMAFBqurq566qmn0l13d3e3fn/58mX99ddfeuCBB3T16lUdOnTolvV2795dRYsWtT5Pmy1y/PjxW743ODhYlStXtj6vW7euzGaz9b0pKSlav369OnbsqDJlyljLValSRe3atbtl/ZLt57ty5Yr++usvBQUFyTAM/fTTT+nKP/fcczbPH3jgAZvPsnr1ajk5OVlnDEmpe/Y8//zzWeqPlLrv0++//67Nmzdbry1YsEAuLi7q2rWrtc60GRAWi0V///23kpOT1ahRo2wv81m/fr0SExP1/PPP2yyze/HFF9OVdXV1lYND6v9ESklJ0cWLF+Xl5aVq1arleHnR6tWr5ejoqMGDB9tcf/nll2UYhtasWWNz/Va/F7dj9erV8vX1VY8ePazXnJ2dNXjwYMXFxen777+XJBUpUkRXrly56ZKtIkWK6MCBAzpy5EiGr//999/67rvv1K1bN+vY+uuvv3Tx4kW1adNGR44c0ZkzZ7JUV2a6d++upKQkm5ku69at06VLl9S9e3ebvu7cuVN//PFHtupP88477ygyMtLmcePPTZI6duyoe+65x/q8SZMmuvfee7V69WpJ0tmzZxUVFaWwsDAVK1bMWq5u3bpq1aqVtZzFYtGKFSsUGhqa4d5FNy4X7devn821Bx54QCkpKTp16pT180vSN998o6SkpBzdAwCAfSEQAgAUGvfcc4/NEos0Bw4cUKdOneTj4yOz2aySJUtaN6SOiYm5Zb3ly5e3eZ4WDv3zzz/Zfm/a+9Pee+HCBV27di3Dk4yyerpRdHS09Y/PtH2BWrRoISn953Nzc0u3FO36/kjSqVOn5OfnJy8vL5ty1apVy1J/JOnxxx+Xo6OjFixYIEmKj4/X8uXL1a5dO5tw7ZNPPlHdunWte8qULFlSq1atytLP5XppfxQHBATYXC9ZsqRNe1LqH+Jvv/22AgIC5OrqqhIlSqhkyZL6+eefs93u9e2XKVNG3t7eNtfTTr5L61+aW/1e3I5Tp04pICDAGnpl1pcBAwaoatWqateuncqWLaunn3463T5GY8eO1aVLl1S1alXVqVNHw4YN088//2x9/ejRozIMQ6+//rpKlixp8xg9erSk1N/xrNSVmcDAQFWvXt26NEpKXS5WokQJPfTQQ9ZrkyZN0i+//KJy5cqpSZMmCg8Pz1bA1qRJEwUHB9s8HnzwwXTlbvwdk6SqVata97NKu78ZjZcaNWror7/+0pUrV/Tnn38qNjZWtWvXzlL/bvXvUIsWLdSlSxeNGTNGJUqUUIcOHRQREaGEhIQs1Q8AsD8EQgCAQuP6mTJpLl26pBYtWmjfvn0aO3asvv76a0VGRlr3TMnK0eGZnWZl3LBZcG6/NytSUlLUqlUrrVq1SsOHD9eKFSsUGRlp3fz4xs93p07mStvQd+nSpUpKStLXX3+ty5cvq2fPntYyn332mcLCwlS5cmV99NFH+vbbbxUZGamHHnooT490nzBhgoYMGaLmzZvrs88+09q1axUZGalatWrdsaPk8/r3IitKlSqlqKgorVy50rr/Ubt27Wz26mnevLmOHTumjz/+WLVr19aHH36oBg0a6MMPP5T03+/X0KFD082uSXukBZu3qutmunfvro0bN+qvv/5SQkKCVq5cqS5dutic7NetWzcdP35cs2bNUpkyZTR58mTVqlUrw1k+BdGtfmdMJpOWLFmiHTt2aNCgQTpz5oyefvppNWzYUHFxcXeyqwCAuwSbSgMACrVNmzbp4sWLWrZsmZo3b269fuLEiXzs1X9KlSolNzc3HT16NN1rGV270f79+/Xbb7/pk08+Ua9evazXb7YM6Fb8/f21YcMGxcXF2cwSOnz4cLbq6dmzp7799lutWbNGCxYskNlsVmhoqPX1JUuWqFKlSlq2bJnNUpi0mSXZ7bMkHTlyRJUqVbJe//PPP9PNulmyZIkefPBBffTRRzbXL126pBIlSlifZ+WEt+vbX79+vS5fvmwzSyhtSWJa/+4Ef39//fzzz7JYLDazhDLqi4uLi0JDQxUaGiqLxaIBAwZo7ty5ev31161BTrFixfTUU0/pqaeeUlxcnJo3b67w8HD17dvXeq+dnZ0VHBx8y77drK6b6d69u8aMGaOlS5eqdOnSio2N1eOPP56unJ+fnwYMGKABAwbowoULatCggcaPH5/l5ZdZkdGSt99++826UXTa/c1ovBw6dEglSpSQp6en3N3dZTabMzyh7Hbcd999uu+++zR+/HgtWLBAPXv21MKFC295jwEA9ocZQgCAQi3tv6pfP/MiMTFRc+bMya8u2XB0dFRwcLBWrFhhs/fJ0aNHszSzIaPPZxiGzdHh2RUSEqLk5GS9++671mspKSmaNWtWturp2LGjPDw8NGfOHK1Zs0adO3eWm5vbTfu+c+dO7dixI9t9Dg4OlrOzs2bNmmVT3/Tp09OVdXR0TDcTZ/Hixda9btJ4enpKSg2KbiUkJEQpKSmaPXu2zfW3335bJpMpVwOJrPTl3LlzNkuskpOTNWvWLHl5eVmXE168eNHmfQ4ODqpbt64kWZcZ3VjGy8tLVapUsb5eqlQptWzZUnPnztXZs2fT9eX6Y9FvVdfN1KhRQ3Xq1NGXX36pL7/8Un5+fjYBb0pKSrrlfqVKlVKZMmVyfcnUihUrbH5Xdu3apZ07d1p/xn5+fqpXr54++eQTm9+dX375RevWrVNISIik1PvdsWNHff3119qzZ0+6drI7W+yff/5J9560k/pYNgYAhRMzhAAAhVpQUJCKFi2q3r17a/DgwTKZTJo/f/4dXZpzK+Hh4Vq3bp2aNWum/v37W4OF2rVrKyoq6qbvrV69uipXrqyhQ4fqzJkzMpvNWrp06W3tRRMaGqpmzZrp1Vdf1cmTJ1WzZk0tW7Ys2/vreHl5qWPHjtZ9hK5fLiZJjzzyiJYtW6ZOnTqpffv2OnHihN577z3VrFkz20tcSpYsqaFDh2rixIl65JFHFBISop9++klr1qyxmfWT1u7YsWP11FNPKSgoSPv379fnn39uM7NIkipXrqwiRYrovffek7e3tzw9PXXvvfeqYsWK6doPDQ3Vgw8+qJEjR+rkyZMKDAzUunXr9NVXX+nFF1+02UA6N2zYsEHx8fHprnfs2FH9+vXT3LlzFRYWph9//FEVKlTQkiVLtG3bNk2fPt06g6lv3776+++/9dBDD6ls2bI6deqUZs2apXr16ln3G6pZs6Zatmyphg0bqlixYtqzZ4/1aPc077zzju6//37VqVNHzzzzjCpVqqTz589rx44d+v3337Vv374s13Uz3bt316hRo+Tm5qY+ffrYzH66fPmyypYtq8cee0yBgYHy8vLS+vXrtXv3bk2dOjVL9a9ZsybDTeaDgoJsfjeqVKmi+++/X/3791dCQoKmT5+u4sWL65VXXrGWmTx5stq1a6emTZuqT58+1mPnfXx8FB4ebi03YcIErVu3Ti1atFC/fv1Uo0YNnT17VosXL9bWrVutG0VnxSeffKI5c+aoU6dOqly5si5fvqwPPvhAZrPZGkIBAAqZO3+wGQAAeSuzY+dr1aqVYflt27YZ9913n+Hu7m6UKVPGeOWVV4y1a9cakoyNGzday2V27HxGR3zrhmPQMzt2PqNjsP39/W2OQTcMw9iwYYNRv359w8XFxahcubLx4YcfGi+//LLh5uaWyV34z6+//moEBwcbXl5eRokSJYxnnnnGeoz59Uem9+7d2/D09Ez3/oz6fvHiRePJJ580zGaz4ePjYzz55JPGTz/9lOVj59OsWrXKkGT4+fmlO+rdYrEYEyZMMPz9/Q1XV1ejfv36xjfffJPu52AYtz523jAMIyUlxRgzZozh5+dnuLu7Gy1btjR++eWXdPc7Pj7eePnll63lmjVrZuzYscNo0aKF0aJFC5t2v/rqK6NmzZqGk5OTzWfPqI+XL182XnrpJaNMmTKGs7OzERAQYEyePNnmqPC0z5LV34sbpf1OZvaYP3++YRiGcf78eeOpp54ySpQoYbi4uBh16tRJ93NbsmSJ0bp1a6NUqVKGi4uLUb58eePZZ581zp49ay3zxhtvGE2aNDGKFCliuLu7G9WrVzfGjx9vJCYm2tR17Ngxo1evXoavr6/h7Oxs3HPPPcYjjzxiLFmyJNt1ZebIkSPWz7l161ab1xISEoxhw4YZgYGBhre3t+Hp6WkEBgYac+bMuWW9Nzt2/vqf+fX/HkydOtUoV66c4erqajzwwAPGvn370tW7fv16o1mzZoa7u7thNpuN0NBQ49dff01X7tSpU0avXr2MkiVLGq6urkalSpWMgQMHGgkJCTb9u/E4+Y0bN9r8G7Z3716jR48eRvny5Q1XV1ejVKlSxiOPPGLs2bMnK7cXAGCHTIZxF/0nUAAAkGUdO3bM0THdAHLfyZMnVbFiRU2ePFlDhw7N7+4AAHBL7CEEAEABcO3aNZvnR44c0erVq9WyZcv86RAAAAAKNPYQAgCgAKhUqZLCwsJUqVIlnTp1Su+++65cXFxs9iUBAAAAsopACACAAqBt27b64osvdO7cObm6uqpp06aaMGGCAgIC8rtrAAAAKIDYQwgAAAAAAKCQYQ8hAAAAAACAQoZACAAAAAAAoJApdHsIWSwW/fHHH/L29pbJZMrv7gAAAAAAAOQKwzB0+fJllSlTRg4Ot5gDZNwlJk6caEgyXnjhhZuWW7RokVGtWjXD1dXVqF27trFq1apstXP69GlDEg8ePHjw4MGDBw8ePHjw4MGDh10+Tp8+fct85K6YIbR7927NnTtXdevWvWm57du3q0ePHpo4caIeeeQRLViwQB07dtTevXtVu3btLLXl7e0tSTp9+rTMZvNt9z2rkpKStG7dOrVu3VrOzs53rF3gbsI4QGHHGEBhxxgAGAcAYyBvxcbGqly5ctbs42byPRCKi4tTz5499cEHH+iNN964adkZM2aobdu2GjZsmCRp3LhxioyM1OzZs/Xee+9lqb20ZWJms/mOB0IeHh4ym8380qPQYhygsGMMoLBjDACMA4AxcGdkZYucfA+EBg4cqPbt2ys4OPiWgdCOHTs0ZMgQm2tt2rTRihUrMn1PQkKCEhISrM9jY2Mlpf4SJiUl5bzj2ZTW1p1sE7jbMA5Q2DEGUNgxBgDGAcAYyFvZua/5GggtXLhQe/fu1e7du7NU/ty5cypdurTNtdKlS+vcuXOZvmfixIkaM2ZMuuvr1q2Th4dH9jqcCyIjI+94m8DdhnGAwo4xgMKOMQAwDgDGQN64evVqlsvmWyB0+vRpvfDCC4qMjJSbm1uetTNixAibWUVp6+lat259x5eMRUZGqlWrVkyLQ6HFOEBhxxhAYccYABgHAGMgb6WtisqKfAuEfvzxR124cEENGjSwXktJSdHmzZs1e/ZsJSQkyNHR0eY9vr6+On/+vM218+fPy9fXN9N2XF1d5erqmu66s7Nzvvzy5Ve7wN2EcYDCjjGAwo4xAOT9ODAMQ8nJyUpJScmzNoCcSElJkZOTk1JSUm59LDoy5OzsnC4vuf61rMq3QOjhhx/W/v37ba499dRTql69uoYPH57hh2vatKk2bNigF1980XotMjJSTZs2zevuAgAAAECBkJiYqLNnz2Zr6QhwpxiGIV9fX50+fTpLGx8jPZPJpLJly8rLy+u26sm3QMjb2zvdUfGenp4qXry49XqvXr10zz33aOLEiZKkF154QS1atNDUqVPVvn17LVy4UHv27NH7779/x/sPAAAAAHcbi8WiEydOyNHRUWXKlJGLiwt/dOOuYrFYFBcXJy8vL2YI5YBhGPrzzz/1+++/KyAgINOZQlmR76eM3Ux0dLTNL0hQUJAWLFig1157Tf/3f/+ngIAArVixIl2wBAAAAACFUWJioiwWi8qVK5cvh+gAt2KxWJSYmCg3NzcCoRwqWbKkTp48qaSkJPsJhDZt2nTT55LUtWtXde3a9c50CAAAAAAKIP7QBuxXbs36418JAAAAAACAQoZACAAAAAAAoJAhEAIAAAAApJNiMbTj2EV9FXVGO45dVIrFyO8uZVuFChU0ffr0/O4GcFciEAIAAAAA2Pj2l7O6/63v1OODH/TCwij1+OAH3f/Wd/r2l7N50p7JZLrpIzw8PEf17t69W/369bvt/h09elRPP/20ypcvL1dXV91zzz16+OGH9fnnnys5Odnmc6xYsSLL9YaFhaljx47prm/atEkmk0mXLl3K9L3ZbQu40V21qTQAAAAAIH99+8tZ9f9sr26cD3QuJl79P9urd59ooLa1/XK1zbNn/wuavvzyS40aNUqHDx+2XvPy8rJ+bxiGUlJS5OR06z9nS5Ysedt927Vrl4KDg1WrVi298847ql69uiRpz549euedd1S7dm0FBgbedjvAncYMIQAAAACwY4Zh6GpicpYel+OTNHrlgXRhkCTrtfCVv+pyfFKW6jOMrC0z8/X1tT58fHxkMpmszw8dOiRvb2+tWbNGDRs2lKurq7Zu3apjx46pQ4cOKl26tLy8vNS4cWOtX7/ept4bl4yZTCZ9+OGH6tSpkzw8PBQQEKCVK1fe9N6FhYWpatWq2rZtm0JDQxUQEKCAgAD16NFDW7duVd26dTN9//79+/XQQw/J3d1dxYsXV79+/RQXF5ele3I7LBaLxo4dq7Jly8rV1VX16tXTt99+a309MTFRgwYNkp+fn9zc3OTv76+JEydaP3N4eLh1NlSZMmU0ePDgPO8z7jxmCAEAAACAHbuWlKKao9bmSl2GpHOx8aoTvi5L5X8d20YeLrnzZ+err76qKVOmqFKlSipatKhOnz6tkJAQjR8/Xq6urvr0008VGhqqw4cPq3z58pnWM2bMGE2aNEmTJ0/WrFmz1LNnT506dUrFihVLVzYqKkoHDx7UF198IQeHjOdTZHYE+JUrV9SmTRs1bdpUu3fv1oULF9S3b18NGjRI8+bNy9E9yKoZM2Zo6tSpmjt3rurXr6+PP/5Yjz76qA4cOKCAgADNnDlTK1eu1KJFi1S+fHmdPn1ap0+fliQtXbpUb7/9thYuXKhatWrp3Llz2rdvX572F/mDGUIAAAAAgLve2LFj1apVK1WuXFnFihVTYGCgnn32WdWuXVsBAQEaN26cKleufNMZP1Lqvj09evRQlSpVNGHCBMXFxWnXrl0Zlv3tt98kSdWqVbNeu3Dhgry8vKyPOXPmZPjeBQsWKD4+Xp9++qlq166thx56SLNnz9b8+fN1/vz5HN6FrJkyZYqGDx+uxx9/XNWqVdNbb72levXqWWdLRUdHKyAgQPfff7/8/f11//33q0ePHtbXfH19FRwcrPLly6tJkyZ65pln8rS/yB/MEAIAAAAAO+bu7Khfx7bJUtldJ/5WWMTuW5ab91RjNamYfkZNRm3nlkaNGtk8j4uLU3h4uFatWqWzZ88qOTlZ165dU3R09E3ruX6Jl6enp8xmsy5cuJDlfhQvXlxRUVGSpJYtWyoxMTHDcgcPHlRgYKA8PT2t15o1ayaLxaLDhw+rdOnSWW4zO2JjY/XHH3+oWbNmNtebNWtmnekTFhamVq1aqVq1amrbtq0eeeQRtW7dWpLUtWtXTZ8+XZUqVVLbtm0VEhKi0NDQLO3ZhIKFGUIAAAAAYMdMJpM8XJyy9HggoKT8fNyU8SIoySTJz8dNDwSUzFJ9mS2nyonrgxVJGjp0qJYvX64JEyZoy5YtioqKUp06dTINaNI4OzvbfiaTSRaLJcOyAQEBkmSzwbWjo6OqVKmiKlWq3HZIYjabFRMTk+76pUuX5OjomO4z55YGDRroxIkTGjdunK5du6Zu3brpsccekySVK1dOhw8f1pw5c+Tu7q4BAwaoefPmSkpKypO+IP8QCAEAAAAAJEmODiaNDq0pSelCobTno0NrytEh94KenNq2bZvCwsLUqVMn1alTR76+vjp58mSutlG/fn1Vr15dU6ZMyTQ0ykyNGjW0b98+XblyxabPDg4O1iVo1apV04EDB5SQkGDz3r1796pixYrpwqusMJvNKlOmjLZt22Zzfdu2bapZs6ZNue7du+uDDz7Ql19+qaVLl+rvv/+WJLm7uys0NFQzZ87Upk2btGPHDu3fvz/bfcHdjTlfAAAAAACrtrX99O4TDTTm6191Nibeet3Xx02jQ2vm+pHzORUQEKBly5YpNDRUJpNJr7/+erZDm1sxmUyKiIhQq1at1KxZM40YMUI1atRQUlKSNm/erD///FOOjhkvi+vZs6dGjx6t3r17Kzw8XH/++aeef/55Pfnkk9blYj179tTYsWPVq1cvvfLKK/Lx8dHmzZs1ffp0TZo06Zb9O3HihHX5WpqAgAANGzZMo0ePVuXKlVWvXj1FREQoKipKn3/+uSRp2rRp8vPzU/369eXg4KDFixfL19dXRYoU0bx585SSkqJ7771XHh4e+uyzz+Tu7i5/f//bu5m46xAIFUSWFOnUdinuvORVWvIPkhxyb20uAAAAgMKtbW0/tarpq10n/taFy/Eq5e2mJhWL3RUzg9JMmzZNTz/9tIKCglSiRAkNHz5csbGxud7Offfdpx9//FETJkzQwIEDde7cOXl6eiowMFBvv/22nn766Qzf5+HhobVr1+qFF15Q48aN5eHhoS5dumjatGnWMkWKFNGWLVv06quv6tFHH1VMTIyqVKmiadOmqU+fPrfs25AhQ9Jd27JliwYPHqyYmBi9/PLLunDhgmrWrKmVK1dal8B5e3tr0qRJOnLkiBwdHdW4cWOtXr1aDg4OKlKkiN58800NGTJEKSkpqlOnjr7++msVL148h3cQdyuTYRhGfnfiToqNjZWPj49iYmJkNpvvWLtJSUlavXq1QkJCcjTtz+rXldK3w6XYP/67Zi4jtX1Lqvno7XcUyEO5Ng6AAooxgMKOMQDk/TiIj4/XiRMnVLFiRbm5ueV6/cDtslgsio2NldlsloMDu9jkxM3GeXYyD+5+QfLrSmlRL9swSJJiz6Ze//XmxysCAAAAAABIBEIFhyUldWaQMprQ9e+1b19NLQcAAAAAAHATBEIFxant6WcG2TCk2DOp5QAAAAAAAG6CQKigiDufu+UAAAAAAEChRSBUUHiVzt1yAAAAAACg0CIQKij8g1JPE1NmxzyaJPM9qeUAAAAAAABugkCooHBwTD1aPkP/hkRt30wtBwAAAAAAcBMEQgVJzUelbp9KHsVtr5vLpF6v+Wj+9AsAAAAAABQoTvndAWRTzUclz1JSRJvUYKjrJ6nLxJgZBAAAAAAAsogZQgWRm3fqV5ODVPEBwiAAAAAAuc+SIp3YIu1fkvrVkpLfPcq2ChUqaPr06XnezsmTJ2UymRQVFZXnbc2bN09FihSxufb++++rXLlycnBw0PTp0xUeHq569erleV/u1P1F3iAQKoic3VO/Jl3L334AAAAAsE+/rpSm15Y+eURa2if16/TaqdfzgMlkuukjPDw8R/Xu3r1b/fr1u+3+HT16VE899ZTKli0rV1dXVaxYUT169NCePXtuu+7s6t69u3777Tfr89jYWA0aNEjDhw/XmTNn1K9fPw0dOlQbNmzItTYzCqGk3Lu/N7Np0yaZTCZdunQpT9spjFgyVhA5e6R+TbwiGYZkyuzkMQAAAADIpl9XSot6STJsr8eeTb2eB/uXnj171vr9l19+qVGjRunw4cPWa15eXtbvDcNQSkqKnJxu/edsyZIlb7tve/bs0cMPP6zatWtr7ty5ql69ui5fvqyvvvpKL7/8sr7//vvbbiM73N3d5e7ubn0eHR2tpKQktW/fXn5+ftbr19+zvJIb9xf5hxlCBVFaICRDSk7I164AAAAAuMsZRup/TM7KIz5WWvOK0oVBqRWlfvl2eGq5rNRnZFRPer6+vtaHj4+PTCaT9fmhQ4fk7e2tNWvWqGHDhnJ1ddXWrVt17NgxdejQQaVLl5aXl5caN26s9evX29R745Imk8mkDz/8UJ06dZKHh4cCAgK0cmXms54Mw1BYWJgCAgK0ZcsWtW/fXpUrV1a9evU0evRoffXVVxm+LyUlRX369FHFihXl7u6uatWqacaMGTZlNm3apCZNmsjT01NFihRRs2bNdOrUKUnSvn379OCDD8rb21tms1kNGza0zka6frbOvHnzVKdOHUlSpUqVZDKZdPLkyQyXjH388ceqVauWXF1d5efnp0GDBllfmzZtmurUqSNPT0+VK1dOAwYMUFxcnLWfTz31lGJiYtLN2Lrx/kZHR6tDhw7y8vKS2WxWt27ddP78eevr4eHhatCggRYuXKhKlSrJx8dHjz/+uC5fvpzpz+BW/vnnH/Xq1UtFixaVh4eH2rVrpyNHjlhfP3XqlEJDQ1W0aFF5enqqVq1aWr16tfW9PXv2VMmSJeXu7q6AgABFRETkuC8FDTOECiJrICQp6ark7JZ/fQEAAABwd0u6Kk0ok0uVGVLsH9Kb5bJW/P/+kFw8c6XlV199VVOmTFGlSpVUtGhRnT59WiEhIRo/frxcXV316aefKjQ0VIcPH1b58uUzrWfMmDGaNGmSJk+erFmzZqlnz546deqUihUrlq5sVFSUDhw4oAULFsjBIf18ioyWUUmSxWJR2bJltXjxYhUvXlzbt29Xv3795Ofnp27duik5OVkdO3bUM888oy+++EKJiYnatWuXTP+u/ujZs6fq16+vd999V46OjoqKipKzs3O6drp3765y5copODhYu3btUrly5TKctfPuu+9qyJAhevPNN9WuXTvFxMRo27Zt1tcdHBw0c+ZMVaxYUcePH9eAAQP0yiuvaM6cOQoKCtL06dNtZm1lNPvIYrFYw6Dvv/9eycnJGjhwoLp3765NmzZZyx07dkyrV6/WypUrFRMTo27duunNN9/U+PHjM7yXtxIWFqYjR45o5cqVMpvNGj58uEJCQvTrr7/K2dlZAwcOVGJiojZv3ixPT0/9+uuv1v6//vrr+vXXX7VmzRqVKFFCR48e1bVrhWdrFgKhgsjRSXJ0kVISU/9xV/p/uAAAAADAnowdO1atWrWyPi9WrJgCAwOtz8eNG6fly5dr5cqVNrNfbhQWFqYePXpIkiZMmKCZM2dq165datu2bbqyaTNNqlevnq2+Ojs7a8yYMdbnFStW1I4dO7Ro0SJ169ZNsbGxiomJ0SOPPKLKlStLkmrUqGEtHx0drWHDhlnbDQgIyLAdd3d3FS9eXFLq8i1fX98My73xxht6+eWX9cILL1ivNW7c2Pr9iy++aP2+QoUKeuONN/Tcc89pzpw5cnFxsZm1lZkNGzZo//79OnHihMqVSw0MP/30U9WqVUu7d++2tmexWPTOO+/onnvukYODg5588klt2LAhR4FQWhC0bds2BQUFSZI+//xzlStXTitWrFDXrl0VHR2tLl262MykShMdHa369eurUaNG1s9emBAIFVTO7v8GQoUnvQQAAACQA84eqTN1suLUdunzx25drucSyT8oa23nkrQ/2tPExcUpPDxcq1at0tmzZ5WcnKxr164pOjr6pvXUrVvX+r2np6fMZrMuXLiQYVkji0veMvLOO+/o448/VnR0tK5du6bExETrMq5ixYopLCxMbdq0UatWrRQcHKxu3bpZ9wAaMmSI+vbtq/nz5ys4OFhdu3a1BkfZdeHCBf3xxx96+OGHMy2zfv16TZw4UYcOHVJsbKySk5MVHx+vq1evysMjaz/DgwcPqly5ctYwSJJq1qypIkWK6ODBg9ZAqEKFCvL29raW8fPzy/T+Z6VNJycn3XvvvdZrxYsXV7Vq1XTw4EFJ0uDBg9W/f3+tW7dOwcHB6tKli/V3oH///urSpYv27t2r1q1bq2PHjtZgqTBgD6GCKu0f1qSr+dsPAAAAAHc3kyl12VZWHpUfksxlJGV2cI1JMt+TWi4r9eXiATienrZLz4YOHarly5drwoQJ2rJli6KiolSnTh0lJibetJ4bl16ZTCZZLJYMy1atWlWSdOjQoWz1deHChRo6dKj69OmjdevWKSoqSk899ZRN3yIiIrRjxw4FBQXpyy+/VNWqVfXDDz9ISt1r58CBA2rfvr2+++471axZU8uXL89WH9JcvwF1Rk6ePKlHHnlEdevW1dKlS/Xjjz/qnXfekaRb3sucyM79zw19+/bV8ePH9eSTT2r//v1q1KiRZs2aJUlq166dTp06pZdeeskamg0dOjTP+nK3IRAqqKwnjREIAQAAAMglDo5S27f+fXJjmPPv87ZvppbLZ9u2bVNYWJg6deqkOnXqyNfXVydPnszVNurVq6eaNWtq6tSpGYYWmR2FnraEacCAAapfv76qVKmiY8eOpStXv359jRgxQtu3b1ft2rW1YMEC62tVq1bVSy+9pHXr1qlz58453uzY29tbFSpUyPQY+h9//FEWi0VTp07Vfffdp6pVq+qPP2xnlLm4uCglJeWm7dSoUUOnT5/W6dOnrdd+/fVXXbp0STVr1sxR32+lRo0aSk5O1s6dO63XLl68qMOHD9u0Wa5cOT333HNatmyZXn75ZX3wwQfW10qWLKnevXvrs88+0/Tp0/X+++/nSV/vRgRCBRUzhAAAAADkhZqPph4tb/azvW4ukydHzudUQECAli1bpqioKO3bt0//+9//cn2miclkUkREhH777Tc98MADWr16tY4fP66ff/5Z48ePV4cOHTLt2549e7R27Vr99ttvev3117V7927r6ydOnNCIESO0Y8cOnTp1SuvWrdORI0dUo0YNXbt2TYMGDdKmTZt06tQpbdu2Tbt377bZYyi7wsPDNXXqVM2cOVNHjhzR3r17rbNkqlSpoqSkJM2aNUvHjx/X/Pnz9d5779m8v0KFCoqLi9OGDRv0119/6erV9H+HBgcHq06dOurZs6f27t2rXbt2qVevXmrRokW65X45sX//fkVFRVkf+/btU0BAgDp06KBnnnlGW7du1b59+/TEE0/onnvusf5sXnzxRa1du1YnTpzQ3r17tXHjRuu9HDVqlL766isdPXpUBw4c0DfffHNb97mgYQ+hgsr532l/7CEEAAAAILfVfFSq3j51T6G485JX6dQ9g+6CmUFppk2bpqefflpBQUEqUaKEhg8frtjY2Fxvp0mTJtqzZ4/Gjx+vZ555Rn/99Zf8/Pysp29l5Nlnn9VPP/2k7t27y2QyqUePHhowYIDWrFkjSfLw8NChQ4f0ySef6OLFi/Lz89PAgQP17LPPKjk5WRcvXlSvXr10/vx5lShRQp07d7bZpDq7evfurfj4eL399tsaOnSoSpQoocceS90rKjAwUNOmTdNbb72lESNGqHnz5po4caJ69eplfX9QUJCee+45de/eXRcvXtTo0aOtR8+nMZlM+uqrr/T888+refPmcnBwUNu2ba3B0+1q3ry5zXNHR0clJycrIiJCL7zwgh555BElJiaqefPmWr16tXVpWkpKigYOHKjff/9dZrNZbdu21dtvvy0pdebTiBEjdPLkSbm7u+uBBx7QwoULc6W/BYHJuJ1dsgqg2NhY+fj4KCYmRmaz+Y61m5SUpNWrVyskJCTD4wKz7dMO0vFNUucPpLrdbr8+4A7I9XEAFDCMARR2jAEg78dBfHy8Tpw4oYoVK8rNzS3X6wdul8ViUWxsrMxmsxwcWLSUEzcb59nJPLj7BRVLxgAAAAAAQA4RCBVULBkDAAAAAAA5RCBUUFlPGbuSv/0AAAAAAAAFDoFQQWVdMsYMIQAAAAAAkD0EQgWVdckYewgBAAAAAIDsIRAqqFw8U78SCAEAAAAAgGwiECqo2FQaAAAAAADkEIFQQZUWCLGpNAAAAAAAyCYCoYLKOW3JGDOEAAAAAABA9hAIFVQsGQMAAACQh1IsKdp9brdWH1+t3ed2K8WSkt9dyrYKFSpo+vTp+d0N4K7klN8dQA5Zj51nyRgAAACA3LX+1Hq9uetNnb963nqttEdpvdrkVQX7B+d6eyaT6aavjx49WuHh4dmud/fu3fL09Mxhr1K1bNlS9erVyzRYGj9+vFatWqWoqCi5uLjo0qVLt10ncCcwQ6igckkLhJghBAAAACD3rD+1XkM2DbEJgyTpwtULGrJpiNafWp/rbZ49e9b6mD59usxms821oUOHWssahqHk5OQs1VuyZEl5eHjken+vl5iYqK5du6p///552g6Q2wiECiqWjAEAAADIAsMwdDXpapYelxMua+KuiTJkpK/n3/97c9ebupxwOUv1GUb6ejLi6+trffj4+MhkMlmfHzp0SN7e3lqzZo0aNmwoV1dXbd26VceOHVOHDh1UunRpeXl5qXHjxlq/3jasunHJmMlk0ocffqhOnTrJw8NDAQEBWrly5W3d3zFjxuill15SnTp1bque6y1dulS1atWSq6urKlSooKlTp9q8PmfOHAUEBMjNzU2lS5fWY489Zn1tyZIlqlOnjtzd3VW8eHEFBwfryhVWliA9lowVVGlLxjhlDAAAAMBNXEu+pnsX3Jtr9Z2/el5BC4OyVHbn/3bKwzl3Zui8+uqrmjJliipVqqSiRYvq9OnTCgkJ0fjx4+Xq6qpPP/1UoaGhOnz4sMqXL59pPWPGjNGkSZM0efJkzZo1Sz179tSpU6dUrFixXOnn7frxxx/VrVs3hYeHq3v37tq+fbsGDBig4sWLKywsTHv27NHgwYM1f/58BQUF6e+//9aWLVskpc606tGjhyZNmqROnTrp8uXL2rJlS5aDORQuBEIFlTNLxgAAAAAUHmPHjlWrVq2sz4sVK6bAwEDr83Hjxmn58uVauXKlBg0alGk9YWFh6tGjhyRpwoQJmjlzpnbt2qW2bdvmXeezYdq0aXr44Yf1+uuvS5KqVq2qX3/9VZMnT1ZYWJiio6Pl6empRx55RN7e3vL391f9+vUlpQZCycnJ6ty5s/z9/SUpV2cuwb4QCBVUaYFQ8jXJYpEcWP0HAAAAID13J3ft/N/OLJX98fyPGrBhwC3LzXl4jhqWbpiltnNLo0aNbJ7HxcUpPDxcq1atsgYh165dU3R09E3rqVu3rvV7T09Pmc1mXbhwIdf6ebsOHjyoDh062Fxr1qyZpk+frpSUFLVq1Ur+/v6qVKmS2rZtq7Zt21qXwAUGBurhhx9WnTp11KZNG7Vu3VqPPfaYihYtmk+fBnczUoSCyvm6f1iTmSUEAAAAIGMmk0kezh5ZegSVCVJpj9IyKeNTv0wyydfDV0FlgrJU361OD8uOG08LGzp0qJYvX64JEyZoy5YtioqKUp06dZSYmHjTepydnW0/k8kki8WSa/3Ma97e3tq7d6+++OIL+fn5adSoUQoMDNSlS5fk6OioyMhIrVmzRjVr1tSsWbNUrVo1nThxIr+7jbsQgVBBdf06XJaNAQAAAMgFjg6OerXJq5KULhRKez68yXA5Ojje8b7daNu2bQoLC1OnTp1Up04d+fr66uTJk/ndrdtWo0YNbdu2zebatm3bVLVqVTk6pt53JycnBQcHa9KkSfr555918uRJfffdd5JSA65mzZppzJgx+umnn+Ti4qLly5ff8c+Bux9LxgoqBwfJyU1KjpeSruZ3bwAAAADYiWD/YE1rOU1v7nrT5uj50h6lNbzJcAX7B+dj7/4TEBCgZcuWKTQ0VCaTSa+//nqezfT5888/FRUVZXPNz89PpUuXVnR0tP7++29FR0crJSXFWq5KlSry8vLKdp0vv/yyGjdurHHjxql79+7asWOHZs+erTlz5kiSvvnmGx0/flzNmzdX0aJFtXr1alksFlWrVk07d+7Uhg0b1Lp1a5UqVUo7d+7Un3/+qRo1auTm7YCdIBAqyJw9UgOhRAIhAAAAALkn2D9YD5Z7UHsv7NWfV/9USY+SalCqwV0xMyjNtGnT9PTTTysoKEglSpTQ8OHDFRsbmydtLViwQAsWLLC5Nm7cOL322msaNWqUPvnkE+v1tA2eN27cqJYtW+aozkWLFmnUqFEaN26c/Pz8NHbsWIWFhUmSihQpomXLlik8PFzx8fEKCAjQF198oVq1aungwYPavHmzpk+frtjYWPn7+2vq1Klq165d7twI2BWTUcjOn4uNjZWPj49iYmJkNpvvWLtJSUlavXq1QkJC0q1ZzbFptaTY36VnNkr3NMidOoE8lCfjAChAGAMo7BgDQN6Pg/j4eJ04cUIVK1aUm5tbrtcP3C6LxaLY2FiZzWY5cDhSjtxsnGcn8+DuF2RpG0uzhxAAAAAAAMgGAqGCzOXfjaXZQwgAAAAAAGQDgVBB5kwgBAAAAAAAso9AqCBjyRgAAAAAAMgBAqGCLG2GUOKV/O0HAAAAAAAoUAiECjLrkjFmCAEAAAAAgKwjECrIWDIGAAAAAABygECoIHPxTP2axJIxAAAAAACQdfkaCL377ruqW7euzGazzGazmjZtqjVr1mRaft68eTKZTDYPNze3O9jjuwwzhAAAAAAAQA7kayBUtmxZvfnmm/rxxx+1Z88ePfTQQ+rQoYMOHDiQ6XvMZrPOnj1rfZw6deoO9vgukxYIsak0AAAAAKhly5Z68cUXrc8rVKig6dOn3/Q9JpNJK1asuO22c6se4E7J10AoNDRUISEhCggIUNWqVTV+/Hh5eXnphx9+yPQ9JpNJvr6+1kfp0qXvYI/vMs5pS8aYIQQAAAAgd/w5a7b+nDMn49fmzNGfs2bnepuhoaFq27Zthq9t2bJFJpNJP//8c7br3b17t/r163e73bMRHh6uevXqpbt+9uxZtWvXLlfbykhiYqImT56sBg0ayNPTUz4+PgoMDNRrr72mP/74w1ouLCxMHTt2zHK9mzZtkslk0qVLl9K9dqtgLbtt4e7glN8dSJOSkqLFixfrypUratq0aabl4uLi5O/vL4vFogYNGmjChAmqVatWpuUTEhKUkJBgfR4bGytJSkpKUlJSUu59gFtIays32zQ5uMhJkiXxilLu4GcBciovxgFQkDAGUNgxBoC8HwdJSUkyDEMWi0UWiyVHdRgOJl2cOUuGYahE//7W63+9+64uzpqt4s8PynHdmXnqqafUtWtXRUdHq2zZsjavffzxx2rUqJFq166dpXbTPr8kFS9eXJJu+b7s3C/DMDKss1SpUllq63YkJCSobdu2+vnnnxUeHq6goCCVLFlSJ06c0MKFCzVz5kxNmDDB2s/r78WtpJXL7F7crK7stJV2/7LTN9iyWCwyDENJSUlydHS0eS07/7bkeyC0f/9+NW3aVPHx8fLy8tLy5ctVs2bNDMtWq1ZNH3/8serWrauYmBhNmTJFQUFBOnDgQLp/NNJMnDhRY8aMSXd93bp18vDwyNXPkhWRkZG5VlfZv39TQ0l/nY3WjtWrc61eIK/l5jgACiLGAAo7xgCQd+PAyclJvr6+iouLU2JioqR//1iPj896HZ07yzPuii7Omq34uCvy6vWk4j6drysREfJ86ik5de6sS+fPZ6kuk5ubTCbTLcs1b95cJUqU0Pvvv6+hQ4dar8fFxWnJkiUaM2aMTp48qWHDhmnHjh26dOmSKlSooCFDhuixxx6zlk9OTlZiYqJ1IkDdunXVv39/9f832Dp27Jief/557d27VxUqVNDEiRMlSdeuXbO+Z/To0Vq1apX++OMPlSpVSl27dtUrr7wiZ2dnLViwQGPHjpUk6x/i77zzjv73v/+paNGi+uyzz9S+fXtJ0oEDBzRixAjt3r1b7u7uevTRR/XGG2/Iy8tLkjRgwADFxMTovvvu0zvvvKPExER17txZEydOlLOzc4b36e2339bWrVu1ceNG1a1b13q9fv36ql+/vgzDsJkEkZycbH2ekJCgUaNGadmyZbp8+bLq1aunCRMmqEGDBpKkq1evSpIuX74sBwfbxUQWi0Xx8fHWum50Y1s32rZtm0aNGqVffvlFRYsW1eOPP67XXntNTk6pkcRXX32lt956SydOnJC7u7vq1q2rzz//XJ6entq6datGjx6tQ4cOycnJSdWrV9cHH3yg8uXLZ9hWYZCYmKhr165p8+bNSk5Otnkt7eeYFfkeCFWrVk1RUVGKiYnRkiVL1Lt3b33//fcZhkJNmza1mT0UFBSkGjVqaO7cuRo3blyG9Y8YMUJDhgyxPo+NjVW5cuXUunVrmc3m3P9AmUhKSlJkZKRatWqV6eDOLtMhQzo1VyV8PBUSEpIrdQJ5KS/GAVCQMAZQ2DEGgLwfB/Hx8Tp9+rS8vLysB/BYrl7VkaZBOarvSkSErkREZPr8VgL27JZDFv9DfK9evbRw4UKNGTPGGiItXbpUKSkpeuqppxQXF6f77rtPI0eOlNls1urVq/Xcc8+pdu3aatKkiaTUQMzFxcX6t56Dg4Pc3NxkNptlsVgUFham0qVLa8eOHYqJibH+reju7m59T4kSJTRv3jyVKVNG+/fv17PPPqsSJUpo2LBh6t27t44dO6a1a9dq3bp1kiQfHx+5u7vb1HPlyhV17dpV9913n3bu3KkLFy6oX79+GjlypCL+vX/Ozs7aunWrypUrp++++05Hjx5Vjx491LhxYz3zzDMZ3qMVK1YoODhY999//y3vp7Ozs5ycnKyf68UXX9Q333yjefPmyd/fX5MnT9Zjjz2m3377TcWKFbNOmPD29k73t/L19zErbV3vzJkz6tatm3r37q358+fr0KFD6tevn8xms8LDw3X27Fn17dtXb731ljp27KjLly9r69at8vb2lpubm5544gn17dtXCxcuVGJionbt2mU9mKqwio+Pl7u7u5o3b57uoK3MQrmM5Hsg5OLioipVqkiSGjZsqN27d2vGjBmaO3fuLd/r7Oys+vXr6+jRo5mWcXV1laura4bvzY//IZKr7bqnJssOydfkwP+oQgGSX+MPuFswBlDYMQaAvBsHKSkpMplMcnBw+G+Wh0P+bR1r049b6NOnj6ZMmaItW7aoZcuWkqRPPvlEXbp0UdGiRVW0aFENGzbMWn7w4MFat26dlixZovvuu896Pe3z3/h8/fr1OnTokNauXasyZcpIkiZMmKB27drZ9PP111+3vrdSpUo6cuSIFi5cqOHDh8vT01Pe3t5ycnKy1pHR5124cKHi4+M1f/58eXqm7v06e/ZshYaGatKkSSpdurRMJpOKFi2qd955R46OjqpZs6bat2+vjRs36tlnn83wHv32229q2bKlzefr1KmTdcZZ3bp1tX37duvnTvvsV65c0Xvvvad58+ZZZzB9+OGHqlChgiIiIjRs2DBrnZn9zG68rze+ltnr7733nsqVK6d33nlHJpNJ1atX1/HjxzVmzBiFh4fr/PnzSk5OVpcuXeTv7y9JCgwMlCT9/fffiomJUWhoqAICAiTpplvGFBYODg4ymUwZ/juSnX9X8j0QupHFYrHZ8+dmUlJStH///sI7O8b536Q9MetTwgAAAAAULiZ3d1Xb+2O23/fXBx/o4rvvyeTsLCMpScX7P6cSmcxcuVnbWVW9enUFBQXp448/VsuWLXX06FFt2bLFukQrJSVFEyZM0KJFi3TmzBklJiYqISEhy1uBHDx4UOXKlbMJcjLav/bLL7/UzJkzdezYMcXFxSk5OTnbs1EOHjyowMBAaxgkSc2aNZPFYtHhw4ethyPVqlXLZg8YPz8/7d+/P1ttzZkzR1euXNHMmTO1efPmDMscO3ZMSUlJatasmfWas7OzmjRpooMHD2arvew6ePCgmjZtarN08N5771VcXJx+//13BQYG6uGHH1adOnXUpk0btW7dWo899piKFi2qYsWKKSwsTG3atFGrVq0UHBysbt26yc/PL0/7XFjk6yljI0aM0ObNm3Xy5Ent379fI0aM0KZNm9SzZ09JqVMGR4wYYS0/duxYrVu3TsePH9fevXv1xBNP6NSpU+rbt29+fYT8lRYIccoYAAAAgEyYTCY5eHhk63Fx3jxdfPc9lRj8vKrv/1klBj+vi+++p4vz5mWrnqzsH3S9Pn36aOnSpbp8+bIiIiJUuXJltWjRQpI0efJkzZgxQ8OHD9fGjRsVFRWlNm3aWPdKyg07duxQz549FRISom+++UY//fSTRo4cmattXO/G2Rwmk+mmGy0HBATo8OHDNtf8/PxUpUoVFStW7Lb6khZ6xcTEpHvt0qVL8vHxua36M+Po6KjIyEitWbNGNWvW1KxZs1StWjWdOHFCkhQREaEdO3YoKChIX375papWrXrTk8mRdfkaCF24cEG9evVStWrV9PDDD2v37t1au3atWrVqJUmKjo7W2bNnreX/+ecfPfPMM6pRo4ZCQkIUGxur7du3Z7oJtd2zBkLMEAIAAACQO/6cM0d/zZylEoOfV8kBAyRJJQcMUInBz+uvmbMyPZI+N3Tr1k0ODg5asGCBPv30Uz399NPWUGnbtm3q0KGDnnjiCQUGBqpSpUr67bffslx3jRo1dPr0aZu/MW8MFrZv3y5/f3+NHDlSjRo1UkBAgE6dOmVTxsXFRSkpKbdsa9++fbpy5Yr12rZt2+Tg4KBq1apluc836tGjhyIjI/XTTz9l632VK1eWi4uLtm3bZr2WlJSk3bt3W/+eDggIkIODg3780XY22fHjxxUTE6OqVavmqM81atTQjh07rKeLSdLOnTvl7e1tPRzKZDKpWbNmGjNmjH766Se5uLho+fLl1vL169fXiBEjtH37dtWuXVsLFizIUV9gK1+XjH300Uc3fX3Tpk02z99++229/fbbedijAsb53+mXBEIAAAAAckuKxSYMSmN9npJ3R4V7eXmpe/fuGjFihGJjYxUWFmZ9LSAgQEuWLNH27dtVtGhRTZs2TefPn8/yBIHg4GBVrVpVvXv31uTJkxUbG6uRI0falAkICFB0dLQWLlyoxo0ba9WqVTbBhCRVqFBBJ06cUFRUlMqWLStvb+90+9b27NlTo0ePVu/evRUeHq4///xTzz//vJ588knrcrGceOmll7Rq1So9/PDDGj16tB544AEVLVpUv/32m9asWZPuCPI0np6e6t+/v4YNG6ZixYqpfPnymjRpkq5evao+ffpISt1Mum/fvnr55Zfl5OSkOnXq6PTp0xo+fLjuu+8+BQXdfGPymJgYRUVF2VwrXry4BgwYoOnTp+v555/XoEGDdPDgQb355pt66aWX5ODgoJ07d2rDhg1q3bq1SpUqpZ07d+rPP/9UjRo1dOLECb3//vt69NFHVaZMGR0+fFhHjhxRr169cnwP8Z+7bg8hZIPLv+tRUxKllGTJkR8nAAAAgNtT8vlBmb92Q0iUF/r06aOPPvpIISEhNvv9vPbaazp+/LjatGkjDw8P9evXTx07dsxwiVNGHBwctHz5cvXp00dNmjRRhQoVNHPmTLVt29Za5tFHH9VLL72kQYMGKSEhQe3bt9frr7+u8PBwa5kuXbpo2bJlevDBB3Xp0iVFRETYBFeS5OHhobVr1+qFF15Q48aN5eHhoS5dumjatGm3dW/c3Ny0YcMGTZ8+XRERERoxYoQsFosqVqyodu3a6aWXXsr0vW+++aYsFouefPJJXb58WY0aNdLatWtVtGhRa5kZM2bozTff1PDhw3Xq1Cn5+vqqVatWGj9+/C2X/23atEn169e3udanTx99+OGHWr16tYYNG6bAwEAVK1ZMTzzxhDWMM5vN2rx5s6ZPn67Y2Fj5+/tr6tSpateunc6fP69Dhw7pk08+0cWLF+Xn56eBAwdmuuk2ssdkXD9vqxCIjY2Vj4+PYmJi7vix86tXr1ZISEjunSaQdE0a75v6/YjfJVfv3KkXyCN5Mg6AAoQxgMKOMQDk/TiIj4/XiRMnVLFixXTHUQN3A4vFotjYWJnN5iyfQAdbNxvn2ck8uPsFmZObpH9TWk4aAwAAAAAAWUQgVJCZTGwsDQAAAAAAso1AqKCzbizN0fMAAAAAACBrCIQKOhdmCAEAAAAAgOwhECroWDIGAAAAAACyiUCooGPJGAAAAAAAyCYCoYLO2TP1a+KV/O0HAAAAAAAoMAiECjpmCAEAAAAAgGwiECrorIEQewgBAAAAAICsIRAq6Fz+XTJGIAQAAACgkGvZsqVefPFF6/MKFSpo+vTpN32PyWTSihUrbrvt3KonN9x4H/LSjZ/70KFDuu++++Tm5qZ69erp5MmTMplMioqKytN+hIeHq169ennahr0hECroWDIGAAAAIBft+vq4dq86keFru1ed0K6vj+d6m6GhoWrbtm2Gr23ZskUmk0k///xztuvdvXu3+vXrd7vds5FZ8HD27Fm1a9cuV9vKSGJioiZNmqTAwEB5eHioRIkSatasmSIiIpSUlJTn7d/oxs89evRoeXp66vDhw9qwYYPKlSuns2fPqnbt2rnWZkbh29ChQ7Vhw4ZcayMzWQkZCwqn/O4AbhPHzgMAAADIRSYHk3Z9nRoINW5f0Xo9NQw6oSahFTN7a4716dNHXbp00e+//66yZcvavBYREaFGjRqpbt262a63ZMmSudXFW/L19c3zNhITE9WmTRvt27dP48aNU7NmzWQ2m/XDDz9oypQpql+//h2fJXPj5z527Jjat28vf3//TMvkBS8vL3l5eeV5O/aEGUIFXVoglEggBAAAACA9wzCUlJCS5Ue94PJqFFJBu74+oZ0rjyspIUU7Vx7Xrq9PqFFIBdULLp/lugzDyFIfH3nkEZUsWVLz5s2zuR4XF6fFixerT58+unjxonr06KF77rlHHh4eqlOnjr744oub1nvjbI4jR46oefPmcnNzU82aNRUZGZnuPcOHD1fVqlXl4eGhSpUq6fXXX7fOvJk3b57GjBmjffv2yWQyyWQyWft846yV/fv366GHHpK7u7uKFy+ufv36KS4uzvp6WFiYOnbsqClTpsjPz0/FixfXwIEDbzrLZ/r06dq8ebM2bNiggQMHql69eqpUqZL+97//aefOnQoICMjwffPnz1ejRo3k7e0tX19f/e9//9OFCxesr//zzz/q2bOnSpYsKXd3dwUEBCgiIkJSagg1aNAg+fn5yc3NTf7+/po4caL1vdd/bpPJpB9//FFjx46VyWRSeHh4hkvGDh48qNDQUJnNZnl7e+uBBx7QsWPHJKXO6mrVqpVKlCghHx8ftWjRQnv37rX5mUpSp06dZDKZrM9vnLllsVg0duxYlS1bVq6urqpXr56+/fZb6+tp/Vq2bJkefPBBeXh4KDAwUDt27Mj0/mfFu+++q8qVK8vFxUXVqlXT/Pnzra8ZhqHw8HCVL19erq6uKlOmjAYPHmx9fc6cOQoICJCbm5tKly6txx577Lb6civMECroWDIGAAAA4CaSEy16/4Xvc/TePatPas/qk5k+v5V+M1rI2dXxluWcnJzUq1cvzZs3TyNHjpTJZJIkLV68WCkpKerRo4fi4uLUsGFDDR8+XGazWatWrdKTTz6pypUrq0mTJrdsw2KxqHPnzipdurR27typmJiYDPfZ8fb21rx581SmTBnt379fzzzzjLy9vfXKK6+oe/fu+uWXX/Ttt99q/fr1kiQfH590dVy5ckVt2rRR06ZNtXv3bl24cEF9+/bVoEGDbEKvjRs3ys/PTxs3btTRo0fVvXt31atXT88880yGn+Hzzz9XcHCw6tevn+41Z2dnOTs7Z/i+pKQkjRs3TtWqVdOFCxc0ZMgQhYWFafXq1ZKk119/Xb/++qvWrFmjEiVK6OjRo7p2LfVvzJkzZ2rlypVatGiRypcvr9OnT+v06dMZtnP27FkFBwerbdu2Gjp0qLy8vPTXX3/ZlDlz5ozat2+vli1b6rvvvpPZbNa2bduUnJwsSbp8+bJ69+6tWbNmyTAMTZ06VSEhITpy5Ii8vb21e/dulSpVShEREWrbtq0cHTP+/ZoxY4amTp2quXPnqn79+vr444/16KOP6sCBAzbB2ciRIzVlyhQFBARo5MiR6tGjh44ePSonp+zHJcuXL9cLL7yg6dOnKzg4WN98842eeuoplS1bVg8++KCWLl2qt99+WwsXLlStWrV07tw57du3T5K0Z88eDR48WPPnz1dQUJD+/vtvbdmyJdt9yA4CoYLOumTsSv72AwAAAABuw9NPP63Jkyfr+++/V8uWLSWlLhfr0qWLfHx85OPjo6FDh1rLP//881q7dq0WLVqUpUBo/fr1OnTokNauXasyZcpIkiZMmJBu35/XXnvN+n2FChU0dOhQLVy4UK+88orc3d3l5eUlJyenmy6DWrBggeLj4/Xpp5/K0zP1IKDZs2crNDRUb731lkqXLi1JKlq0qGbPni1HR0dVr15d7du314YNGzINhI4cOWK9N9nx9NNPW7+vVKmSZs6cqcaNGysuLk5eXl6Kjo5W/fr11ahRI+vnThMdHa2AgADdf//9MplMNkvBbuTr6ysnJyd5eXlZ78+NgdCcOXNkNpv1xRdfyNXVVZJUtWpV6+sPPfSQTfn3339fRYoU0ffff2+dSSZJRYoUuenPYMqUKRo+fLgef/xxSdJbb72ljRs3avr06XrnnXes5YYOHar27dtLksaMGaNatWrp6NGjql69eqZ136zNsLAwDRgwQJI0ZMgQ63K+Bx98UNHR0fL19VVwcLCcnZ1Vvnx56+9udHS0PD099cgjj8jb21v+/v4ZBn+5iUCooHNJC4SYIQQAAAAgPScXB/Wb0SLb79u79pT2rD4pB0eTLCmGGoVUUIM2mYcBmbWdVdWrV1dQUJA+/vhjtWzZUkePHtWWLVs0duxYSVJKSoomTJigRYsW6cyZM0pMTFRCQoI8PDyyVP/BgwdVrlw5axgkSU2bNk1X7ssvv9TMmTN17NgxxcXFKTk5WWazOcufI62twMBAaxgkSc2aNZPFYtHhw4etgVCtWrVsZrj4+flp//79mdab1SV4N/rxxx8VHh6uffv26Z9//pHFYpGUGkLUrFlT/fv3V5cuXbR37161bt1aHTt2VFBQkKTUpW2tWrVStWrV1LZtWz3yyCNq3bp1jvohSVFRUWratGmms5nOnz+v1157TZs2bdKFCxeUkpKiq1evKjo6OsttxMbG6o8//lCzZs1srjdr1sw6IyfN9XtT+fn5SZIuXLiQo0Do4MGD6TYxb9asmWbMmCFJ6tq1q6ZPn65KlSqpbdu2CgkJUWhoqJycnNSqVSv5+/tbX2vbtq06deqU5d/vnGAPoYKOTaUBAAAA3ITJZJKzq2O2HlHro7Vn9Uk1Ca2o/u88qCahFbVn9UlFrY/OVj1pS7+yqk+fPlq6dKkuX76siIgIVa5cWS1apIZZkydP1owZMzR8+HBt3LhRUVFRatOmjRITE3PtXu3YsUM9e/ZUSEiIvvnmG/30008aOXJkrrZxvRtDEZPJZA1rMlK1alUdOnQoW22kLV8zm836/PPPtXv3bi1fvlySrJ+rXbt2OnXqlF566SX98ccfevjhh62zsRo0aKATJ05o3Lhxunbtmrp163Zbe9u4u7vf9PXevXsrKipKM2bM0Pbt2xUVFaXixYvfkZ9B2u/rzX4Gt6NcuXI6fPiw5syZI3d3dw0YMEDNmzdXUlKSvL29tXfvXn3xxRfy8/PTqFGjFBgYqEuXLuVJXyQCoYIvbQ8hNpUGAAAAkAuuP00s7ZSxxu0rqkloRe36+kSmR9Lnhm7dusnBwUELFizQp59+qqefftr6R/q2bdvUoUMHPfHEEwoMDFSlSpX022+/ZbnuGjVq6PTp0zp79qz12g8//GBTZvv27fL399fIkSPVqFEjBQQE6NSpUzZlXFxclJKScsu29u3bpytX/tvaY9u2bXJwcFC1atWy3Ocb/e9//9P69ev1008/pXstKSnJpr00hw4d0sWLF/Xmm2/qgQceUPXq1W02lE5TsmRJ9e7dW5999pmmT5+u999/3/qa2WxW9+7d9cEHH+jLL7/U0qVL9ffff+foM9StW1c7duzIdPPsbdu2afDgwQoJCVGtWrXk6uqabtmZs7PzTX8GZrNZZcqU0bZt29LVXbNmzRz1Oytq1Khxyzbd3d0VGhqqmTNnatOmTdqxY4d1VpiTk5OCg4M1adIk/fzzzzp58qS+++67POsvS8YKOmeWjAEAAADIPYbFsAmD0qQ9Nyw5W7aUFV5eXurevbtGjBih2NhYhYWFWV8LCAjQkiVLtH37dhUtWlTTpk3T+fPns/wHfnBwsKpWrarevXtr8uTJio2N1ciRI23KBAQEKDo6WgsXLlTjxo21atUq62yaNBUqVNCJEycUFRWlsmXLytvb27oXTpqePXtq9OjR6t27t8LDw/Xnn3/q+eef15NPPmldLpYTL774olatWqWHH35Y48aN0/333y9vb2/t2bNHb731lj766KN0x86XL19eLi4umjVrlp577jn98ssvGjdunE2ZUaNGqWHDhqpVq5YSEhL0zTffqEaNGpKkadOmyc/PT/Xr15eDg4MWL14sX19fFSlSJEefYeDAgZo1a5Z69Oih//u//5OPj49++OEHNWnSRNWqVVNAQID1VLTY2FgNGzYs3ayiChUqaMOGDWrWrJlcXV1VtGjRdO0MGzZMo0ePVuXKlVWvXj1FREQoKipKn3/+eY76fb0zZ87YnJomSf7+/ho2bJi6deum+vXrKzg4WF9//bWWLVtm3YB83rx5SklJ0b333isPDw999tlncnd3l7+/v7755hsdP35czZs3V9GiRbV69WpZLJbbChBvhRlCBR1LxgAAAADkoiahldKFQWlSZwpVytP2+/Tpo3/++Udt2rSx2e/ntddeU4MGDdSmTRu1bNlSvr6+6tixY5brdXBw0PLly3Xt2jU1adJEffv21fjx423KPProo3rppZc0aNAg1atXT9u3b9frr79uU6ZLly5q27atHnzwQZUsWVJffPFFurY8PDy0du1a/f3332rcuLEee+wxPfzww5o9e3b2bsYNXF1dFRkZqVdeeUVz587Vfffdp8aNG2vmzJkaPHiwateune49JUuW1Lx587R48WLVrFlTb775pqZMmWJTxsXFRSNGjFDdunXVvHlzOTo6auHChZJST12bNGmSGjVqpMaNG+vkyZNavXq1HBxyFicUL15cX331leLi4tSiRQs1bNhQH3zwgXXp1kcffaR//vlHDRo00JNPPqnBgwerVKlSNnVMnTpVkZGRKleuXKYbLw8ePFhDhgzRyy+/rDp16ujbb7/VypUrbU4Yy6kpU6aofv36No9Vq1apY8eOmjFjhqZMmaJatWpp7ty5ioiIsG4EXqRIEX3wwQdq1qyZ6tatq/Xr1+vrr79W8eLFVaRIES1btkwPPfSQatSooffee09ffPGFatWqddv9zYzJyOmuVAVUbGysfHx8FBMTk+2NwW5HUlKSVq9erZCQkEw3z8qRsz9Lcx+QvEpLQ7M+XRLID3k2DoACgjGAwo4xAOT9OIiPj9eJEydUsWJFubm55Xr9wO2yWCyKjY2V2WzOcahU2N1snGcn8+DuF3Qu/+5az5IxAAAAAACQRQRCBV3aptIsGQMAAAAAAFlEIFTQpQVClmQpOW+O4QMAAAAAAPaFQKigc/b873tmCQEAAAAAgCwgECroHJ0lk2Pq9+wjBAAAAAAAsoBAqKAzma7bWJoZQgAAAAAA4NYIhOwBG0sDAAAAAIBsIBCyB9ZAiCVjAAAAAADg1giE7EHaxtKJV/K3HwAAAAAAoEAgELIHzBACAAAAALVs2VIvvvii9XmFChU0ffr0m77HZDJpxYoVt912btUD3CkEQvaAPYQAAAAA5JLtiz/XjqVfZPjajqVfaPviz3O9zdDQULVt2zbD17Zs2SKTyaSff/452/Xu3r1b/fr1u93u2QgPD1e9evXSXT979qzatWuXq23daN68eSpSpEimr2/evFmhoaEqU6ZMlgOqW9UJ+0UgZA84ZQwAAABALjE5OGj7ovSh0I6lX2j7os9lcsj9PyP79OmjyMhI/f777+lei4iIUKNGjVS3bt1s11uyZEl5eHjkRhdvydfXV66urnekrcxcuXJFgYGBeuedd/K1HygYCITsAUvGAAAAAGTCMAwlxcdn+dGofSfd17m7ti/6XNu+nK+k+Hht+3K+ti/6XPd17q5G7TtluS7DMLLUx0ceeUQlS5bUvHnzbK7HxcVp8eLF6tOnjy5evKgePXronnvukYeHh+rUqaMvvsh4JlOaG5eMHTlyRM2bN5ebm5tq1qypyMjIdO8ZPny4qlatKg8PD1WqVEmvv/66kpKSJKXOphkzZoz27dsnk8kkk8lk7fONM3L279+vhx56SO7u7ipevLj69eunuLg46+thYWHq2LGjpkyZIj8/PxUvXlwDBw60tpUT7dq10xtvvKFOnTrluI4bRUdHq0OHDvLy8pLZbFa3bt10/vx56+v79u3Tgw8+KG9vb5nNZjVs2FB79uyRJJ06dUqhoaEqWrSoPD09VatWLa1evTrX+obb45TfHUAucP438WaGEAAAAIAbJCckaGbvx3L03h+Wfakfln2Z6fNbGfzJEjm7ud2ynJOTk3r16qV58+Zp5MiRMplMkqTFixcrJSVFPXr0UFxcnBo2bKjhw4fLbDZr1apVevLJJ1W5cmU1adLklm1YLBZ17txZpUuX1s6dOxUTE2Oz31Aab29vzZs3T2XKlNH+/fv1zDPPyNvbW6+88oq6d++uX375Rd9++63Wr18vSfLx8UlXx5UrV9SmTRs1bdpUu3fv1oULF9S3b18NGjTIJvTauHGj/Pz8tHHjRh09elTdu3dXvXr19Mwzz9zy89wJFovFGgZ9//33Sk5O1sCBA9W9e3dt2rRJktSzZ0/Vr19f7777rhwdHRUVFSVnZ2dJ0sCBA5WYmKjNmzfL09NTv/76q7y8vPLxE+F6BEL2IC0QSiQQAgAAAFAwPf3005o8ebK+//57tWzZUlLqcrEuXbrIx8dHPj4+Gjp0qLX8888/r7Vr12rRokVZCoTWr1+vQ4cOae3atSpTpowkacKECen2/Xnttdes31eoUEFDhw7VwoUL9corr8jd3V1eXl5ycnKSr69vpm0tWLBA8fHx+vTTT+XpmbrFx+zZsxUaGqq33npLpUuXliQVLVpUs2fPlqOjo6pXr6727dtrw4YNd00gtGHDBu3fv18nTpxQuXLlJEmffvqpatWqpd27d6tx48aKjo7WsGHDVL16dUlSQECA9f3R0dHq0qWL6tSpI0mqVKmSLBaLYmNj7/yHQToEQvaATaUBAAAAZMLJ1VWDP1mS7fft+mqxflj2pRycnGRJTtZ9nburSYeu2W47q6pXr66goCB9/PHHatmypY4ePaotW7Zo7NixkqSUlBRNmDBBixYt0pkzZ5SYmKiEhIQs7xF08OBBlStXzhoGSVLTpk3Tlfvyyy81c+ZMHTt2THFxcUpOTpbZbM7y50hrKzAw0BoGSVKzZs1ksVh0+PBhayBUq1YtOTo6Wsv4+flp//792WorL6Xds7QwSJJq1qypIkWK6ODBg2rcuLGGDBmivn37av78+QoODlbXrl1VuXJlSdLgwYPVv39/rVu3TsHBwerSpYtq166dXx8HN2APIXtgXTLGHkIAAAAAbJlMJjm7uWXrsWfVcv2w7EsFdeuplz5foaBuPfXDsi+1Z9XybNWTtvQrq/r06aOlS5fq8uXLioiIUOXKldWiRQtJ0uTJkzVjxgwNHz5cGzduVFRUlNq0aaPExMRcu1c7duxQz549FRISom+++UY//fSTRo4cmattXC9taVUak8kki8WSJ23llfDwcB04cEDt27fXd999p5o1a2r58uWSpL59++r48eN68skntX//fjVq1EizZ8/O5x4jDYGQPXBhDyEAAAAAuSPtNLGgbj3VtEsPSVLTLj0U1K1nhqeP5aZu3brJwcFBCxYs0Keffqqnn37aGipt27ZNHTp00BNPPKHAwEBVqlRJv/32W5brrlGjhk6fPq2zZ89ar/3www82ZbZv3y5/f3+NHDlSjRo1UkBAgE6dOmVTxsXFRSkpKbdsa9++fbpy5Yr12rZt2+Tg4KBq1apluc/5Le2enT592nrt119/1aVLl1SzZk3rtapVq+qll17SunXr1LlzZ0VERFhfK1eunJ577jktW7ZML7/8sj788MM7+hmQOZaM2QM2lQYAAACQSwyLxSYMSpP23MjDGSxeXl7q3r27RowYodjYWIWFhVlfCwgI0JIlS7R9+3YVLVpU06ZN0/nz522CiZsJDg5W1apV1bt3b02ePFmxsbEaOXKkTZmAgABFR0dr4cKFaty4sVatWmWd7ZKmQoUKOnHihKKiolS2bFl5e3unO26+Z8+eGj16tHr37q3w8HD9+eefev755/Xkk09al4vlVEpKiqKiomyuubq6qkaNGoqLi9PRo0et19P6WaxYMZUvXz7bdQYHB6tOnTrq2bOnpk+fruTkZA0YMEAtWrRQo0aNdO3aNQ0bNkyPPfaYKlasqN9//127d+9Wly5dJEkvvvii2rVrp6pVq+qff/7Rxo0brXsNIf8RCNmDtD2E2FQaAAAAwG0K6toz09duDInyQp8+ffTRRx8pJCTEZr+f1157TcePH1ebNm3k4eGhfv36qWPHjoqJiclSvQ4ODlq+fLn69OmjJk2aqEKFCpo5c6batm1rLfPoo4/qpZde0qBBg5SQkKD27dvr9ddfV3h4uLVMly5dtGzZMj344IO6dOmSIiIibIIrSfLw8NDatWv1wgsvqHHjxvLw8FCXLl00bdq027o3khQXF6f69evbXKtcubKOHj2qPXv26MEHH7ReHzJkiCSpd+/eNqebZafOr776Ss8//7yaN28uBwcHtW3bVrNmzZIkOTo66uLFi+rVq5fOnz+vEiVKqHPnzhozZoyk1KBp4MCB+v3332U2m9W2bVtNnTr1tu8BcofJMAwjvztxJ8XGxsrHx0cxMTHZ3hjsdiQlJWn16tUKCQlJt070tv2yTFrylOR/v/TUqtytG8hFeToOgAKAMYDCjjEA5P04iI+P14kTJ1SxYkW5ZeG4d+BOSztlzGw2y8GBXWxy4mbjPDuZB3ffHrBkDAAAAAAAZAOBkD3g2HkAAAAAAJANBEL2wMUz9SuBEAAAAAAAyAICIXtgnSF0LX/7AQAAAAAACgQCIXvAKWMAAAAArlPIzg4CCpXcGt8EQvbA+bolY/zDDwAAABRaaSeXXb3KfywG7FViYqIkydHR8bbqccqNziCfpc0QkiElJ0jOHC8JAAAAFEaOjo4qUqSILly4IEny8PCQyWTK514B/7FYLEpMTFR8fDzHzueAxWLRn3/+KQ8PDzk53V6kQyBkD9KOnZdSZwkRCAEAAACFlq+vryRZQyHgbmIYhq5duyZ3d3fCyhxycHBQ+fLlb/v+EQjZA0cnydFFSkn896SxYvndIwAAAAD5xGQyyc/PT6VKlVJSUlJ+dwewkZSUpM2bN6t58+bWJY7IHhcXl1yZXUUgZC+c3f8NhDhpDAAAAEDq8rHb3WMEyG2Ojo5KTk6Wm5sbgVA+Y8GevUjbWDrxSv72AwAAAAAA3PUIhOxF2sbSzBACAAAAAAC3QCBkL9I2lk7ieEkAAAAAAHBzBEL2woVACAAAAAAAZA2BkL1gyRgAAAAAAMgiAiF7wZIxAAAAAACQRQRC9iItEEokEAIAAAAAADdHIGQvrEvGCIQAAAAAAMDNEQjZC+uSMfYQAgAAAAAAN0cgZC84ZQwAAAAAAGRRvgZC7777rurWrSuz2Syz2aymTZtqzZo1N33P4sWLVb16dbm5ualOnTpavXr1HertXY5NpQEAAAAAQBblayBUtmxZvfnmm/rxxx+1Z88ePfTQQ+rQoYMOHDiQYfnt27erR48e6tOnj3766Sd17NhRHTt21C+//HKHe34X4th5AAAAAACQRfkaCIWGhiokJEQBAQGqWrWqxo8fLy8vL/3www8Zlp8xY4batm2rYcOGqUaNGho3bpwaNGig2bNn3+Ge34Wsp4xdyd9+AAAAAACAu55TfncgTUpKihYvXqwrV66oadOmGZbZsWOHhgwZYnOtTZs2WrFiRab1JiQkKCEhwfo8NjZWkpSUlKSkpKTb73gWpbWVV22aHFzlJMmSeFUpd/BzAdmR1+MAuNsxBlDYMQYAxgHAGMhb2bmv+R4I7d+/X02bNlV8fLy8vLy0fPly1axZM8Oy586dU+nSpW2ulS5dWufOncu0/okTJ2rMmDHprq9bt04eHh631/kciIyMzJN6/f45qCaS/jn/u7ayrxLucnk1DoCCgjGAwo4xADAOAMZA3rh6Nev7Cud7IFStWjVFRUUpJiZGS5YsUe/evfX9999nGgpl14gRI2xmFcXGxqpcuXJq3bq1zGZzrrSRFUlJSYqMjFSrVq3k7Oyc6/WbjrpIJ2ermLebQkJCcr1+IDfk9TgA7naMARR2jAGAcQAwBvJW2qqorMj3QMjFxUVVqlSRJDVs2FC7d+/WjBkzNHfu3HRlfX19df78eZtr58+fl6+vb6b1u7q6ytXVNd11Z2fnfPnly7N23b0lSabkeAYV7nr5Nf6AuwVjAIUdYwBgHACMgbyRnXuar5tKZ8Risdjs+XO9pk2basOGDTbXIiMjM91zqFBJO2UskWPnAQAAAADAzeXrDKERI0aoXbt2Kl++vC5fvqwFCxZo06ZNWrt2rSSpV69euueeezRx4kRJ0gsvvKAWLVpo6tSpat++vRYuXKg9e/bo/fffz8+PcXdw9kz9mkQgBAAAAAAAbi5fA6ELFy6oV69eOnv2rHx8fFS3bl2tXbtWrVq1kiRFR0fLweG/SUxBQUFasGCBXnvtNf3f//2fAgICtGLFCtWuXTu/PsLdI22GUNK1/O0HAAAAAAC46+VrIPTRRx/d9PVNmzalu9a1a1d17do1j3pUgDn/e2Ja8jXJYpEc7rrVgAAAAAAA4C5BamAvXDz++z6ZWUIAAAAAACBzBEL2wsn9v+9ZNgYAAAAAAG6CQMheODhITm6p3ydeyd++AAAAAACAuxqBkD1J20eIGUIAAAAAAOAmCITsiTUQ4uh5AAAAAACQOQIhe+JCIAQAAAAAAG6NQMieOP+7sTRLxgAAAAAAwE0QCNkTlowBAAAAAIAsIBCyJ2mBUCKBEAAAAAAAyByBkD2xLhkjEAIAAAAAAJkjELInHDsPAAAAAACygEDInnDKGAAAAAAAyAICIXvCptIAAAAAACALCITsCcfOAwAAAACALCAQsifWU8au5G8/AAAAAADAXY1AyJ6wqTQAAAAAAMgCAiF7wpIxAAAAAACQBQRC9sTFM/VrEkvGAAAAAABA5giE7AkzhAAAAAAAQBYQCNmTtEAokWPnAQAAAABA5giE7Ilz2pIxAiEAAAAAAJA5AiF7wpIxAAAAAACQBQRC9sR67DybSgMAAAAAgMwRCNkTl7RAiBlCAAAAAAAgcwRC9iRthlBKopSSnL99AQAAAAAAdy0CIXuStoeQxMbSAAAAAAAgUwRC9sTJTZIp9XuWjQEAAAAAgEwQCNkTk+m6jaWZIQQAAAAAADJGIGRvXAiEAAAAAADAzREI2Zu0fYRYMgYAAAAAADJBIGRvWDIGAAAAAABugUDI3qQFQokEQgAAAAAAIGMEQvaGGUIAAAAAAOAWCITsDXsIAQAAAACAWyAQsjecMgYAAAAAAG6BQMjesGQMAAAAAADcAoGQvWHJGAAAAAAAuAUCIXtjPWXsSv72AwAAAAAA3LUIhOyNdckYM4QAAAAAAEDGCITsDUvGAAAAAADALRAI2RsXz9SvSSwZAwAAAAAAGSMQsjfMEAIAAAAAALdAIGRvOHYeAAAAAADcAoGQvbGeMkYgBAAAAAAAMkYgZG9YMgYAAAAAAG6BQMjeWJeMsak0AAAAAADIGIGQvXFJC4SYIQQAAAAAADJGIGRvnAmEAAAAAADAzREI2Zu0PYQSr0iGkb99AQAAAAAAdyUCIXuTNkPISJFSkvK3LwAAAAAA4K5EIGRv0gIhSUri6HkAAAAAAJAegZC9cXSWTI6p3xMIAQAAAACADBAI2RuTSXLxTP2ejaUBAAAAAEAGCITsUdrG0swQAgAAAAAAGSAQskdp+wglEggBAAAAAID0CITsUVogxAwhAAAAAACQAQIhe2RdMsYeQgAAAAAAID0CIXvkwgwhAAAAAACQOQIhe8SSMQAAAAAAcBMEQvaIJWMAAAAAAOAmCITskbNn6tfEK/nbDwAAAAAAcFciELJHzBACAAAAAAA3QSBkj6yBEHsIAQAAAACA9AiE7JHLv0vGCIQAAAAAAEAG8jUQmjhxoho3bixvb2+VKlVKHTt21OHDh2/6nnnz5slkMtk83Nzc7lCPCwiWjAEAAAAAgJvI10Do+++/18CBA/XDDz8oMjJSSUlJat26ta5cuflmyGazWWfPnrU+Tp06dYd6XEBw7DwAAAAAALgJp/xs/Ntvv7V5Pm/ePJUqVUo//vijmjdvnun7TCaTfH1987p7BVdaIJRIIAQAAAAAANLL10DoRjExMZKkYsWK3bRcXFyc/P39ZbFY1KBBA02YMEG1atXKsGxCQoISEhKsz2NjYyVJSUlJSkpKyqWe31paW3eiTZODi5wkWRKvKOUOfkbgVu7kOADuRowBFHaMAYBxADAG8lZ27qvJMAwjD/uSZRaLRY8++qguXbqkrVu3Zlpux44dOnLkiOrWrauYmBhNmTJFmzdv1oEDB1S2bNl05cPDwzVmzJh01xcsWCAPD49c/Qx3i9IxP+m+42/rH49K2lwtPL+7AwAAAAAA7oCrV6/qf//7n2JiYmQ2m29a9q4JhPr37681a9Zo69atGQY7mUlKSlKNGjXUo0cPjRs3Lt3rGc0QKleunP76669b3pzclJSUpMjISLVq1UrOzs552pbp5BY5fd5JRolqSn52W562BWTHnRwHwN2IMYDCjjEAMA4AxkDeio2NVYkSJbIUCN0VS8YGDRqkb775Rps3b85WGCRJzs7Oql+/vo4ePZrh666urnJ1dc3wffnxy3dH2nVP/aGbkq8xwHBXyq/xB9wtGAMo7BgDAOMAYAzkjezc03w9ZcwwDA0aNEjLly/Xd999p4oVK2a7jpSUFO3fv19+fn550MMCKu3YeTaVBgAAAAAAGcjXGUIDBw7UggUL9NVXX8nb21vnzp2TJPn4+MjdPTXU6NWrl+655x5NnDhRkjR27Fjdd999qlKlii5duqTJkyfr1KlT6tu3b759jruO9dj5a/nbDwAAAAAAcFfK10Do3XfflSS1bNnS5npERITCwsIkSdHR0XJw+G8i0z///KNnnnlG586dU9GiRdWwYUNt375dNWvWvFPdvvtZA6GrkmFIJlP+9gcAAAAAANxV8jUQysp+1ps2bbJ5/vbbb+vtt9/Oox7ZibQlYzKk5PjrngMAAAAAAOTzHkLII2kzhCSWjQEAAAAAgHQIhOyRo5Pk6JL6fRIbSwMAAAAAAFsEQvaKk8YAAAAAAEAmCITslbNn6ldmCAEAAAAAgBsQCNmrtBlC7CEEAAAAAABuQCBkr1zSjp6/kr/9AAAAAAAAdx0CIXuVdtIYM4QAAAAAAMANCITsFUvGAAAAAABAJgiE7FXaptKJLBkDAAAAAAC2CITsFTOEAAAAAABAJgiE7JU1EOLYeQAAAAAAYItAyF65/LtkjEAIAAAAAADcgEDIXrFkDAAAAAAAZIJAyF5Zj51nhhAAAAAAALBFIGSv0gKhRAIhAAAAAABgi0DIXrGpNAAAAAAAyASBkL2yLhljDyEAAAAAAGCLQMheubCHEAAAAAAAyBiBkL1iU2kAAAAAAJAJAiF7xbHzAAAAAAAgEwRC9opTxgAAAAAAQCYIhOwVS8YAAAAAAEAmCITsFcfOAwAAAACATBAI2SsXz9SvyfGSxZK/fQEAAAAAAHcVAiF7lTZDSJKS2VgaAAAAAAD8h0DIXjldFwixsTQAAAAAALgOgZC9cnD4LxRiHyEAAAAAAHAdAiF7Zt1YmiVjAAAAAADgPwRC9sx69PyV/O0HAAAAAAC4qxAI2TOXtECIGUIAAAAAAOA/BEL2jCVjAAAAAAAgAwRC9szZM/VrIkvGAAAAAADAfwiE7BkzhAAAAAAAQAYIhOyZM8fOAwAAAACA9AiE7JnLv0vGCIQAAAAAAMB1CITsGUvGAAAAAABABgiE7Jlz2rHzzBACAAAAAAD/IRCyZ2mBUCKBEAAAAAAA+A+BkD1jU2kAAAAAAJABAiF7Zl0yxh5CAAAAAADgPwRC9syFPYQAAAAAAEB6BEL2jE2lAQAAAABABgiE7BnHzgMAAAAAgAwQCNkzThkDAAAAAAAZIBCyZywZAwAAAAAAGSAQsmcsGQMAAAAAABkgELJnLp6pX5Ou5G8/AAAAAADAXYVAyJ4xQwgAAAAAAGSAQMiepe0hlJIopSTnb18AAAAAAMBdg0DInqUFQhIbSwMAAAAAACsCIXvm5CrJlPo9y8YAAAAAAMC/CITsmcl03dHzbCwNAAAAAABSEQjZO5e0QIgZQgAAAAAAIBWBkL3jpDEAAAAAAHADAiF75+yZ+jWRJWMAAAAAACAVgZC9Y4YQAAAAAAC4AYGQvbNuKs2x8wAAAAAAIBWBkL1zIRACAAAAAAC2CITsHUvGAAAAAADADQiE7B1LxgAAAAAAwA1yFAidPn1av//+u/X5rl279OKLL+r999/PtY4hl6QFQokEQgAAAAAAIFWOAqH//e9/2rhxoyTp3LlzatWqlXbt2qWRI0dq7NixudpB3CbrkjECIQAAAAAAkCpHgdAvv/yiJk2aSJIWLVqk2rVra/v27fr88881b9683Owfbpd1yRh7CAEAAAAAgFQ5CoSSkpLk6uoqSVq/fr0effRRSVL16tV19uzZ3Osdbh+njAEAAAAAgBvkKBCqVauW3nvvPW3ZskWRkZFq27atJOmPP/5Q8eLFs1zPxIkT1bhxY3l7e6tUqVLq2LGjDh8+fMv3LV68WNWrV5ebm5vq1Kmj1atX5+RjFA5sKg0AAAAAAG6Qo0Dorbfe0ty5c9WyZUv16NFDgYGBkqSVK1dal5Jlxffff6+BAwfqhx9+UGRkpJKSktS6dWtduXIl0/ds375dPXr0UJ8+ffTTTz+pY8eO6tixo3755ZecfBT7x7HzAAAAAADgBk45eVPLli31119/KTY2VkWLFrVe79evnzw8PLJcz7fffmvzfN68eSpVqpR+/PFHNW/ePMP3zJgxQ23bttWwYcMkSePGjVNkZKRmz56t9957Lwefxs5ZTxnLPGQDAAAAAACFS44CoWvXrskwDGsYdOrUKS1fvlw1atRQmzZtctyZmJgYSVKxYsUyLbNjxw4NGTLE5lqbNm20YsWKDMsnJCQoISHB+jw2NlZS6j5ISUlJOe5rdqW1dSfblCSTg4ucJFkSryrlDrcN3Ci/xgFwt2AMoLBjDACMA4AxkLeyc19zFAh16NBBnTt31nPPPadLly7p3nvvlbOzs/766y9NmzZN/fv3z3adFotFL774opo1a6batWtnWu7cuXMqXbq0zbXSpUvr3LlzGZafOHGixowZk+76unXrsjWbKbdERkbe0fZKxv6iIEmX/76gTey1hLvEnR4HwN2GMYDCjjEAMA4AxkDeuHo16/sH5ygQ2rt3r95++21J0pIlS1S6dGn99NNPWrp0qUaNGpWjQGjgwIH65ZdftHXr1px0KVMjRoywmVEUGxurcuXKqXXr1jKbzbna1s0kJSUpMjJSrVq1krOz8x1r1/R7SenYJJndHBUSEnLH2gUykl/jALhbMAZQ2DEGAMYBwBjIW2mrorIiR4HQ1atX5e3tLSl1pk3nzp3l4OCg++67T6dOncp2fYMGDdI333yjzZs3q2zZsjct6+vrq/Pnz9tcO3/+vHx9fTMs7+rqKldX13TXnZ2d8+WX74636576czIlX2Ow4a6RX+MPuFswBlDYMQYAxgHAGMgb2bmnOTplrEqVKlqxYoVOnz6ttWvXqnXr1pKkCxcuZGvWjWEYGjRokJYvX67vvvtOFStWvOV7mjZtqg0bNthci4yMVNOmTbP3IQoL67HznDIGAAAAAABS5SgQGjVqlIYOHaoKFSqoSZMm1jBm3bp1ql+/fpbrGThwoD777DMtWLBA3t7eOnfunM6dO6dr1/4LL3r16qURI0ZYn7/wwgv69ttvNXXqVB06dEjh4eHas2ePBg0alJOPYv+uP2XMMPK3LwAAAAAA4K6QoyVjjz32mO6//36dPXtWgYGB1usPP/ywOnXqlOV63n33XUmpx9hfLyIiQmFhYZKk6OhoOTj8l1sFBQVpwYIFeu211/R///d/CggI0IoVK266EXWh5uye+tVIkVKSJCeX/O0PAAAAAADIdzkKhKTUvXx8fX31+++/S5LKli2rJk2aZKsOIwszVjZt2pTuWteuXdW1a9dstVVoOV93klrSFQIhAAAAAACQsyVjFotFY8eOlY+Pj/z9/eXv768iRYpo3Lhxslgsud1H3A4nF8nh39yPfYQAAAAAAIByOENo5MiR+uijj/Tmm2+qWbNmkqStW7cqPDxc8fHxGj9+fK52ErfJ2UNKiCUQAgAAAAAAknIYCH3yySf68MMP9eijj1qv1a1bV/fcc48GDBhAIHS3cXZPDYQSr+R3TwAAAAAAwF0gR0vG/v77b1WvXj3d9erVq+vvv/++7U4hl3H0PAAAAAAAuE6OAqHAwEDNnj073fXZs2erbt26t90p5DJrIHQ1f/sBAAAAAADuCjlaMjZp0iS1b99e69evV9OmTSVJO3bs0OnTp7V69epc7SBygQuBEAAAAAAA+E+OZgi1aNFCv/32mzp16qRLly7p0qVL6ty5sw4cOKD58+fndh9xu5zdU7+yZAwAAAAAACiHM4QkqUyZMuk2j963b58++ugjvf/++7fdMeQilowBAAAAAIDr5GiGEAqYtEAokUAIAAAAAAAQCBUOzBACAAAAAADXIRAqDNhDCAAAAAAAXCdbewh17tz5pq9funTpdvqCvMIpYwAAAAAA4DrZCoR8fHxu+XqvXr1uq0PIAywZAwAAAAAA18lWIBQREZFX/UBeYskYAAAAAAC4DnsIFQbWU8au5G8/AAAAAADAXYFAqDCwLhljhhAAAAAAACAQKhxYMgYAAAAAAK5DIFQYuHimfk1iyRgAAAAAACAQKhyYIQQAAAAAAK5DIFQYcOw8AAAAAAC4DoFQYWA9ZYxACAAAAAAAEAgVDiwZAwAAAAAA1yEQKgyuXzJmGPnbFwAAAAAAkO8IhAoDl38DIRlScny+dgUAAAAAAOQ/AqHCwMn9v+9ZNgYAAAAAQKFHIFQYODpJji6p3ydeyd++AAAAAACAfEcgVFhY9xFihhAAAAAAAIUdgVBhcf3G0gAAAAAAoFAjECosrEfPEwgBAAAAAFDYEQgVFi7MEAIAAAAAAKkIhAoL9hACAAAAAAD/IhAqLNICoURmCAEAAAAAUNgRCBUWbCoNAAAAAAD+RSBUWFg3lWbJGAAAAAAAhR2BUGFh3VT6Sv72AwAAAAAA5DsCocKCTaUBAAAAAMC/CIQKC5aMAQAAAACAfxEIFRbOnqlfE1kyBgAAAABAYUcgVFgwQwgAAAAAAPyLQKiwsAZCHDsPAAAAAEBhRyBUWLj8u2SMQAgAAAAAgEKPQKiwYMkYAAAAAAD4F4FQYWE9dp4ZQgAAAAAAFHYEQoVFWiCUSCAEAAAAAEBhRyBUWLBkDAAAAAAA/ItAqLBgyRgAAAAAAPgXgVBh4UIgBAAAAAAAUhEIFRZpM4SS4yWLJX/7AgAAAAAA8hWBUGGRtoeQJCWzjxAAAAAAAIUZgVBh4XRdIMRJYwAAAAAAFGoEQoWFg8N/oRD7CAEAAAAAUKgRCBUmHD0PAAAAAABEIFS4uHimfk26kr/9AAAAAAAA+YpAqDBhhhAAAAAAABCBUOGSFgixqTQAAAAAAIUagVBh4py2ZIxACAAAAACAwoxAqDBhyRgAAAAAABCBUOHi4pH6lU2lAQAAAAAo1AiEChPntECIGUIAAAAAABRmBEKFCUvGAAAAAACACIQKl7RNpRNZMgYAAAAAQGFGIFSYMEMIAAAAAACIQKhwsQZCHDsPAAAAAEBhRiBUmLj8u2SMQAgAAAAAgEItXwOhzZs3KzQ0VGXKlJHJZNKKFStuWn7Tpk0ymUzpHufOnbszHS7oWDIGAAAAAACUz4HQlStXFBgYqHfeeSdb7zt8+LDOnj1rfZQqVSqPemhnrMfOM0MIAAAAAIDCzCk/G2/Xrp3atWuX7feVKlVKRYoUyf0O2bu0QCiRQAgAAAAAgMIsXwOhnKpXr54SEhJUu3ZthYeHq1mzZpmWTUhIUEJCgvV5bGysJCkpKUlJSUl53tc0aW3dyTZvZHJwkZMkI/GqkvOxHyi87oZxAOQnxgAKO8YAwDgAGAN5Kzv31WQYhpGHfckyk8mk5cuXq2PHjpmWOXz4sDZt2qRGjRopISFBH374oebPn6+dO3eqQYMGGb4nPDxcY8aMSXd9wYIF8vDwyK3uFwjF4g7/P3v3HedWfef7/3WOukbTe/GMxw1XXLCNTTEmwdSQQAghkITcZLO7gYRsNns3ZX+7NyHJ3d0sm2xugJC2WRJa6CTGYDDEYMC94TpuM+Ppvc+on/P740gaTZ+xNR6N9Xk+HnocSaP56nuOdKRz3voWrj71f+mx5fL2woemujpCCCGEEEIIIYSIob6+Pu655x46OztJSUkZ9bHTKhAazjXXXENxcTFPPPHEsH8froXQjBkzaGlpGXPjxJLf72fLli1s2LABi8VywZ53gIZDWP77I+iuPAJ/d2Rq6iASWlzsB0JMIdkHRKKTfUAI2Q+EkH1gcnV1dZGVlTWuQGhadhmLtnr1at5///0R/26z2bDZbEPut1gsU/Lmm6rnBcBhvBmUgFt2PDGlpnQ/ECIOyD4gEp3sA0LIfiCE7AOTYyLbdEpnGYuFgwcPkp+fP9XVmB5k2nkhhBBCCCGEEEIwxS2Eenp6OH36dOR2RUUFBw8eJCMjg+LiYr773e9SW1vLH/7wBwB+9rOfUVpayqJFi/B4PPz2t7/lL3/5C2+++eZUrcL0Ep5lLOiDYABM076BmBBCCCGEEEIIIc7BlCYCe/fu5dprr43c/uY3vwnAF77wBR5//HHq6+upqqqK/N3n8/EP//AP1NbW4nQ6ufTSS3nrrbcGlCFGYYkaRNvfB6YLN4aSEEIIIYQQQggh4seUBkLr169ntDGtH3/88QG3v/Wtb/Gtb31rkmt1ETPbAAXQjW5jdgmEhBBCCCGEEEKIRDTtxxASE6AoYE0yrvt7p7YuQgghhBBCCCGEmDISCCUaGVhaCCGEEEIIIYRIeBIIJRoJhIQQQgghhBBCiIQngVCisYS6jPmky5gQQgghhBBCCJGoJBBKNNJCSAghhBBCCCGESHgSCCWa8NTzMqi0EEIIIYQQQgiRsCQQSjTWcCAkLYSEEEIIIYQQQohEJYFQopEuY0IIIYQQQgghRMKTQCjRyKDSQgghhBBCCCFEwpNAKNFICyEhhBBCCCGEECLhSSCUaCKBUN/U1kMIIYQQQgghhBBTRgKhRGMNdRmTQEgIIYQQQgghhEhYEgglGukyJoQQQgghhBBCJDwJhBKNJTztvLQQEkIIIYQQQgghEpUEQokmHAj5JBASQgghhBBCCCESlQRCiUYGlRZCCCGEEEIIIRKeBEKJJtJlTMYQEkIIIYQQQgghEpUEQonGKmMICSGEEEIIIYQQiU4CoUQjg0oLIYQQQgghhBAJTwKhRCPTzgshhBBCCCGEEAlPAqFEI7OMCSGEEEIIIYQQCU8CoUQT3WVM16e2LkIIIYQQQgghhJgSEgglmnCXMT0IQf/U1kUIIYQQQgghhBBTQgKhRGNN6r/u7526egghhBBCCCGEEGLKSCCUaEwWUM3GdRlYWgghhBBCCCGESEgSCCWiyDhCEggJIYQQQgghhBCJSAKhRBSZaUy6jAkhhBBCCCGEEIlIAqFEFB5YWloICSGEEEIIIYQQCUkCoUQUPfW8EEIIIYQQQgghEo4EQonIKoGQEEIIIYQQQgiRyCQQSkTSZUwIIYQQQgghhEhoEgglIkuSsZRBpYUQQgghhBBCiIQkgVAikhZCQgghhBBCCCFEQpNAKBHJoNJCCCGEEEIIIURCk0AoEcmg0kIIIYQQQgghREKTQCgRSZcxIYQQQgghhBAioZmnugJi4oKazu6KNpq6PeQk21ldmoFJVcZfgHQZE0IIIYQQQgghEpoEQtPM5iP1PLjxGPWdnsh9+al2vnfrQm5cnD++QsKBkE8CISGEEEIIIYQQIhFJl7FpZPOReu57cv+AMAigodPDfU/uZ/OR+vEVFOkyJoGQEEIIIYQQQgiRiCQQmiaCms6DG4+hD/O38H0PbjxGUBvuEYNEuozJGEJCCCGEEEIIIUQikkBomthd0TakZVA0Hajv9LC7om3swmSWMSGEEEIIIYQQIqFJIDRNNHWPHAZN+HEyqLQQQgghhBBCCJHQJBCaJnKS7bF7nEw7L4QQQgghhBBCJDQJhKaJ1aUZ5KfaGWlyeQVjtrHVpRljF2ZJMpYyy5gQQgghhBBCCJGQJBCaJkyqwvduXQgwJBQK3/7erQsxqSNFRlFkljEhhBBCCCGEECKhSSA0jdy4OJ/HPreCvNSB3cLyUu089rkV3Lg4f3wFSZcxIYQQQgghhBAioZmnugJiYm5cnM+GhXm8fbyRv3liHwAv3XcF+WmO8RdiDXUZ8/eBroMyjlZFQgghhBBCCCGEuGhIC6FpyKQqXL8ojyWFqQBsP9M6sQLCLYTQITC+2cuEEEIIIYQQQghx8ZBAaBpbNy8LgPdONU/sH8PTzoN0GxNCCCGEEEIIIRKQBELT2NVzswF471QLmqaP/x9VE5hsxnVf7yTUTAghhBBCCCGEEPFMAqFpbEVxOklWE629Po7Vd03sn2VgaSGEEEIIIYQQImFJIDSNWc0qa2dnArDtXLuNydTzQgghhBBCCCFEwpFAaJpbN8/oNrbt5AQDIasEQkIIIYQQQgghRKKSQGiaWxcaR2jf2XZ6vYHx/2Oky5gEQkIIIYQQQgghRKKRQGiaK8l0MiPDgT+os7N8AtPPR7qMyRhCQgghhBBCCCFEopFAaJpTFCXSSui9Uy3j/8dwIOSTFkJCCCGEEEIIIUSikUDoIhCefn5C4wjJoNJCCCGEEEIIIUTCkkDoInDFnExMqkJ5Sy/VbeMMeGRQaSGEEEIIIYQQImFJIHQRSLFbWFGcBkyg25gMKi2EEEIIIYQQQiQsCYQuEhPuNiaDSgshhBBCCCGEEAlLAqGLxLp5RiD0wZkWAkFt7H+QQaWFEEIIIYQQQoiEJYHQRWJJYSppTgvdngAf1nSM/Q8yqLQQQgghhBBCCJGwJBC6SJhUhSvnZAGw7eQ4xhGKjCEkXcaEEEIIIYQQQohEI4HQRWTd3FAgdGoc4wjJLGNCCCGEEEIIIUTCmtJAaNu2bdx6660UFBSgKAqvvPLKmP/zzjvvsGLFCmw2G3PmzOHxxx+f9HpOF+FxhD6s7qCzzz/6g6XLmBBCCCGEEEIIkbCmNBDq7e1l6dKlPProo+N6fEVFBbfccgvXXnstBw8e5Bvf+AZf/vKXeeONNya5ptNDfqqDuTkuNN0YXHpU0mVMCCGEEEIIIYRIWOapfPKbbrqJm266adyP/+Uvf0lpaSk/+clPAFiwYAHvv/8+//Vf/8UNN9wwWdWcVq6em82pph62nWzm5iX5Iz/QkmQsfb0XpmJCCCGEEEIIIYSIG1MaCE3Ujh07uO666wbcd8MNN/CNb3xjxP/xer14vd7I7a6uLgD8fj9+/xjdqmIo/FyT/ZxXzk7ndx9UsO1kMz6fD0VRhn2colowA7q/j8AF3A4isV2o/UCIeCX7gEh0sg8IIfuBELIPTK6JbNdpFQg1NDSQm5s74L7c3Fy6urpwu904HI4h//Nv//ZvPPjgg0Puf/PNN3E6nZNW15Fs2bJlUsv3BcGsmKjr9PD4S6+TO3STAJDWV841gLurjS2vvTapdRJisMneD4SId7IPiEQn+4AQsh8IIfvA5OjrG/84wdMqEDoX3/3ud/nmN78Zud3V1cWMGTO4/vrrSUlJuWD18Pv9bNmyhQ0bNmCxWCb1uV5u3cv2M22oBYu4eW3J8A9qOQknvo/DrHPzzTdPan2ECLuQ+4EQ8Uj2AZHoZB8QQvYDIWQfmFzhXlHjMa0Coby8PBobGwfc19jYSEpKyrCtgwBsNhs2m23I/RaLZUrefBfieddfksP2M218cKaNL6+bM/yDHMkAKH637ITigpuq/U+IeCH7gEh0sg8IIfuBELIPTI6JbNMpnWVsotauXcvbb7894L4tW7awdu3aKapRfLp6rjH9/M7yNryB4PAPCk87H/CApl2gmgkhhBBCCCGEECIeTGkg1NPTw8GDBzl48CBgTCt/8OBBqqqqAKO717333ht5/Fe+8hXKy8v51re+RVlZGb/4xS947rnn+Pu///upqH7cmp+XTHayDbc/yL7K9uEfZIkaP8k//j6GQgghhBBCCCGEmP6mNBDau3cvy5cvZ/ny5QB885vfZPny5fyf//N/AKivr4+EQwClpaVs2rSJLVu2sHTpUn7yk5/w29/+VqacH0RRFK6emwXAu6eah3+Q2d5/3e++ALUSQgghhBBCCCFEvJjSMYTWr1+Prusj/v3xxx8f9n8OHDgwibW6OFwzL5uX9tfy3skWvnvTMA9QVTA7IOCWFkJCCCGEEEIIIUSCmVZjCInxu3KO0ULoWH0Xzd3e4R9kDXUbk0BICCGEEEIIIYRIKBIIXaSyXDYWF6YA8P7pEbqNWSQQEkIIIYQQQgghEpEEQhexdaHZxradbBn+ARaHsZQxhIQQQgghhBBCiIQigdBFLDz9/HunmtG0YcZqCrcQ8kkLISGEEEIIIYQQIpFIIHQRu6wkHafVREuPj+MNXUMfIF3GhBBCCCGEEEKIhCSB0EXMalZZOysTGKHbmHQZE0IIIYQQQgghEpIEQhe5dfP6u40NEZllrPcC1kgIIYQQQgghhBBTTQKhi1w4ENpb2U6fLzDwj5EuY9JCSAghhBBCCCGESCQSCF3kZmY6KUp34Atq7CpvG/hHGVRaCCGEEEIIIYRISBIIXeQURYm0Enr35KBuYzKotBBCCCGEEEIIkZAkEEoA6+ZmAbBt8DhCMqi0EEIIIYQQQgiRkCQQSgBrZ2dhUhXKm3upaY9qDSSDSgshhBBCCCGEEAlJAqEEkOqwsGxGGgDvnYqafl4GlRZCCCGEEEIIIRKSBEIJYt3cYaafly5jQgghhBBCCCFEQpJAKEGsm2eMI/T+qRYCQc2405JkLH3SZUwIIYQQQgghhEgkEggliEuL0kh1WOjyBDhU22ncKS2EhBBCCCGEEEKIhCSBUIIwqQpXzQnNNhaefl4CISGEEEIIIYQQIiFJIJRArp47KBCyhrqMySxjQgghhBBCCCFEQpFAKIGsm2cMLH2wuoNOt19aCAkhhBBCCCGEEAlKAqEEUpDmYE6OC02H7adboqad75vaigkhhBBCCCGEEOKCkkAowUS6jZ2KCoR8EggJIYQQQgghhBCJRAKhBBPuNrbtZDN6uMuY5oegfwprJYQQQgghhBBCiAtJAqEEc3lpBlaTSm2Hm8pOrf8PMo6QEEIIIYQQQgiRMCQQSjBOq5lVpekAvHumC5TQW0DGERJCCCGEEEIIIRKGBEIJaN3cULex060ysLQQQgghhBBCCJGAJBBKQFeHAqEdZ1r7xxGSLmNCCCGEEEIIIUTCkEBoGtm9sZw9myqG/dueTRXs3lg+rnIW5CeT5bLh9gfxKnbjTplpTAghhBBCXGCxOr4VQggxcRIITSOKqrB7Y8WQL03jy7ICRVXGV46isC40/Xx30GLcKV3GhBBCCCHEBRar41shhBATZ57qCojxW3VLKQC7N1bg7Qtw1Z1zI1+Wq28tjfx9PNbNy+alA7W0+Uxkg3QZE0IIIYQQF1z08W349rke3wohYmv3xnIUVRl2P9yzqQJd01l966wpqJmIFQmEpplVt5TS2eTmw7erObS1Gl3jnL4srwq1EGrzWcAE+HsnobZCCCGEEEKM7tJri2iq7DJaCr1aga6f2/GtuLgkShgRz+sZbsEHDKhfdGh7MYjn12CySZexaSglyxj3R9dAUeCyG0smXEaWy8aighTcWI07pIWQEEIIIYS4QDRNp+poK2/+9gj/860PqDzcCoCuG39vOttNQ3nnFNYwccRyHKdYlpUo3QljvZ6xfA1W3VLK6ltLo8Ja/aJswZco77XhSAuhaSj6Danr8MwPdvPpf1qFxWaaUDnr5mXjbpZASAghhBCJKZF/FZ4q7Q29lO1o4MTOeno7fZH7HckW3N1+UAAdKg+1UHmohYK5aVx2YwkzFmagKBfvSdlUimUrkPMpS9d1/N4gPncAb1+AwkvSmdfYx+6NFTRWdFG8KJPGyi5O7mpg1ccmHkbEcn+PZVnR3SZ1XWfpR2Zw6C817H713EKXc30NgkGN3nYv3a0euts8dIWW3a0ebE4zu1+tYPerRrl5s1JIyXLQVt9LWq4TdZoHJoncdVUCoWkm+o2ZWeBi82+O0NHYx1Pf28mn/2kVzhTruMu6em4WdR8YrY2OVtbTldnK6tIMTNN8hxZCCCEmiwQIUy+Wr0GidIeYap5eP6f3NVG2o57Giq7I/bYkM/NW56EFdY5uq42ceL337EkOba1BUaDuVAd1pzrImuFixQ0lzF6Rc8FOPuM1QIi1sU6GV9xYgt8XRA/qaEGdYFBD14zrkYumoQV1ZizIoLvVw+6NFXQ2uyldmsWJXQ1UHGyhYF4anl4/bz9+DK87YAQ/4WWfsQy3EBvs7JFWzh5pjdzet7mS0/uaSMtxkJ7nJDXHSVquk/RcJ3aXZdjwMB6Cr6BfM0KWUNASXna1urE6TOx5tZI9r1YCYLaonNzdSNXRVmxJFuzRF5cFm9OM3TXwPovVNOrreem1ReSVpnL0vdqB9Wj10NvhHXH7D9ZQ3kVD+TGjnlaVrCIX2TOSySpOJrs4mYz8JEzmgZ2RYr0PxKI8vzdIb4eXnnYPKZl2iuanJ1zXVQmEppHhUsrb/2EFf/rZAXo7vDz9/Z186jsrSctxjqu81h4vbt0IkLYcquBn+3eSn2rne7cu5MbF+ZO2HkIIEWvxfKAdz3UTExfLE4pEeW/Eej1j+Rokyq/CU3EitvKWUqqPt1G2o56Kgy0EAxpgvH4lizOZvzaPmYuz2P/m2SHb++q75mF3Wdi9sYK8WSm01PTQUt3Dm789SmpOOSuuL+GSy/MwWSZ39IvJChCWXV90XmXFWleLG2eKlfR8J7s3VkTqicLA2xN0YmcDJ3Y2RG7Xneyg7mTHmP+nqgpWpxmbw4zVYcbmNFNzoh1CYYXJrBIMaLTX99Je30vFhwP/3+Y0k5pjhENpuY5IWLTsumIgNvv7aJ8dS9YXkV2czJF3a/pb2oTCn76oVnFjCfg1OhonNhO0yaJiDwVFyZn2Ia/foa01HNpaM+L/q2aF5Ay7ccm0k5JpXK892cHx7fWoJgUtqJMzMwVVVWip6Sbg00IBUdeAcjILXGTPcJFdbARFug57YrgPjLV/rrixhJaankjg09PhpbfDS2+7N3Ld2xcYtmxdN9bhYvkOGI0EQtOI8WU98MMqf3Yqd/1/q3jxP/bh7Qvw4n/s45avXkpeaeqoZW0+Us/XnznId8w2ABx4AWjo9HDfk/t57HMrJBQaJFEO3IW4UBLlV/5YngTI59C5maym/eHb53pCEc/v21iK9YnweF+DYFDD2xvA2+fH2xcIXfyRpSd8X6+f5IyBJ04rbii+qE4EYv1eG6u8/DmpHHu/bkCXsIyCJBZckc+81XkDWrQPd3wbXa6u6dxy/1IOba3m0NYaOpvcbH2yjN2vVrDsuhksvKoAq31yTmmi32sdTW7mrc7l9N5GynY0sPCqAmYuyaK1rgeTSUU1K5jMqnHdpBi3TWpkqIfosjTNCMf2b65i76azFzx89HkC1J3soOp4G9XH2kYOHUZpLaKaFOOiKqjhdY5cjPVurw9NWqPA3JW5AwIeqyMU+EQHP6HbZos6oIXPnk0V1JS1o5oVtIDOihtLmL8mj47GPjqa+uhoCC0b3XS3e/D2BWiq7KKpsmtIvV3ptkhQEm4FklOSTG+Hl61PlqHrutFKRjOWmqZD6L7w3/TQ39B1UnMcQ0KXw+/UcPidkUMXs1WNBC7JmQ6SM4w61ZR1cPyDush6Lr6mkLkrc/D0BPD0+o1Lj7//eq8fT6/xN2+PH03TCfo1ejt9A/a9Ac9tM0UCn5TMUB0idbHjTLYOGS9nz6YKjm+vj7xPoz83bv/fK+hs6qO5qtu4VHfTXNWDzx2I3McH9cbbQFVwJBtBb/3pDtxJJv7yhzJO72lm7qoc0vOSOLW3ES2oo+tGyzNdMy6apqNrRFqj6ZoR2hTMTWP3xgqqjraSkuWg/kwn3a0eFFVh/+az7N98duQ3cdQ2caXZcKXb8PT4aanpQVGN12DPpoqL6rtgOBIITSMjHaym5yVx9/cuZ9Ojh2iu6uZPPz3A9V9eROnS7GEfH9R0Htx4DB3wEA6EjA8NHaPr9oMbj7FhYZ50H4uSKAfuQlwosdinwuMNXHJ5Hr0dXnZvrKClpoeZS7LoaOxl/xtVU/4rfyxPAuRz6Nyc63bTNR1Pr5/eTi+9nT76Or30dvhwd/lIzxv4S7or3UbtyQ4ayj/EbFExhU4OVYuKyaxiNquYQverZuM+Z4qVWcuy2L2xgvb6XhZcWUDdqQ72vlY55e/bWBptH7jsphIWryuku81D0K8R8GsE/RrBQJCAXyPg0wgGtAF/C/iD6JpO/pzUASd1rgwbp/c1cez9Ojx9AQLe4DnX+eBb1XQ0upm/No/ixZmYTNN7Hpbo1yAY0Ji7Mpdj79dxaGsNK64vZulHZxAMaqiqMq5xegaHckvWF/H248ciA0PXnzYGg7YnWZi7OpcFa/PJmuEatuzRwtjofWD1rbNYtqGYY+/XcXBLFb0dXj544TR7X6/k0vVFXHrtDA5trT6v8DfgD9Je30dzdTctNT201vTQUtMDwMldDZzc1d/a5dj7dRx7v27EssIUVcFkMvZ71aRgsZnYu+ks4KKGsxQvyiBvdiq9nV6cKdZxbf+Jhty6ptNS00PVsVaqj7dRf7oTLdif9iiqQl5pCqpZofZER6QVyLLrill+ffHQsEdhzHqGP1/D4UZ6nvOcPtMGh72RQX4V4/1RvChzwOMDviCdzW46Gvtob+yjMxQatTf24e0N0NPu7d8uUQOYN53tnnDdRmJ1mAcELSnRoUuGfdgubXs2VXD8g7oh6+lMsY5ru4WPh6IDo2Pv13FmfzOKqqBrOituKGbNbbMnNBbXcGH7cKF8el4S81bnRerS3eoZFBJ14+72G+OEAdXH2wEnrTQDcGpPE6f2NI27XoMNbqGka8aLa3dZcKXbSEqz4UoLLSO37SSl27DaTSiKMuJ7LXqdL0YSCE0jzQ8/AiaV7PvvH/K3vqf+m6ucOvsWXUXV0VZe/+Vh1t19CYvXFQ557O6KNuo7PQCRLmPhFkJghEL1nR62nmjiugW5k7My01D0h193m5esoiT6unzse/3C/7IjxHjFc4uS4Q4ojJkxKll8TSH5c9I4tbcxcnDj7vHj6fYZy9CvZO4eP0G/NqDc8gPNlB8wDjAyi1wULxx4sDgVVt1Sit8THHASUDA3FUVROPhWlREgWEyhpYrZqmK2mDBbQ7dD1y+9tghd02PWvSWe3x+xNPi9tvKmmex45QwH3qxi3upcklJt7NlUQV+nb0D409fpM34dHoeedu+AE42JOrW3iVN7jYPhtDwnKZl2PL1+7EmWcy7zfMTivaHrOj3tXtrqejFZVDKLXAP2AYB9r59l3+tj/4I7+vMYy542LzD0NQi3SDAuFuxR121JxrLmRBtn9vWfOGlBnfKDzZQfbMaRbGHuqlzmr80ne0byedV1KnjdAepPd+DzBHGmWods8/1vVrH/zSrjhkJ/eGlRQ+FmOMwcdNtijBsyuHVEuEvYgrX5lCzJHDKOyPmw2s0su66YJdcUcWJXA/vfPEtnk5s9myo58FY1WYVJkZPCscJfd7cv0hWtpbabluoe2hv6IieS0cKhRlharpNgQEMLaASD+oDl4DFYdE0noOkw6LvK+AkWqo62UXW0DTDGVMoscJGRn0RGQf/F4Ro4Ruh4Qu6+Lh/Vx1qpOtZG9fG2yIl4WHKmneKFGRQvzKRwfjqH/lI97Mmw1WGa8HdLrE6sxxtGRDNbTWQWusgsdA0pz9Pjp6OpjwNvnqX8YAuKYnx+FM5Lo/CSdBRFQVFDYVco9AqHX+H7FQUI368qVB5uoeJgC6qqoGk6l91UwppPzD6v7TWe9RxMURSsdjNWu5mULAd7NlVwZn/zkNfAbJ3Y6zmeFnzD1SUly0FKloPZK3KMx+k6fZ2+SEC0+9WKSAu0nJJkVJOCohotziJL06Db0fcroJjU0P1weGsNum68Jrf9/XKS0mwkpVkxW8Y36VIsXoPpSgKh6cSk0vLzhwEGhELNv/gFLT9/mKyvP8Atf7uEd54+wfEP6nn36RN0t3lY84lZA5Lgpm5P5HpfuIWQMvQA6q9/v5flxWlcPTebq+dmsWxGGuZRfiELajq7K9po6vaQk2y/KAeoLroknbId9Rz/oP8XodKlWay8aebUVSqBJMrJa6J0pQJYcb3Rv3vwCcWRd2s58m7tuMsxmVUcycaAii01PZGDjNaaHl748V5ySpJZsr6IOStzxn1wEAtBv0bFoRbKdtRTdTQ8GKbxuVh3qpO6U53nXHb0NkvOtNNW38u2Z0/iTLbgSLbiSLbiTLHiCN222ExDfhWM9/dHLPR2eo0m6xhBy+D32sndjZzc3ThqGY5kC84U4+DSmWojKcVKS00PZ4+0Rk4C5qzMofTSLKM1S0APtXLpb90SuX/A7f5L7YmOyPN1NPTx1uPHUVWFwvnpzFqWTenSLJJSbZOyjYYz0feGu9tHa10vbXU9xrLWuO7zDNdKZ+ixQXTIYDarkTA0EkKEr1tNkce01HTTUN6FooKuwezLsll0ZWEo5DGCHqvDPOYAxHs2VXBm39ATp7xZKXS2eHB3+Tj0lxoO/aWGzEIX89fmDen2FE987gB1p42xWmpPttNc1T3iQLGDgw50Y9ySwJDwYnyu/NScC7JtTBaVhVcVMP+KfMoPNLNvcyUt1T3G+yE07o2nx8/Vd81jT2hmpNmXZRP0a7z6yIe0VHeP2KXGlmQmqyiZrBkusotcZM1I5syBJva8WhnZXvNW5454cqhpOlpQQwsYgy9rof0+PBjz4XdqObqtFhQddIW0PCe6ptPZ7MbbG4gMoh3NkWwho8BlBET5SRRdkk7Qrw37g0r+7FTOHGgeMu6P2WaiaF4aMxZmUrwwg9QcR+Q7IZYnw7Es61zCiNHYXRaq322j/GDLkP298JJ0Vt48c0Ll7dlUQcUwZZnM6qSHLmPVK1avwXhb8I1FUZRQSGOjubo71C3F2AdmXpp1XmHLnk0VkTF/tIBO7cn2CZcX69dgOpFAaBoJh0AtP38Y96FDFP74x7Q99VQkDAr//drPzY/0hd+/+Sy97V6u/fz8yC80Ocn2SJnuQV3GounA/qoO9ld18P/ePkWyzcza2ZlcPS+bdXOzKMlMijx285F6Htx4LNLyCLioBqiuP9PJnlfLQ80bB6r4sIXn/30vV981j/zZo4/dNB3Ec+iSCCevkBgDpnY09XHsvTqO76jH0zPwV0sUo5uBw2UEPA6XNbS0RC2NoCMyq4atv7lvS3VP5KAgs8hFe0MvTWe7efv3x/nghdMsuDKfxesKSclyTMq66bpOc1U3ZdvrObmncZgBC43OuTmlKWQVJEVOvgI+jaC/v5tMwB80useErgf82ojjOYRnCBmNyWKEZs5kK46UUGCUbKF4YQa7NxqzwSzfUMzJPY3s3zzxlo9TPRuPruv0dvhoruqiqaqblqpumqq6Rx3A05lixZlqJSnVRlJqKOyJLG04U41QbXALhz2bKjh7pHXISUBGftI5d4moPdERed8WzDVm4mmr66X6mDHGx7vPnCB/diqzlmUza1n2pL1/w0b77Fh4VQFJqTbee+4kraHgZ3DrgzBVNU54MwqS8HT7qDnRETkJWHFjCatunonJ3D/Oynjt2VRBw7auIa9BZoErpi0QVn1sJjklKcbAyIdaaK3t4YMXTrP9pTPGwMhr8pi5JAuTRY359+d4y/N5AtSf7qT2ZDu1JzuMAGjQyUtqtoPCeWl43QHO7G+OvNdW3jSTlTfNjAST/V32QtfDAaY/6nZUF76zh1uoPt4e6WLk9wYvaFCmqgpzLsth9opsqo+1sW/z2UiYMnjw3DP7mof8f2q2g6wZLiMAKnKRNcNFUpptyPg1e16tHPJeg+FPiFVVQVVNMEzjvj2bKji6rZaVt5TQoB0hT10c6T68fEMx7Q19tNX30hYKV9vqe+lq8eDu9lN7op3aEwOPQy02kxFyR7W2qD/T/0NDdnEyMxZmULzA6JY2UmutWJ4Mx7KsWIURYfEafMV6PeM53Ahvt+h94Hxa4MSqNVqsX4PpRAKhaSb7/vtxH/yQ3nfe5eTlawBIvf02sr7ylchjFMU4eHCl29j65AlO7Gqgt9PLjX+7BJvDzOrSDPJT7TR0evAM02VMAfJS7Tz7t2vZcaaFbada+OB0Cx19ft481sibx4xfUosznFw1N4tkm4lfb6sYcp5yvgNUx0OLo4byTna/WkH1MaMpr6oqZBa5aK7qjhxMmcwKzVXdvPTQPuatzmXt7XNwpV+4X3FjLZ5Dl+gv2paabmYuyaa9vpcDW6Z+nJhYWnVLKcGAFhl0L6PARf2ZDpoqu8ma4aKjsY/Nvz5i/AIZ1CPLYMC4HgxPARvo/7vZqg5oGTF7RTaXXls0Rk1iSwtqVB5q5ch7tZF9CsBqN+HzBCMnFKtuKWX1x2J3ULDi+mKsTjNHttXS0+blwJtVHNhSxcwlWSy5ppAZCzImfDI6nN5OLyd3N1K2o562ut7I/a50GymZdupOdw45CZi5OHP8v5TqOlpAJ+APsu/1sxzYUhXZZrNXZJM/Ow13tw93t4++bv+A6wGvES71tHlD3WqGip4NRlUVynY2UH28LdLnPvriSjPCkujWVhd6Ot/uNg/NZ7tpquqiuaqH5qqu4UMJBdJznWSXJOPp9lN1rC2y3RZfU3jeXSGi6xiLLhHRt+f8TU6o21ILTZVd1J/upP50Jx+8cJrs4mQjHFqeTUZ+Uuj5YxNIBHxBulo9ZBcnU7I4c8gJ50hjp6Rk2ckocJFZkERGYRKZBS7Scp2YzKqxXnubhuwDZsvEfkkfbpvB5LZAmLkki5lLsvD0+jm1p5GynQ00VXZReaiFykMtxtTpK3MJajrH3qsb8vyxHrh555/OsO/1s+TPSaXq2F6azg4NgFJCAVDhvHQK56XhSrezZ1MFx0Y5cTJbTUzk6GXPpgqqj7fHxXgbiqJQvCiT4kWZNJR3sm/zWSoPtUT+braoZBQagU9WodHqJ7MwaczBqCcrQFh2fRGvvXaEFTcWo6rqgLKyiwd2S/R5AkZQVNc7ICzqaffiD4+TFXr5nSlWIwBamEHR/Ixxh3OxPBmO5xPreA2+Yi1eX4Px7gPnUl6idfOKJQmEpqG02z5B73vvRTrNd778Cn2795D6ydtJu/12LAUFACy4ogBnqo3Nvz5CTVk7L//nfj72taW40m1879aF3Pfkfjyhny8KlBbWqMfYo81HQ+V7ty6kOMNJcUYxd60qJqjpHK3r5L1TLWw72cy+s+1UtfXx9K6qEet5PgNUx7rF0UTDpeGCoJKUNsxmnVNV+pCDnzS7mw6PnZO7Gyn/sIWVN5Ww9KMzLmjXlFiJ/iDVdZ2lHy0e0q98KvR2eik/0EztyQ5QoPxAC+UHjIM9Z6oVTdNprOwipzg5Jif3E3U+J2I+T4CW6u7IoIbNVd2RGT+qj7cPaJnWUm2Md3C+zuxvpuJgCwXz0ihdanRHSc6wj/2P56Cn3RM5gYw00VegeGEGNqeZU3uaRhwscrzGOihYfWspn//RFVQeauHIuzVUH2+PnMylZjtYfE0h89fmT3i8lmBAozLUJezs0bbIAaDJojJrWTbz1+bRUN7FnlfP/wBIURRMFoX9b54dEIJGWkYUulhz2/DjFvi9wVA45AsN6hgKi7r6b9eU9b/PNE2nq9lNV7N71DrZkyyRfvpJaTYK5hmzfXQ09rH4miLKdtRz7P06Fl5dQMniTJqrulFUgKHjMgCR65esycPnDrB7YwV+T5CFVxew60/lnN7XREq2g0Nba4Z0hzC2EaTnJ5ETmuI2pziZzCIXVrvZ2E67zv9XxFieBIz3YPayG2fS3eah4kNjfKy6Ux2RwTp3/bmc9Dwns5Zl4+n1c3QcgYSm6fR2eOluddPZ7KGr1U1Xi5vuFg+dLe7hW1VFrZYz1RoKfULhT4GL9DzniCfXsT4JmKoWCPYkC0vWF7FkfRFt9b2c2FnPiZ0N9Hb6OBzq4hqeKt3vCXLFHXPG1SJT1/VIi5vo1oHFCzPpbvWwe2MFbfW9pGQ5jOfrMELd8MDNYIRx4fCnYF76kM/zyQ4yz7e8WMqblUpOSTKVh1oiY0Itv6HknH5omKwAwe/vD6/HKstqN5M7M4XcmSkD7ve5A3zw4mmOvV8XWc9zCbkTSaIEX/HqXPeB8ZQXLR5CuelE0fWRehVfnLq6ukhNTaWzs5OUlJSx/yFG/H4/r732GjfffDMWy/kNEBkeMwizGQIBFKsV3Rc+yVJIuuIK0u74JK7rrkO1Wmmu6mbjIx/i7vLhSrfxsQeWklng4sAbv2fmjn8mnf4R2RvJpG7t91h+wxdGrUOPN8Cu8lae21vNG0dHH3sB4LKSdBYVpJCXaic/1U5eisNYptqxDwpNNh+p574n9w9pcRQ+xZ9oi6OJhEsN5Z3sebWCqlAQpKgK89fmsfKmmex/+M8cbcxmUW4z6x+8K/I/73zvWY42ZjMro52+tJLIYIYpWXauunMuMy/NmtBo/ufifH8VDne1aK3robW2J9JNoa+r/6QguySZ5RuKKZibds7jWEx0P+hqcVN+sJkz+5tpqOgcdfrTMEeKlZLFmcxcksmMBRmTNhXtYCMd9A++3+8L0lLdQ9PZLqN1w9ku2hv7hl235Ew73W0e0I0T5VW3lBqzFkXN9KGalMh90VPdqibVmNUkdN+x7XUceac20jLC7rIM6aqVNcNF6aVZlC7NHnE2mPHSNZ3q420c2VZL5eHWyJeyI9nCgisKWHhVASd3N4xrm43HRPeB9oZejmyrpWx7fWSME7NVZd7qPJasL6T8QPOo5fW0ezFZVE7tbsTT278d82alMH9tPnMuy8HmtAyp2+B9YKLdSMb7PpuowbPBXPqRGcxenm0MsNzhpafDWPZffAQD5zbGSKyoqkJ6gRH+ZIcumUUuLNahQfxkbbfzda6f3e5uHxWHWig/0Ez18bYBswVZHSZ87iALrshnyfoi9r9xltP7msguScaRZKGzxU13m2fguDHDsNhMpGQ5CAY1Ohr6omapKWHt7RMbMDWW+0C80TSdmuNtlO1soPxg88BB7hVAN7olJaXZCPiCkS6iwejr5zBeT3KmPTIQbsHcNFIyR+9COFXd2abCaK3u4uVEPRbnBdNhPYUYSSzPjcVQE8k8JBC6QGL1po8eQDr7/vsjt5Ovv55gVxd9O3dGHmtKTSXl1ltJu+OT+LJnsvHhD+lo7MPqMHPzTd0Ubv8sOvqAoR11FOP2p/8ACz8+Zn3+dLCWv/vjwXNeH4B0p4W8VCMgykmx8eqH9fR4B4+5YQh3Z3v/2x8ZV4uj8YZLDeWd7NlUEZnlIRwEXXbjTFKzjYOs3RvL6du7h9xnvz9k+zfe9X2cK1ex6mOlnNzdyPaXTkd+YZ2xMIOr7pwbadI/GSZysuNzB2it6zWCn1pj8M/Wuh68vcNv8+Gk5zkpnJdOQag5+nibJI9nP2hv6OVMaJao8ECwYbmlKcxank1vh5dDf6mJnLyWLstCVRSqjrfhjxrAVDUpFMxNY+aSLEqWZJKW44z8bTIOZgdv710by9m7qZKSxZk4Uqw0n+2ira532ME9Xek2souTySlJIackmeySZI68WzvgJP18T/YHHzReem0Rrgw7lYdaqD/dMaBernQbpZdmMXNpFoXz0iPjDoy13XyeAA6XlaPv1dLV0h/CFsxNY/G6QmYty8ZkGV9ZF+KEwucJcHJ3I0feraG1dmA3r552L6tumRmpQ1+Xj7cfPxYJjMOSUq1csiaf+WvzSM8bfT8/3++CC/G+HW+LBm9fYPiwqNM3oKtGcqYdXddBNxq26rpuvNd0HV0DndDfNH3Q30Pd5KLCjoVXFfSHP4VJ426FGQ/vtcnidQc4e8QIh84eaSXgG1+4oKoKrgxbZCaYlCz7gOv2JAt7X6uM+QnnxXwS4HUHOL23kbIdDTSUd479D8NQVAWzRR0yw2C4ZaiiKnzuB2smfQyp6Spew9/Bznc/mC7rKcRILubvgngwkcxDuoxNI4PDIBg40HTW1x8g/0c/pPOll+h4+RUC9fW0P/kk7U8+iX3hQj7y8TvY7phNQ2Uvr7xopcj7bT4x898HPIeCzjtnPof+0Ltc+9+3gDr6wXb0ANWj+dKVM3FYTdR3emjo9FDf6aG+043Hr9He56e9z8/x+q4xy9GB+k4Pd/96B3Nyk8lwWklPspKZZCwznFYyXMbSalZ5+YljrPGa2WEPDClnrcfM5v85hq+kMdI1TFEV5q/J47Kb+oOgsNW3zkK/oYg67SgtP3+Y5kceRdE0Mh94gAVf7W8xdMnleZQuzWLf62c5+HYV1cfaePaHu1myvohVH5sZaTUQFouxkoZrph2ebWL2imwCfo1Nj35Ia22v0eJkGIpiTKOaUeAiszCJ9oZeTu1pirQoyStNIRDQaKkxpmVtb+jjyDajiXx6fhJFoWbqhfPScCT3B0RjnYhpms7s5dmc2W9M7xs99oqiQP6cNGavMAZRDY+BcOgvNcOeoGz4q0XUne7g7OFWKg+30NnkpqasnZqydt5//hRpuU5KlmQyc3HmkO0VXafxjvXg9wXp6zS63fR1ebEnWSiYmzZgrB6As0daB/yfI8VKbkky2eHwpzh5SKurCzVl6+pbS7n9H1bg7vFx9nArFYdaqDrWRk+7l8Pv1nL43VqsdhPFizMpXZqFFtTZt6lyQDm6rrP1yTKOf1Afme0HjKme56/JY9HVhWQUDA1K4qG5tdVuZvG6QhZdXUD96U4Ov1tD+f7myPThezZVUlPWjt1lofJQSyQ0M5lVSpdlsWBtPkULMsacxShW4mWATUVRjAG9kyxDpvbds6mCykMtkSBzwRX55/x6Dm655Eq3sXhd4YTLiYf32mSxOczMW5XHvFV5BHxBqo61UX6wOTIeFMDcVbkDA59MO650G+ooM4fGc5egeGVzmFl0dSF9XT4ayjsjrapmLc9i7so8Y7Y0a3gWNVNkWnez1RT5m2mY12TwYPkndjXIth9BonQhSZT1FEJMPgmEppOgNiAMCovcDmpYi4rI/vrXyfrqV+ndvoOOl16k56238Rw7hufYMebbk1DWfJV6pYQa++W8WPUgn5zxPcI9Q94581mOJt3Bot4X4Ox2KL161CqtLs3gKxVv0+XVeHr+hiF/v6dsCyk2lX/8158MCTl0XafT7R8QEr17oonufa3oCkNCHDBCHEWH7ZXt7K4cOuNXNItJYaXXxFUeI4CJLm9Dn5llPuP+6mNtIwZBgdZW3AcP4j5wgL4DB+k9fBg11D1P0TR04E+v7aZ07kquu3515P+sdjNrb5/Ngivz+eCF01QeauHDv1Rzck8Dl398FguuLEBVlZiMlaTrOlX/9StsPgczFlw6JIw4s3/orBpJaTYyQwN+ZhaGxn/Id0Z+bd+zqWLYcV1W31rKJ76xnLpTHZHZTFpremiv76W9vjcyhkJGQZIxlsElaQQDGvvfMMaaWnZ9UaTOW58s49j7ddicZvaGAgYwfrUump/OrOXZlC7NHtD6aLwnKDPmG62yOhr7qDzcQuXhVupPddDR2EdHYx8fvlWN1W4iPd+YgtrvDXLFJ/vHelh+fTGlS7OoOtpKb6cR9hihj68/AOr0jjCd8kB2l4WcEqPlT7gFUFKaddTuWFMxZavDZWX+2nzmr80n4A9SU9ZOxaEWKj9soa/Lx+m9TZze24SqKqRkGbMYurv9pOc52bOpIjKYr65BTkkyi9YVMndlLhbb9BhHS1GM1mQFc9Po7fRy9L06jr5XS1+nb8CMLUlpNlbePJM5l+VMeLyheDTZU92ezyCzsSwrUZitJmYty6a11mhNEg4Q0vOcE95mcsJ5bkZ632YVJce0hSfIfjCcizn8jZYo6ymEmHzSZewCmcpmcYH2dro2vkrHiy/iPXECHYVTc+6gpuhaADJ8p7lrxrfZVn43R5M+xaLeF1g/+ym4479hyafGLH/H9/6DtGf/hyfm3zAgFLqnbAufL3uDjru+yNoHvzWuuu4408rPH97LVR4L79v9A0KctR5z5P5LPlJEqsNCe5+Ptl4f7X0+WnuMZXuvH1/QaKLw2eNvkOSaT2ryfN63+6kwB7mlz0qGZvwCp+saR2wapzJVkjOsLPC2sqC1khn1p8moPIG1oXZIHT0mC/agHw0FNdQZLYiC++qPcul3voFt9tCxFaqOtvL+86dobzAGCs4uTsadpLK5omVI8KUAazxmbl2Szz1/demAv/l9Qdrre2mpMcb6aa3tobWmd8AYJtHMapCk9koySzMouv7ySPgz2onsO//yR44254zYDHlRdhPrf/iZ/u3R46fuVAc1J9upO9k+oNtNmCPZirvbR+myTJrb6/E2OgZ07TJZVIoXZjB7eTYzL80a0ooq7Hy6fXjdAaqPtXH2SAtnj7SOOEVyeMyH8TJZVGOa6hQrzhQbPe0ems52R34ZPpdm2/HUvUXXdBrPdlHxoTEAc3QLrmiqyQhVF60rJKfkwn22TqZgUKPiYAtv/PYI6MY63vfotedV5sXcRDqWXRikO8S5i/dxRWQfOL8WnudTnogfF/N+EEvNDz8CJnXIj+Fg9JwgqJH9wNemoGbifMk+MLmky5gYwJyeTsa9nyf985/Dc/QYnY8/wiVvPIfd087pOZ+kzTqHxxpegCSF7PYPSes+RUVzIbYzj6HOOYSamoHqTEJ1OvsvSf3XL/vSXez39PH5Pz0L6Dw9/3ruPocwCIwWR0vr36DLPIermI9dg6PWIMt8Zpb6zPS6q7msp5Fbsi9FC2gEzQ4Cdo1gav/MHAG/htcToK7VTVv6Ggr62mkO9HGVx8lVoVnVdF0jv2EXtb5aMmwW/tfBsyxoO0tSYGh3qsrkXI5nzOR45kxmddRyW/n7/GH+DTwzfwNfO/gCt1TuxISO6723OPP+23Rcfg3Nt92DVlKKSVWxqAomVSHvzlLsh9to3N4YGRvnKixYdXjX0R8KrQkFXx+UNXP5wWba63poqTHG/Ols6ht2/BlFVbApfZg62+h1FRJEx4TCjDOvkb4mn7UP/vW4XwNdUSmt2EhJ5Vx2nLkr0pVtduXrNFecQs9ZO+DxdpeFWcuNqY8B3D0+6k52UHvSaEXUVteLu9toVVVxsBWwAsYU47OWZzN7eQ7Fi8Y3+PP5/CJmc5iZc1kOcy7LQdd0ms52U3nYCIcGjFUUmh7PkWyEPEkpobAn1RZahsMf4z6r3RRp7bNnUwXlB5vP+5fcePrlT1EV8kpTyStNZe1ts+ls7qPiwxYqPmyh7lRH5DFfeuiqEYO86cpkUmlv6DXCoFBLiz2bKuQEbASJMp1vPJNuXlMr1u9b2Q/EdBTTEMekGhPpwIDyoofREENJkCYmQgKhBKIoCo7Fi3D8xyPk5Cwm/9gLJNc2c6Dgbwj3GWtOX0pz+lIArN4OXEfrSOqtJ6n3Q1y9dST1NmDSBk5HWz7zZhRdIxX4fNmbfK7sTRTAnJdHb5OTt7/5O5YUd2HOzMKcmYEpI9NYZmYSsCTR1eals9mY8raz2U1+zjr83QE8us5Kn4WVvv6TzCTHDGAGf/n98XGts8OeR7s9b+AbXddYu/sH2N3NLBz0+KDNTlvxXKrz51CWOZN9rkLKPSoev8bdZVsGhEEAjyz7FK32VO4te4MqVw7FPU2k73yH9J3v8F7BpTx9yXVUphYMeA6n3QiCLvWZUFBY7bWQG1Q5YQmy2GeiIGgigM7CboXNvzw8ZJ0sTjPphUnkFaeQXeQis9DFntZONv56J4tdhZRWbGTm2c1UltxIRemt1BzZieXLX6UwPxM1KRTsJSWFLqHrzv7rV92/jr2BE7Q+/DB/3nKSZ+Zv4O6yLdxb9gbpd32RtQ9+evRt7rIye0UOs1fkAMZAvK/9pYJtH9QwrxsUFILoPF2o8y9rMpmzOGdcr+WA1+k8x11SVIXc0hRyS1NQTQrNVd2oqoKm6SzfUMya22aNOrbGcBLlRCw128my64rxe4PUneqIBCWHttZcFOsXTbpqTIxM5zv1YhkgJMoJRSzXM9bvW9kPxLQUwxAneqxUdJ2sv/1bWn796yFjqo5XLPf3uP6MlCBNTIAEQolINaF+7Mek9t2LL5gFioKiBdFVE0m+enSzhT41C58tjTZbGm0ZUbGJruPUu3H5W3C5G0nqriVgTaMm90oASs9ujszgdcq2jAp9IcVlWzjzwWHcjmz6HFm47dm4HVm4HVkELK6h9SMF7KGZwHTdCKt0naS+erBZcCQ7ULUAquZHDfpQAz7UgBfV70Hxu1G8blRvn3HR/KhBPy2Zi2nKXYmiBdBVM405l1F6djOBnDwyVq/EsXwZzuXLsc2bh2IeuFvous6ze6o5/H/fGBAGhYVvq7pG6/K13HTgdead2MPVdYe4uu4Qx2av4O1VH6M6cwYBTScQ1Djo9vNhu5ePui0UBk2UBIxLmDkUmrSqOs0mjWZTeKnRqwDN3ViaarhiaxVXNB0n3ZPO4qKPUlqxkdKzmyOvBUBF6a00VWwk6f3nx/0WSQst7y17g8+XvYECfJg1mxfPqvz1B8e4/srBUdrItlW18o87T7PGb+YSLATQMaNQ3OTnvif3R2Z6G69YjLsUFj7Bz78yD9OSVIKHOzmwpQqL3TThg+2enbtZlAsrbrqWHWda+8Oqm2bSu3s3PTubYQoO4CfjgCURgpJECfjExSWmAUKinFAkyHrG+rsgrk+GYyhR1jOWBoQ4odvh/Snzb/+G1I9/As/x4wS7utG6u/qX3T2R28HuLrSuboLd3WhdXSg2Gy0PP0LLw48AYM7JwXv8OA3/91+x5OVhyc/DnJdvLLOzhxzLR8Ryf4/jz47o1yDQ0Ejml/+Kzj/9mZZHH51wkJYo+0CirOdwJBBKVAs/zjs9/5ejSQsiYwYZA0p/ikWu46z94Sdpr+uh9cgh2g4forUpQFugGLeWRp+SQp8thSbbrEhyoCih4CF7Bemdp2hLm09fUh6KolNVvIGq4qEDTodZfV043M043C3GxWNcb868lKqS61E0P7pqIadpXyTkmIiKkptoyl0ZCUvKS26iovRWuj5+F5/56pox/19RFEoyk/jOghtGfEw4FHrm82tY+/278Zw8Sesvf0nX65tZeGY/C8/sx3XttWTdfz+OJYvZcaaVu3+zk6ddPhb4TdzSZ0FBQUPnNaefZpNGm6rzmctnUGgzY+32YuvxkdncStGpAyyqPMRlTSdwBoyZkMpn3oyjchOWlr0ABBQVs65R7a+jwV1Ba+4C3nPoOAJeHEEvzoCXJM2PK+jFGfThCHixB7zYfR4sPg8mvX/a4nDAt7TlDEtbzsDO/+ZAehY9JXPpLp1LT8lcekvmEkhKJnqcZEVR0HSd+p/9nL+2z4uM47TDHoiMB7Wk+QwHf/g2G54ZOuj4cDYfqee+J/cPGeKnodMz4XApPFbSh6k6Dx2tgKPG/den2mFjBb07dw0YK2ksi/Nbafn5w/z4xB5+PbN/nJm/qdzK7Qc3ndOBQSxmoIv1ActwY0xFByUT2W7hL9+Mr9w3ZD3bfvnYOX35xmSbIS0thIg+odA9HtI+/Wk6X34lLk4oYlneaCevF9N6xvzkNU5PhmP+eZso6xkjmtuN9+RJzBmZ2BcvpuXnD0e2H0Drr35N669+fd7PE2hqonvLW8P/0WTCnJ2NJS8Pc34elnBQlJeH6+qr0Xr7xtzfdV2HQADd7zcu4euBALrPjx7w47rmGgINDbT8/GH81dWk3303XZvfoO13v7ugnx26rhNoasJ7+jS+M+V4y8/gO30Gb3k5AB3PPUfHc88BoCa76Nuxk7qqaixFRViKCrEWFmIpKsKck4NiGmYikBjuAwn1GTmNSCCUoN753rMc7VnAopxm1n/xbuj5COtdufA/dRxtWgD//iLrH7yLvNnr4BProKMKdv+Gvj0v0daTRltgBm36bNqsK2jty8DnMU6Oel2F9Lr6pwTWdQVFVUjOsJGS5SA120FKdmiZbiXJ7EHt7STYmkOgtY1AawvB1jaO1CRT5Z5NacWrlJ59nYpQiGNftIiFWU2h8YtC3ZyixzcKj20U6hq1//02Kl6vZlFOM7nvbEYzW5h19nWSLr+co4ezxz0eyOrSDPJT7TR0eoYdb1gB8lKNk08A+7x5FP70p2Tdfz8tv/wVXa+9Rs/WrfRs3UrSNetY8pX7IrOzVcy8CQUl0nImTVNYXv4mKTaV//2v/0mwopzurR/Qs/Ud3AcPgtYf1ujpGVTNW8ET5DC3vZp7elsirZjC3bz+kJLPE/M3YCuegS+oDTsG0QC6jkUL8LmyN/n0qa2RcOlMSgEWLUBRTzP29hbs7S1kHdwR+be6pExOpc3gVFoRJ9OKOJNWRJ/Fzt+EwqDO7jJ2pJUAxoxvS5rPhO6HJd/bTF6qg4wkK5kuK5kuG1lJxjJ8X7rTyv4fPMRnfNqQVlo6xiDmEwmXWvsClFZspMahQ1R5WSc2UupWaE26bMwyou1bdzvb3jzJ5w9uotsTiLwGt5e9wRPzb2Ddutu5cQLlxaolVPTJTnWbm+qPfYYZr/4Rx5O/Pafm1hMdY2pUoS/f32wrj0mIFsvWY6WVr4FJJagNDatmnn0dghow8YOMtL/uH8/rYjvIiNcTlHgWb9ssfGLhOXYMz/HjeI4dQ01OpvXXv6H1178BQHW56P1gO76KSiyFBVgKC7EUFGAtLMRcUIBqtQ4tONb7wDkcuGtuN4HWNoJtrQRaWwm2tRNoayXY2kagrRVLcbFx8vrwI6Dr2ObPR/d4aXvyKcw52cYJZk4Opuzs4dfxHOsV6/UcyYDgKxgk4957af3d/9D6q1+Red99ZP7VX6H7fKCqYDKNOhPmkPKIoyAtxq9B9v33g26sp9bVTdbXvkrb7/9Ay8MX13qeS90CbW14jh3HW3Ycz/EyPMeP46usHHCcOhzFbseUnIyanGwsU1JCy2RMySmRpSml/zGdr26i/cknUSwWdL+flI/dgmPZcgIN9fjrG/A3NBCor8ff1ASBAIGGBgINDXBwhEqo6oCwSnE4aHv897T+5rfogQD4R5h4ZASdL79C58uvRMrueOEFet//AEtertFyKS8Pc14ulvx8zLm5mLOyUNSooQnG8XrqwSD+2lq8p8/gKz+D90w53jNn8JWXo/X0jKueWncPfXv2wJ49Q/9osWDJz8daVIilsMj4bC8qwnXFFWh9Y4do4xIH3wXD0QMB0u+6i2Cr8eOu9/QZXFddhb+h/py7J04nEgglKF2DRbnNrH/wrgH3r/8B8L1n0Qd/lqcVw/U/xLn+OzgPPUvRrl9B8+sANJ10UXuqGNPCVN5P/YfQcMZBru78Kb6yXoo+vpzcB//fKLXJG3Brz6YKjp+qYFFuM7nvvI5isVB69nWcay7naOMskpd+dPxN39VOo5xnvx/ZmZt/8Qv4+ffhru+jazPHVYxJVfjerQu578n9QyahCh8yfe/WhUOCCNucORT+50Nk3X8/rb/6FZ0bN9L77jZ6393GzXmF1NiWUBg1o1q45UypWyFfq6TyxhvxV1cPLHP+fFzXrif52muxL15MZ0U7pf/wQ+45+faALm3h5b1lbwDw8Z/8C2tmZeD2B+n1Bun1Buj1BejzBenxBujzBnn/dDPP7K7mU6fe4dOntg4Nl+bfwJ9mX80tjm4WdteQVVdOdm05qW2NFPS2UtDbyjW1BwHQUWhOz+XwjFuwNu3k9mNP4O6+jicW3hgJSl6+7AGOZM2mzx+gvKWX8pbhZ7AKu9unRdYnOhQKD2L+h/k38MX/2U1RhhOrScVmUbGZVGwWE1aTitWsYjOrmBV4KCmVm60e7i17hzRvN1tnXMaNlTu5oWoPfylawbHuBi5/4RUsWgBTMIAS8IPPj+73Gb8O+X3oPh+630/Q66P2QBXFXh9VrmzuLXuDz5W9iYrO9vxFHMucyZGn3uW6792O2W4b8/2241/+jW2HG6kfFHw1dHrY9s8/JnVJLmt/+N1Rywj29OKvrcVfW8vJHp3W7FLmPvlb5jz5W1SgNjWPnkMnCf7wRwPHlRpujKmo+9c/eCc7v185oTGmIr+0BQLowSC63w+BAAcXXcXu2Qf55MFNqJ0dvDTnGq6r2sPtJ7ZMOESLxTYbIEZhla7rZHz2swTb2mn5+cPUHjhCY0YRh9/ZgeP1P0kLhGkonrfZROqmaxr+6upQ8HM8EgIFW1tHfQ6tpwf3vn249+0b9u/m7OxISGQpLMRSWIhjyRLSP/c546Q6qEHxDNp++SvaxmhtpGta5Bd5Av7Ir/WpH/sYwbY2oztEYyPJG66n47ln6X5zC47LLsNfW0v1V+4j0NZGsLWVQHs7el/f+DZi6FcTb1kZ3rKyYR9iSk/HnJ2NOScndDECI9vcuaR9+s5Q6GJs63M+cWLs0CXrb/7GWMeODoIdncayM7zsGHTbWGKx0PLoL2h59BeR52l97DFaH3tsaAVUFVTVOHENX1eUAfcpDseAIM06Zw7Blhaaf/4wpowMTOlpmDMyjOtp6ZjT01AGB2qTFXwNs82y778fPRAwtkl7O4G2doLtbaHrbQRDtwPt7cb1tjYCHR0AtD3+OG2PP25smpQUet97H+/xMszZWZiysjBnZWHOysacHbqemTlwXWN4Mpx1333owaCxT3X3kP7Zz9L+7LO0/eY3ZD1wDievY7wG6fd+nq7NbxifF2XH8R4vI9DUNHxRWVnYFyxA6+szPifMZggEyPjyl8n++gMjB6ojaP7FL2h/8skBx/EtP38Y66xZ5Pzv/z3gsXowSKClNSooqicQCozC1wPNzUNCK93tRne7R6+IxYJisaCYzQOXFosRhIV/cdU0AnX1BOrqGbFEsxlLTg7m/HwsubmY8/NIWrcu8pmWfs9nafnlL+l+/XVsc+fS/eYWWn/1a3Svd/jyTCasxcXY5szGOms2ttmzsM6eTfdbb9H62C8jQVrqnZ8iafXl+Gtr8NfW4qupwV9Ti7++Hvx+/FVV+KuqRqzz4H3dX1VN/YMPojqcqHY7qtOBYnegOhyh63bjbw47isNB6q23RsKlYCAAJSXj+i4YybD7+6O/oOVh4z3ruuIKurduJdje0b+ft7eHbvfv31pn54Byu197je7XXgO46MMgkGnnL9jzXnRT6+k6lG+FHY/R/PIOUHQqZ97E7p57UPGjYWG162lmVm4GazLZTx4BdZhmiMPYvbGcvr17hoQ4LT9/mMa7vo9z5apxT7k90oHYuR6gnW8LBN/Zs7T86td0/ulPVBRtoKL0VkorNnJaa+FAzlzuPLkVMpZF7i89uxnFYsG5Zo0RAq1fj6Vg4CDVQU3nobv/gS6vxtPzh3bNu6dsCyk2lX8cR8uZHWda+fM//DAS/gwOXcL3f/wn/8La2Zn9dejowHPsGO4jR/EcPoz76BECdfXDPkdoEi96zHY67Ml4VQv52SlYkxz4VAte1YRHsdCHiV7FRI+m0q2ptAYU+nQTS1pOc3ljGe8VLGFn3mKurjvImobjHMyazem0IhwBH7ZwN7igD3tg4PXwUp3I3PIxoisKvrQM/Jm5BHNy0XPyUPLzUfMKMBcUYCsswJLk5LmvP8gdH24a8TV4edkt/ONvvk+wvi4U+tThr6mJBED+2lqCg77cYrYOJhM9qhVF13EFPANeT4/ZRrpNxYLWHwAFAhAMTug5ui12ylML6UrL5rabVmGb0f9LlTk7e+Cvahj7wI/v+UduPzj6Nvv20w+Nu/vY5iP1bPvnH0eCxujg6+lLrmPdN77EVVlmo6VBqIXBwGXoRLStDQKBEZ8nmJxC0swSrDOKsMwoNpZFM7DOKMKclzek+XZkHIYHHuDMjVEttDY/S+u5/GJ9nuXpfj9aby/Bnh60nh7anniSzhdfJPmGG0i58QZ6t++g4/nnyfra18j+2lfHX684Dr5i/b0y+P/OJ0AYsW6PPELLI4/i2nAd1oICPEeP4SkrG/5XZVXFNnsWtgULsC9ciPfkKTpfeilyQpF2550krV2Dr7YWf13UZ1Bd3dgnVCHhzw1TRgam5OT+7hjRXTP8/gl/doxFsVoxZWYaAUVmBuaMTEwZGZgzM+g7cJCet96KnLw6r7gC26xZBJqa+i/NzUa9Jkh1uTClpIDZbHx+mUwDlyPeb0JRTfiqqvCVl0fGVFRTUkDX0bq7x37yOKQmJxuhWnp6KDRKx3e2Eve+/biuu46UG26g+8036d6yBddHP4Jr3TWgBdGD2tBlMDDs/e79+41W1aoKmoY5Px/VbifY1kawq4uxm0vHhik1FVN2OCjKxl9Tg/vAAZKu+yins7OZ3dBA39Z3cK5di+PSS9HcfehuD5rbjeZ2o7v70PrcUbf7r4+4f5jNUT/kOAdMHBLdij56aUpKonvrO3Rt3Ejqpz6Fc9lS2p97Hs+hQ5F9fwhFwVpSgm3BfOzzF2BfuAD7/PmYs7Nj9rkW689bML63mn7yUyPcC+3vaffcQ8bnPodiHRj0hK9jNo/Yai5cl/B2yvjSF0m5/nojhKo3Wir5G6KWwwRS46XYbFhLS7HNmoV1zmxss2YbIVBx8ZCgdSKvgR4MEmhs7A+Iamvx19Tgq63BX1tntLaahH0m/F2A2WwEhapqfM5Fhc9jXlcUI/Bubz+/yiiKsb+mp0cCPsViYf7hQ+e/olNgIpmHBEIXyEUXCIVVvAe//xh7eu5kd889rHY9zSrX80Nuc+0/wfLPQ0rBmEVGPrAe+BrZN18KPY3gyqX5tUO0PPzIhD78J6M5fizGKPFVV/Pef72J9/gxSiteG/L3sws+iaWklFW3lOC64grUpKRRywuPrQPDt14a79g6sQyXAq2t9B0+wiO/3Eh+QwXz2qvJ8MbfwavHZMEW9EdaflWk5ONXzfhNZgKKCb/JbNxWTfhVM4HQcqTry5pPsrbhGEFFwaTr1CZloikqOX3t2LSRg4GwDmsSTc50bEEfJd1N7M6Zz968+VxTc5BFbZW02FOwaAFSfWP/2u1xuKi1pVHvSCfd282itspIF8CduQs4lllKKn5W5dqxeD2YvW5M4aXHjSm89LhRfSP8KnWOdBQCqkpQUQkoJpICHsazFwVMZjqSM2lPyaItOZO2lCxq7WkcCSZxRf1hPn3qnWFbtj0zfwPr52UxK81Giu4jOegjWTPG0HIGvDgCHuw+D1afsf6v7jyD3tfLgrazzOqqRwNUwKeasGoTP0nttjjotLko6GlGJeogaDQWC5aCfKwzirHMKMJaNAPLjCKOv/o2KW/+ech6dtz1RdY++K2B2znUIkv3+QZcNF+opZvPx5Hf/IHkrZvZWrScPbkLWFd7gDUNx/EsuJT8FUvQenoigU/4EuztRevpQfd4Rqj8IGYzltxQc/n8fCz5+VgK8jHn5WHJL8BSkI8pOTny8MkKvmId4mTefz8Zd3+Glt/+lvbf/4G0O+8k5eab0Nye0Imd2ziZ84RuR1+P+puv6izB5pZI+ab0dMy5uUN+hR5ysQ68jcWCe/8B+nbtIunKK7EUFdGzdeuIv+QrFgu2Sy7BvmAB9kULsS9YgG3ePFSHY9jtM+oJha4TbG83wqFwOB0OjEJLrXf0VqBjUpQh2yDQ3Bz5W8ott2DKSDeCnswMzJmZxrbMzMSUkYma5Bz2pG6866nrOsGODgJNzZGAqD8saiLQ1Iy/uYlAc8uEu5ycDzU5GVNamnFJTR26TO+/3fnqJtr/8IfIyWvm/feR9eUvG+Oi6RoEg0arTk0DTUMPLdE04/5g0Lgv9Ji2p5+h4+mnIyfWSevW4Vi8KKq1TTuB9tD1jo5zPhGeDKbUVCOQCrdkSjeumzPSMaWnY0rPMN5P6em0v/ACrb94rL+lxac+hevqqwm0NBNoaSHY0kKguYVAS/9ltB8DphvFasU2bx72BfONsHi+8Vlhcg09Po3l5+1kHMdPZgg/nrL0QIBAc3NUSNRotGhqaMTfUI/nw1AAoSik3nZbqNXPLGyzZ2MpLBx+nJ8x6jXW/WPRfT4a//M/af/DE2AyQTBI0jXXkLRq5cDvuHCY6XEP+r4L3+8xfji4APGD6nQa+3Fk/07HlNZ/OxJKhx+TkoJiMg0J+KZrCyEJhEYhgVCMHX6BPb/fPDD8CRkSCgEkF0DRZVB4GRSuhILlYBs401jzw49A60myU7ZAV13/H1IKaO7aAJnzLppxKPy1tbT85jd0/PFZ4w5VZebTT2G/9NIhrSDGEqvxU2IVLg0uL9yty6+YsOhBNs1cwztFK/jf60u4rMCF7vGgeX3oXi+6N3Td40H3edG8PjSPh9f3nSXo8WAN+lnVWIaKjobC1qLleMw2TE4H96yfjzkpCdXpQHU6UZxOo7mq0xm5b3+Tl//1x8N4TRY+c+Jt7i17A79qwqIFB7QweerLl7OiOB1fQMMbDBrLgIYvfAlqeP0ah2ra+Y83Tg4JIAbcvuQ6biqyUeDtwNbahLOtGVdHC8mdzaR1tZLe3YrDP86T65Aui5NGZzqNzgwanek0hZaNzgyanOn0WewAo9drmOBvOKquYQ8YA5LbAz5uO7ONWyp3RgKm10ou57XStQQVEwHVRFBRCapG2BNU1aj7jdua0v/+Dtcn/Bq8XrKaw1mzye1rJ6+3jdw+45Lj7hgw4Plw/IqKRdfQUFDRabe58KkWY0D1gBeLHpsWBz7VTF9SCv7kVPzJaQRS0tBS0yA9AzU9HVNmJtbMTMxZWfz9GxU0uvUh6/nMvI/yXuFSFtDND1alE6ipwVddjb+6Gn9t7bhaIoSDpU6rE4/JRqZNwaoHI8FPrFtYjESx21FdLjwWO7U+heLW6kjwpSnqmK8bgJqUZIRE+flY8vKpP34ax+H9vFG8iufmfYQbK3dy5+l36bjjc6x58NsjzyIzgvBBnvtzXx52LC3d7zdO9qObk3e0D21iHrr4m5sv6En/+VKdzkirn3AAZJs1ywiShhHzEwpdp/m//ovWX/8GXVVRNI3U228n7VN3DAm9MEcFXtF/G6HF3PkcuE9GC4TmRx81ulWEWx/cdRdpn7x9aEuWQHBcLV663/4LPVu3Rk7EUj/1KTK/9CVMaanGScw494VYngifS3m6pkV+yR/YRSvUTautna5XX43MMJt01VX9LaZMpqEtqEwmFJMK6qClyYz7ww+N7kqhFkLJN91E+t2f6W+VlJo6qdstvK6B5mYjLBoUGEWvZ8pNN6I4HKGuNaGuNg4Hqj3quiN0DOMwLkrodtvjv6fl0Uf7A76//VvS77kbrbcXrbfPWPZFXw8to68Pus9XYcykiapS8O//hn3BAqylpePfXnE2Ntrg549ZWDUZnx0xCiNi3so2hp8duq7T/PDDtP7iMXSTCSUYJP1//S8yPntPfwitYwTUmtYfVg+5HgqmdZ2Ol16i88WXIp+5mfffT845dFOP9WfkVJpI5iFjCInz48pF19UhYRAQua3rKqTPNAam7q6D43VwfKPxIEWF7PlGQFS0EgovI/vaQnjhn6FrUFbZVU82f4CP/mHi9dSCcHZ7pLURJVeMuwvbZJZlKSzEnJMDEPnw79m+HceyZRMu68bF+WxYmHferZduXJzPY59bMSRcyjvHwXlvXJzP07ajpA0TSFx5+QLWfu7j4y6rMCpcurzxeOTEus6VzTPzN/DY51aQO476rSrSSd9SxbW7Ng7bJUgBtl5+K2tmZWJSFRxWEzBykLt2diYdv/oVtw8KWaLHcUq2m/n2v43eZSnY1cW+ncf46VPvktPXTk5fO7efeQ8VnSAKv17yiUjg81efWsucmXmkBTWSghozghq+oI4/oOEPGmHV/rPtOP74+yHhz+DxpSpuuosZGU6Cuo6uGy3FNN24GNdB03TqO90cq+/m7rIt3FK5c8h2a3Gk8cz8DawoTqMkMwmTqmAxKZhUBbOqGkuTgllVqO/08NL+2hHDqmZHOs/M38BX1s3ClpdMl6LQo2vY2luwNjdgaW7A0tyIuaneaOJcW0umuwtLKHgIdwlM9w4/0KLfYsNnteOz2nFbbLjNdvpMNnpMVroUC90mG26zjfltZ1nVdCISfL0862qeXHADfWYbDNd83A80hS50hS4jh3J+1cwz8zfQFshg9pKVpF1uIc1hJdWmkuHpIq2jCVdbE7ametSGWg7vOU5mVzNpPqOlRbgGqb4+UukDN4wWvShW64BLXU8Aj6LiV82UdtahAhoKbxVfhttshDxf3LAIc3IyqsuF6koyBv90uVCTXJhcxhhTisUSCX8/U7aFe1ur+4OvS67jjZLVPHR1Dpc5/fjr6/HX1Yea09cRqKsn2NGB1tuL99RpvKdOA+AI1fmGqj3cUNU/AGbai09S9uKTxsmg1YoaXh+bLWppQbXa+tfVZqO+L0BzxgxKn/wtc578b1R02pyp+J99gbb/efy8ut/ogDkzM3SyZjdO1hwOVLsdxRl1ohcaRyF6TAXV4aTrrbfo3rgR3WRGCQZIuf12Um+5BT00bg7+/vFzhlx8A7tZ6X4/ms9H5yuvoOg6uslE6caN2GeWTOyHhqA27EFw5HZwYi09Wh57jNZf/4aMr36VncUzWFNVTdujj2KZURTTMGJAHccjxuvZ/ItfDGjNHK6XOTfnnNezZ+vWIeVZCvLPu5XccONvTGZ5iqpiDv0qP1KZ4W4aut+PY/myc95m7n37hmwz29w5MQkMx7PdBqzrvHnDrqdmMqEGg1jnTLxekbpFjb0SCRNs1nM+eR0cSPhqakj9+PiP04BRg4YpP6mO5f4+GZ8dsfhMI7avQaw/O1oee4zWXzw25LvAlJJ8zvtB54svDd0PzKYp/YycTiQQEuen5ApWF/4NdA0/Xswq1wtGN7EHDkPAA3UHoXYv1O6Dmn3QVQNNx4zLgSdC/zV42Oaw0G/hm78D828Zfwhz7M+w+dtDWhtx449h4cS+5GJaFrH98Adj8OvosX3OVazCJTDWMe3Z/yHzgQe4ZcMdWN7bxfVf+i6ZW+bBww/TnOsa97qOFi7durSAtYtvGVc5JlXhp559pIVmAIsOShTg86HyTOpHx13etXMzecJzA38c1OLmj6Eyb52bOeb2M6WkcNl1l3N2Xy+7Oj18pmwLKnrkxDrJ72Z3/lXkpdq559qhg5gPNjcnmVef0YZtCRS+reoaf3fdvHG9b0YaY2rIAOZ//S9jlhfUdLJeenLMEO0f//XmQes5Y9iyrvrxX2hp6+GLR1/l9vL3IwHOlhkrea10LUnpKTz19Y9gSXYZLcdG+aVzx5lW7v7NTu4u28KqphND3mvdVifPzN/Al66cSU6KnT5vgF5fkD5fgF7vwGVDl4eP7H51zG32DBvYWd42Qo1SjYttPlxlvCfvPfY6d598O7Kem4tX83rpGvyqmTkFaThdTgKqmYDJTNBkdIHUVBM6CjpG8Nfp9nO0rj+wmt1ZF3mvNTgzI3WsduUzK9OFw2rCYTFh11TsbhOOgAl7nx+HtRurSeWfXzlihEHD7J86Cv+Udyvvf/umYd+3mtttDABaX4evrp5fv7AdR3sL2e4OljWfinwrDPjPYBDd7SY4znFrXKEL9AeGGX2d0NfZH6KpamQMAeMS1cw86r49bRqHn3ie64+/E9lmL8xYw4p//ocJh+Y7vvcfpG3cOHCbvfwyVda0IV0Ax2PzkXr2/+gn3K6HPjuCQf7rnx6dcN3CJxTDdZM+1xOKzAce4OSGO9j33i4yb7iTeerwA9lOpLzTN9zF9oO15NxwF7P1iR+4x/OJU0zLi/HJa7yeDMf8pG6S1jP6ZDgu1nOYMs/3mDQexXJ/j+fPjpiK4T4QvZ5pf/3X8NprZHzlb1FHGNR8IuXF3WfkNCKBkDg/qskIQ567l6FBTujQ/cZ/Nx5nTYKZVxqXsO4GqAkFRLV7oXoPBEY7uNehqxZ+uwFyF4ArD5LzwJUTup5rLENdZTj251DdhrY24rl74dN/GH+QE8uyGDRW0k1L4PALxlL/2tR/+BO7cCn6Azbd76f1uM7lpRlYvnq/0cBigl8k4XDp4zfexZpuDznJa8jcPPFwaU6Wk9N3fZGt9ssgqiXU1stv5dalBczJck5oNdf+8Lt0Hqln6zAtq9b96NusHeeJWHhGu5EGNFaAdT/69rjCudWlGXxzzSdo6By+K9of528gL9XOD0ozxlW31aUZvGtTB4RoYeEwLdWmsnoc5cUqRAuXFd5mt5e/P2SbNSRlsu7r38ZeOL7XYHVphjGb2Fgtvv517EGqd5xp5dVdfx4zlPvC2hLSnFY63X46+nzG0u2nsy+0dPsJasZnz91lW7g7albB8Ho2OY1WVRW9QC9AIHQZ3Uitl8J13Pjh8IH/WOUM3mY6MP9fvFhNKqpqtBwzKYpxXTFuKwr4g2k0ln4USo0ylzefioQuT8y/nhfnrMeiBbi6JIUZLjNOJYhDD2LTgzj0ADaC2LQgVj2ANRjAogV4eVcFfreHlY1lLG85TTDUjW1r0XI2lV6BNTODZ791E5bUlDHHZ9h8pJ5tP/sxny8bNF7VwU088c8B+NG3xx287Pjef5D27P8M2WYK8Pln/4cdMKFQaMTB0M+hbuHyYtEVmaBGx11f5Etdl1D/u72AiT+c2kt+6iX89K4vknUOYUSkvN/sjKrbOZZHbMYHnKzQJeMr97HjTGt/3b5y34TLi3Wrjbg9GY7xazBZ63neJ8OTHMhFlxUPx6QXvTgOI2L62RG1nv6oLtfxEEzHdcu2SSZjCF0gF+0YQmHDtpwpNMKgibScOfQcvPTXYz9uLPZUSMqFjkoI+kZ+XFI23P1HsLqMEMns6F+aLP1dQrQg/GzxwPUbQDFaCn3j8LhbLiXSWElh57sfxOsg4bEuL3xg9vKyW0ac8ny8X06TNSZULMuLxQlnLLcZGNPYbzzcyDPzNwxZz7vLtnDrOKexD7deauj0DNvuUcEIDd//9kdGfZ/ous7Wsia2fPffxpwFMOVv/pY5OS4URUGh/2NMUUBBidw+3dRDyy8eG7O8zk99ngyXFbdPw+MP4vEHcYcuHr9xX1uvj4/tfxVNUYcdl+rusi2ousZTC24Yc5sNV4dzHftqIuW5bCaS7RbsFhM2s4rdEmoRZTGu2y0mrGYF29O/5+6jr4+4zZ5fcjNXPvgt7FYTFpOK1axiDS1tZmNpMRldKH/xhW/T5dOGXZ+JDOIPsZ9tL7yvD37fnsu+HsuyJqu8mARfIbH8XonnusWqvOnw3R4L0es5+HhoysfWieNxf8TF6aI/N55iMqj0KCQQmkSxGFsnNGvZmK74OthSjOfqaYDuqGUwRrMhKWp/QIQCfS1j/gsf/T7MWgfOLEjKMlpFjWSkFkfhQ9oJtjgC4naspLCE2A9iIHxglvGV+4Yc0Lb98rEJH5jF+oQiHk9QYr3NIP4Gao/lLICxLi/czW4sP//MMpbOSIuMUxXUiLquE9R1DlV3cOKh/zdmUMW9XyI3xR4JpbyB/oDKEwqrvIEgjV1e1u3885jljTdk+uzxN2IafI0lzWHBZlEjYZ4R8hmvR2jGXRQUvIEg1+3685h1O3r9p8lJtmMxq9hMRjhlMStGeGXqD6t+934F3d6RW5ilOix896b5qFFjaenDxJ6arvPvr5+g0z3yANwZTgs//fQybKHQzRKulyn6uhpqXQYbfrqNhq7hWz6ON2QNi+dwKZ7rNhnlxSrEiXW9Yi2o6ew43cSb7+3i+qsvZ+2cnHMOq+Ix4BNiPOScYHJJIDQKCYTiXKQlTj3DjyM0RkscXQdPhxEMHX4O3vvJ2M9pTzOOqP2eMbqrnQOzwwiGnJmhZSgocqTD9oeNug5r4i2O4nmspDDZD6aOHDSem3g7QYnXFl+xagkVLiuWwdeOM628+s0HxwxKlv/LP3JJXgqeQBC3LxQqBUJhU6hF1MGqDl470jDmc85Id+C0mvEFtajZCYP4gzq+oBbp/icmz8wsJ+lOa6R1VjjsCrfQspqNAe5f2l9Lr2/k2fhyU2xs+8drsVnG/i6OZYAT3qfqR+jyGw/BVzyGVbGuV1i8fRfEuqzJKC+WxwlyDHPxkXOCySWB0CgkEJoGIi1nYNhTlPG2nBlva6MvvAqlV4eeToeA1wiGwgGR3wNVO2DTN8cuK73U+P++ltG7qo3XvBsgb6kxRlJSdmiZA65so4VU+JfZWLY2moyWSwBakED5Ng6+9wbLrr4B86x1593iSIjpJFa/CsfrSUAsw6pYlhXLsGq8LaGe+es1o47BFtR03j/VzBf+Z8+Ijwn719sXc2lRGuGjtfCg4DpGV0JjCUdqO/jen4+NWd5X1s1iRqYzNCOhEVD5IxcdX0DjVGM3H5xpHbOsRQUp5KXYB9w3ePK9hk4PR0KDl4+mMM2B02rqr0e4TlH1nErpTguZLhuZSVayXDYykqxkuqxkumxkJVlJc1h44I8HaOkZ/rs//D57/e+uxhvQ6PUG6PMF6fUG6B00IH2vN8DJph42fjhSN/V+tyzJozTLhd2iYjObIktb1G2LqvL1Px6gtXfkuuWm2Hjz76/BYlJRFFAVBTW0NFqi9b+w8RpWxbpe0fWLt7AqUQK+WJc1GeXFc7gUz3WTc+PJJYHQKCQQmiZiMSbR+bY2Op+ydB283UYw1NsaWrb0L2v3GSHT+TDZjIDImQXNx41Z3EbiSDda94TXU1GMOitq1HUFNB1e/TtwjzTb0Tm0XILYtziahO5scSlR1jOBxOq7IF5/LY3Xk4B4bQkVq7JiXV6sgq9YlqWHuhV+cLplXEHat2+8hNnZrlCYFMQf0PFGAiaj5daR2k7eONY4ZlmCSDikKgq6ruMfRyu3kgwnaU4LFpOKOar7n1lVIl0CTarCa0cacI/SSstpNXH78kLAOEzRQt1MNZ3Q0rje3OVhZ8VIxy/9/v66uVw+K5N0p5V0p4U0pxWrWR32sbEISoKaTpfHzw3/tY2m7pGHNchMsvLoZ1dgMamR7R0ebD98XQ0dqn32N7to7hm+rPC+/t63rsVsGn69BtcvHgO+WJc1WeXFa7gUz3WLZbdJMTwJhEYhgdA0EouT4Vi1Nop1WeNtvbT0HrA4oLcJeppDyybw9YzveSbLjDVQsAxSi0KXGcYyKQfUQQcfsW5xFO/hUqzKS5T1jLV4rVdIInwXxGs3gYu9JVQsy5Pga6BffW4FpdkuWnq8tPb4aO3x0trrMy6h+8629dE8ysl+NFWBJJuZJKsZp82Ey2bGaTWRZDUb99tMdPb5x9U98dal+WQm2ULjaGkDluHrzd3eUYMIAUlWE2lOK2lOC+mhZarDwp8O1tLjHTmsSrKZuHVpAe5Qa69uT3+Lrx5vgB5PALd/5P+fbNZBYVx4XC6zSYn8zeMPcrqpd8yybl9ewOxsV6QFmtWkRlqiRQbMV1W++vT+MVujbfnmNaHgqz/oUgY1L4x1UBXPwVe4vEQYf2wyxviK55ZQU2XaBUKPPvooDz30EA0NDSxdupSHH36Y1atXD/vYxx9/nC9+8YsD7rPZbHg8o7SOiCKBUAKK1QxosSzrfFsv+fr6Q6Jjr8COR8Z+zuwFRlezSL8D3XhuXeu/3tsCbWfGvx6DmazG9giHRCkFsOe3sRsrKd7DpViVlyjrGRavIVos6xYi3wVT62JvCRXL8iT4mpxw6fdfWsW6udlDTn7jom5fXMXKmRmRFjd6aBnU9Mh1TdfZe7aNrz9zcMzyvn3jJczNSSagGd3+/EGNQFDHr4WWQY0PqzvZeGjsrnE3LspjQX6K0XJGVQZ0aVNDgcLZ1j4e3145Zllzc5IIatDh9tPR5yOehvTKTrbhtJpC27x/0P3o1lDGmGZT24VyMkS/niZFQUfHM471zAltMzU06r4ammEzurujAvT5A1S29I1Z3mcvn8GigjRcdjPJdjPJNjMuuxmXzUyyzUKSzYSiKHEbLgWCmvHZ0TV6C7KLocVXuMx4bQk1laZVIPTss89y77338stf/pLLL7+cn/3sZzz//POcOHGCnJycIY9//PHH+bu/+ztOnDgRuU9RFHJzc8f1fBIIJah4nH1rKsdKOt+y1txndFnrrOm/dNcZ4dK5SCsBZwaY7WC2RS0d/bdNFtj3e/B1j1BIHIRLsSgvEhaOdIB8kaxndHnxGKLFsm5hsRxHK85bQiWCeG0JFcvyJPiamnAp3usWr90Tz6VemqbT7QnQ3uejvc9HR58/stxV3jquLoU3Lc7jspJ0XDajhVc4PEiyGkuX3cyR2g7u/d3YXR1j2Q3zsc+tYGlRWmRcrnAg5wtqBML3aRpHajr5yZaTY5Z3w8Jc0pOskYHyvYFgaBm6+IO09foSojWa1aSOa1yzdfOyKEh1YFKNQexNan9XyfBtVYVfbyun2zPyrI5JVhMfW5qP16/hDgWCHl8wdL1/IgS3P0jfKN0voy0qSGFmZhKpTgtpDgtpTgtpDqN1XLi1XLLNzO2/+CAm4dJkjPEVzy2hptq0CoQuv/xyVq1axSOPGC0cNE1jxowZPPDAA3znO98Z8vjHH3+cb3zjG3R0dJzT80kgJOLKdB8rKVowAN31USFRFZS/CxXvjm89YsWeFuq+lj1oMO7s/gG5HZnw3xuMEGtYY2wzTYOgNzQAuRd8vfC7G4xWW6PVa/13jMHGAz5jzKdIGZ7++7rroXrX2Os5+zrImGmEZRan0bUwcnGGQjQb/Ol+Y+yqEdczH77+oRG4jfGLddyGVbGuVyzrFl1ePM8CGI+heazLmozyEkA8jxsRb8FXrFtCxXPd4jWsiuV6TnVYdSHKinV5491mj4daowU1HU3TCep6aGwoItf3Vrbx9899OGZZD358EYsLUyLjS+kYranQjfGWdIxyj9V18uPNJ8Ys7+o5WditJno8Abq9fno8AXpC3QG9gYuvZVYsFKXbsZlN6JGWbENbFnr8QbpGCb3CwpMVOKwmHBYTTqsJu9WE02LGYVVxWM04LCbsZpV/+dMR2vv8w5Yz1V0Ap9q0CYR8Ph9Op5MXXniB2267LXL/F77wBTo6OvjTn/405H8ef/xxvvzlL1NYWIimaaxYsYJ//dd/ZdGiRcM+h9frxevtTzW7urqYMWMGLS0tFzwQ2rJlCxs2bJBASAykBVGqd0ROUPQZayd8gqKUvYrpRaMrpRL1UaaHPsaCd/wP+vxxtPyJdVln38f85G1jPi543Q/QM+eGghEPBLwo4dneQqGL0nAY9cyWcT1vrOhpJcZrEfCFwptQ3WIxg1wc0lULqGZjnVXz0EvQhzJiiNYvuOpv0AuWGzPh2VPRbalgTwV7CliSQgOYBzE/shy66xjua1oPhTiBr+7v3x+CPvD2GGNo+XpQvN3GsnYvpvceGrte8242AtdI8KVELcLXFdB11INPgK93hLoBzkyCd/we3ZEGtmSwJoPNZQzUPkj/PqUPKO/89s/zL2tAmW/+04DXVk8uIHj9v140ZU1GebH47J6UsuK5blqQYMX7HNnxFovXXoep9Kq4CeSCms7es+00dXvJSbaxsiT9nMKlN4428qPXygb8op6fauP/u2k+NywaX2v26VK3WJX3xtFGHvijceI/XIjz8GeWTri8WNQrqOms/8k2Gru8owQlNrZ+c924Xo9YrudkbLNYlBfLbRbr7R+L8nwBjV5fgPdPt/DN54+M+Zx3rSykINVBUNMJaHpoqUVd16lo6WVXRfuYZd24KJflM1KxW4ygxG5RI6GJcZ+K3WLieH03X/vj2EHafetKyUq20dnnp8Ptp9PtpyPqevh2HPWoPCc5yVYyk2wkhcZrS7KZcdnCY7YZ9zmsJn6y5TSd7tHCpfG/1+JBV1cXWVlZ8R8I1dXVUVhYyPbt21m7dm3k/m9961u8++677No19FfyHTt2cOrUKS699FI6Ozv5z//8T7Zt28bRo0cpKioa8vjvf//7PPjgg0Puf/rpp3E6nbFdISGmUH7HHpbUPIXD3z/DRp8lgyNFn6U+bdXUlKVrXH/0m9j9bSOeWLstGWxZ9NNhT6SjZXYf56rT/zbmUx6Y8SXc1gzs/i5sgU5sgS5s/tAydN0a6EKN0VecjoKmqJj0sZvotjln02PPQ1OsaKqZoGJBU8xoqtW4rppxeFuY2/z6mGVVZK7Ha0nDpPkGXnQvJs2PSfNi97WT5B+pddDU0FDxm5xoihlHoGPMx7vNaagEMQc9mPThv6jjiV+1EzA5CJgc+FUHAdVOZu9JVN0/4j7gNzk5lv8pdMWMrpjQFRUd1VhGrpvQgRVnf4M12D1iWR5LOlsW/qcR7o1DfsceVlU8DDAoYDLsKX1g3Pt8vJY1WeUN/ox0WzI4HKPP23MtK57rFuv1BEDXyOw5gd3fgceSRqvrkjG/Sy5EWZoOZ7oUuvyQYoHZKTrxcg4R67rFqrwPWxVeqlTp8PX/c5pV55MzNZZmTvz7Opb1+t3J8Ptg6KfHl+ZNrH6xXM9Yb7NYlRfLbTYZ2z8W5Wk6PLjfRIdvcDn95aVZ4XsrgmO+7051KjxybOxg/GsLg8xNvbB1O9mh8Ojxset2W0mQoiRQFePnqdBwTsZg4aHbNT0Kz5SPXdaGgiCZdvBpoUtQibrev2zzKjR5LuwH63hfg3jQ19fHPffcc3EGQoP5/X4WLFjA3XffzQ9/+MMhf5cWQiKhxOGvwjFrcRRpUVI/oJwB5Q1uUTJSnSrfw/zU7WM+ZfCjD6IXXgYmG3pkXCOb0RUrPLaRakap+mBcLaECn3sFveSq0R8Uy/UcZwutwKeeMNZTC4IegKDfuK4FQAughJd1BzBt+acxy9NmXAFmC3g6UTyd4O0yrmtjNxUeD91sD7XKcYHVha4HUZuOjfl/wcWfNroTRr72QoOpQ//A6oDSfAL19Jtj18OZZYyb5e2K2brFiq5aBnYhtDjQzYO7FdpQyl4Ff9/ILaHsaQSv/1djwHjVAibzwGWo9ZiuqJif/Qz0No/c4is5j8B9u42yFHXkLorn0npsNDEuL55bfMVr3RKpZRuQOC2+YlxeMBDg1N4tuNvrcKQXMHflBkxm87nXLUZi3bIqqOnsPNPMX3bs4yNrL2PN7Oxz74YZ420Wj63RLvaWbbFuCRWvdYv1eu6qaONzv9s75uP+5eZLmJmVRE9oBsAerzEjYK/PmAmw1xvgTHMvx+pHGqO030/vXMKtl06PbmPTpoXQuXQZG86dd96J2WzmmWeeGfOxMoaQEFMgVrOzxWog7liOuzQZ5V2M66nr4O8DTyd4uqBiG7z+j2M/500PwcyrjO5YVpcRBJkGfYbGej0nOlC7rhtdG73dRvjl7e6/nH4b9v527LIKloMrzwjh9HAYp0VdD0JvM3RWj13WdKGY+rsnRq6bjHUdcWbCKJlzjK6Iihq6mPqDpvB9qgncHVA79kEjK+41ZmO02I0B7YdbqlZ44hPGye/wK3UOY7bFYOyr8Hvw58uMccimqm66brxfA97QeGleY7//3Y2jjLE2wf0TYjvGVzyPFxbr8hKpbjEeLywYCFC26w3c7bU40guZf/kN5x68xGqCgTgfTy6W2yym2z+G5W0+Us8P/3yYGT0fkkMHTaRR7VrKv3x8yTmNyaWisUoti5S1R5uPhnrRjD8Wy7LidXD7eDFtxhACY1Dp1atX8/DDRlNuTdMoLi7ma1/72rCDSg8WDAZZtGgRN998Mz/96U/HfLwEQkJMkUk9AJrCcGkyy7uY1zNeQ7RY120qZgH8zDOQvxT8buNkfPAy4DGuV+2EIy+MXV72AmMWwKAfNL9xwh8MGNeDodvhMEwYrK5QC0JTf9gVDqiUUAgWcEN75dhlpRQaIagW7N/e0Zeg3wgOx00JtfgyR7X46m/thcliBDkdZ8cuypllBHCRcda8DL/PjIPFaZRnD4055kjrv25PNQbmt6ca43W9+ndjDJY/BaEcxPesjolWt4s9+Ir3mTXjtaxJqJu++dsoUWXpKQUo51DWgTd+T8GOB8mlNXJfI5nUrf0ey2/4wsTqFRJvwddklBWLIG0yZomcatMqEHr22Wf5whe+wK9+9StWr17Nz372M5577jnKysrIzc3l3nvvpbCwkH/7N2PskB/84AesWbOGOXPm0NHRwUMPPcQrr7zCvn37WLhw4ZjPJ4GQEFMnZvtBrH7BilXoMlnlXezrGa8hWizrFi+zAA5nKsKqu/8IMy7vb/UUaREVuuhBqN4DGx8Yu6yPfh9yFhjd9vRgaBm+6KHyNGgugw9+NnZ5s68DRyr4PUZYM9zS22mEaWJ8wi23tCkY/8tkB7N1UCgXHjA/VK+AD7rG0equcKUxU6VqGlhepHVbqEXaoefB3ztyObZUuOZbRpfj6ABuwHVLf4D44pdHCb4wvhc+97IR7EUPjG9c6b+tBeH3t0DPKK20kvPgb7YZ3X2jW9yF6xJeT4htkCah3MTLiveZNeO1rHiuW6gsfZhutcpEy4ouMw6Dr5iWReyCtMlopTWVplUgBPDII4/w0EMP0dDQwLJly/j5z3/O5ZdfDsD69euZOXMmjz/+OAB///d/z0svvURDQwPp6elcdtll/OhHP2L58uXjeq6LIRAKakH2N+2nua+ZbGc2K3JWYIqTWTqEGE1cBqOJMq11vK5nvIZosaxbLIOveG0JFa9lxbq88QZftz0G+cv6wy49GNUFMBSE1X8IW/5l7LJu/DEUrhgmQDD1j+NkskDNbnjm7rHL+/QfoGBFqLVXsL/lVzDc6sgPtfvHV7dbfmoEfGab0epowNJmBBXj3ma/gqy54GkPdS3tNLr7ha97Oo2uhG0V0F4xdnlicigqoIyvVZolqb+L75Axw0K3g37wjT12BwXLIblgUFdOuzEmWnhpssJffjR6l9OkHPjsC0ZYOFLrvfB9AI9dMXo3zOQ8+Ot3jNUZEHIP6vIb9MEzxjhrI7KnwbX/1N/dMuDtb3kX8BgBZsBjfCdVj929haJVxvegyRq6WIa/rqrwwc9Hb+XpzISPPxoKWc0MnJHU1H8fCvzh1tHDR1cufGmz8Z4IB/jhcfwitzVj2z35ydG3WVK20Sp28Gf3cGPUacExXgMFkvPhgX3G+2mkce7CZcVrKApxH3zFOuCLVZA2Ga20psq0C4QupOkeCL119i3+ffe/09jXP35BrjOX76z+DteVXBeLqgoxaeIyEBJTL15DNIjP4CseW0LFc1mxLC9Rgq94LQvGHzB98jcQHix/uJZoWhDq9sMbYw+Uz5V/Bxmzhy8jXHb9YTg+jrEvi1ZDSv7AAC66G2b4el8rdI90ghjFkmScpMOgAfPDC90IXQLSsk2ICTGFJg8xW6MmEwld/B5oPj52GbOuBVdO/+3hTrt7mqDinbHLWnoPZM8L1cU6cv0UMzx7zxjBVx787XtGMKgoxn3DLTUNHlk5ymfRFAZfk9S6MKattKaQBEKjmM6B0Ftn3+Kb73wTfdABVehtyk/X/1RCIRHXJBASCS1W42iFyoq7llDxXFYsy0uE4Cuey4rXsCqWXTBjXd54y7p3o/FZEu6CGQ6+dC3U4iXU6qVqJzw/jl/Lb/slFK0c5iQ46nbNXvjT/WOXdeXfQ3pxfxfOgNfovhkeEy3ggdbTUHdg7LJsKf3jckWvZ7g1z7mMg6WoAwfID3exC98X9IK7fexyCldC5uxBM5qGT/xD93VUwc5Hxy7riq9D+syoVoA+43rQN/B68wk4+8HY5aWVgD1lwCykkQkQwtf9fcZlLOGxy8ItzhTV+DiIvh0MTdYwFkeGMQbZWPx94G4b+3Fi4qwuo1XVkNZjUbf9bmg5OXZZuYuNCUQi++ag7uDh696e8XX5XfAJyL7EKDP6Ep6oxOYygvVfr49N8BUnJBAaxXQNhIJakBtevGFAy6BoCgq5zlw237FZuo+JuCWBkEh0cbsPxDJgiteyYlleIgRf8V5WvIVVidLiK57rFqsQLTwGWcU2ePL2cZS3EUrXXZi6wcUxntyFLmsi5d39rNG6MOAJdd/zDO3CV3cQ3vnXscta+VeQMWvgfYO7orWVw55xzEY67yZjgocBXQm9UXUMLd3tEnxNlvG+1+LARDKPc5+vT1xQ+5v2jxgGAejoNPQ1sL9pP6vyVl3AmgkhhJj2VFPsDnLitaxYlrfw4zD/ltiES7EsK57rFiorJq3kFn7cCGqGHTB1ggFTrMpSTcZ4T8/dixEmDRMu3fjv41/fWJaXKHUrucJ43cYKSkquGL0cRTHGv5p1zTjLu/LC1Q1i/3rGsm7xWtZEypu7YextN+c62P/42GXd/ND4QtETr41d1meeim3A9/lXjPeurhnPGxnHKWp5djs8c9fYZd32mDG7aaTVWHDosv5D+MsPxi7rmu9A7qJQq7HBF6X/euOR8XX5XXwHONJDs6H2GGNlebvB19N/32iTAUTrGflcfDqTQGiaaO4bZUC1c3icEEIIIc5DIgRfk1CWXnIVtUe7WFpy1fm19orH4CuWQVWsy0uEuiVK8AWx3f7xup6J8npOVcBXOo5Afu6G8ZV16V1jlzX7Wtj727HLuuZb41vXmVfBjkfGLu+Tvxm7vPJ34Q/j2GdcuWM/ZhqSLmMXyPl2E9jTsIcvvfGlMR/3uxt+Jy2ERNyK2+4yQlwgsg+IRJcQ+0C8dnVMlLolSjdMkPHkLqbX82LvVhvrsmJZXqy7YcYBGUNoFNM1EAqPIdTU1zRkUGmQMYTE9JAQJwJCjEL2AZHoZB8QF0ScB18xm2Ag1uIx4It1WfFcNwn4JlZWLMuLdVg1xWQMoYuQSTXxndXf4ZvvfBMFZdhQ6Nurvy1hkBBCCCGESGxx3g0zZl0nYy2Ou5vG8+sZl2XFY7faqLJiForGa5ffaUQCoWnkupLr+On6n/Lvu/99yADT3139XZlyXgghhBBCCCFE/IZVsQ5F43HCiGlEAqFp5rqS67h2xrXsb9pPc18zTx5/ksMthznSemSqqyaEEEIIIYQQQkxPsW6NNg2oU10BMXEm1cSqvFXcPOtmvrv6uwBsKt9EVVfVFNdMCCGEEEIIIYQQ04EEQtPckuwlXF14NUE9yK8O/WqqqyOEEEIIIYQQQohpQAKhi8B9S+8DpJWQEEIIIYQQQgghxkcCoYuAtBISQgghhBBCCCHEREggdJG4f9n9ALxa/ipnu85OcW2EEEIIIYQQQggRzyQQukgszlrMuqJ1aLrGrw/9eqqrI4QQQgghhBBCiDgmgdBFJDyWkLQSEkIIIYQQQgghxGgkELqISCshIYQQQgghhBBCjIcEQheZ6FZClZ2VU1sZIYQQQgghhBBCxCUJhC4yi7MWc03RNdJKSAghhBBCCCGEECOSQOgiFG4ltKlik7QSEkIIIYQQQgghxBASCF2EFmUtklZCQgghhBBCCCGEGJEEQhcpaSUkhBBCCCGEEEKIkUggdJGKbiX0q0O/murqCCGEEEIIIYQQIo5IIHQRu2+Z0UrotYrXqOismOLaCCGEEEIIIYQQIl5IIHQRW5S5iPVF62UsISGEzmi5xgAAPFxJREFUEEIIIYQQQgwggdBF7ivLvgJIKyEhhBBCCCGEEEL0k0DoIhfdSkjGEhJCCCGEEEIIIQRIIJQQwq2EXq94nfLO8imujRBCCCGEEEIIIaaaBEIJYFHmItbPkLGEhBBCCCGEEEIIYZBAKEHct9SYcUxaCZ277c8/xY4Xnxn2bztefIbtzz91gWskhBBCCCGEEEKcGwmEEsTCzIXSSug8KarK9ueGhkI7XnyG7c89haLK7iSEEEIIIYSYOvIjtpgIOYOdRs53545uJbTpiUfi9oMiXj/E1t5xN1d8+rORUEjXtEgYdMWnP8vaO+6eknoJIYQQ4tzE6zGHEEKcK/kRW0yEeaorIMYvvHMDA8KH6FBiNAszF3LtjGvZWr2Vvc37cO1uPueyom1/3vhgGS4QCQcnV9w5/vLOdz1jVTctGKS7tYWOxno6mxroaGygs7GBpLR0tj/3VKSOBZcsILtkFu7uLhzJKeOuWyzF8jWI9espppa8nkKIc5Eonx2xPOYQQsT3MWk81y2W1t5xN7qus/25p2irq2XlLbdxes8Odr70rPyIPYJ4fj0nmwRC00j4DRp94DJaCxVd1wn6/fh9XgJeL36vl89mfJwjh7aznSN8afXNbH/uKRorznDJ5VdSeegAx7b9hZW3fpLVn7hz3PWK9cHU6k/cid/jYftzT9HV3MSSj9zA8fe2cvDNTaz6+B1cdstt6Jo2rnR7rLpdfvunaaosHxD4hAOgruYmtGBwzOeoO3GcPz30QwAyi4opvGQhhfMXUjh/ESnZOSiKMqH1PxexfA3i+eA4Ub7IYymeX08hEl08fw7F82dHLLdb9LGVt7eXZTd8jGPv/YUdzz99UZ04xfN7Tep2cYnnY9J4rdv5vs/cPd20nK2guaqS5rOVtFRV0FJdBUDZ++9Q9v47ANiSXDScOcW2px8nq6iYzKJiMgqLsNjsk1a3ySor1uL5O2+ySSA0zay9427a62uNFirPPw26TnJWNmf27qLsg20EfEbwE/B68fu8oOtDyriFPABq2AfAmT07ObNnZ+Tveze+xN6NL2FPcuFITcOZkmpcUlNxpKThTE3FmZKGMyUFZ2oaSzfcDKEUOlzH8M6z9lP3sPS6m2itqcbd3Ym7u8u4dHX1Xw9dPN3duLu78Pb1RupyZOsWjmzdErm9588vsufPLwJgttqw2GxY7HYsNrtx3WbHYrdjjrpdOH8h2597iroTx8mbM4/Te3bSUlWJ2WZj18vPsevl50bc3iazmZScPNJy80jNySMtN5+GMycp++BdVJMZLRggZ9YcAl4vbbXVtNZU0VpTxaG3NwPgysg0AqIFiyi8ZCFZxSWoqgmYvAPawa/BRA9oY1kWxHY94/WLHOL3Sy7Wr2csxes2i7V4Xs9EOdCL1/WM5wPQtXfcTdDvN344Kj9N4fxF1J8q49Su7Sy/6VYuu/kT4y5rKloSa1oQT3c3vZ0d9HV20NfViTu0DN/u6+igr6uDvs5OAPZteoV9m14BwJmSSkvVWT547kkyCooiF4v9wpw4xbq8eP7Oi6cT6+lSt3h+r53LcYeu66Efrz34PB78Xg9+j4eCuQuYf+U1xufQmdMUL1lG5Yf7qDiwl9LlK7E5Xex/feO419PmdFG6fCXbn3uK+lMnKF12GRUH+8uzJ7k4sDlU3gg/6CoY9ztcKcxasYrtzz1Fw+mTzFtzFWcPH+D4e+9w2S23GT9g6/q4fhge7/tMCwZpr6+l6WxFfwBUVUlPa8uw5ZqtNgI+b+S2t7eH8n27Kd+3O+rJFVJzcskMBUSDg6LJOvZe+fFPnVdZMPXv24uFBELTUG7pHI6/904k7Oluaaa7pXnU/1FNZiw2G2abDd2sUOOpJ2jSWZC7mJaTpyNlOVPTcHd1oesant4ePL09tNfVjFknRVGx2OyhrlRPAzpmi5UdLzzNjheenvhKKgoOVzLu7q7IXWabjYC3/0Mt4PMS8HkHPGY0lR/up/LD/f3/HyrLkZxCaq4R9qTm5JGamxu5npyROaAl0o4Xn6Hsg3cjHwzRHxRLN9xM3Ynj1J44Ru3xozRWnKanrZUTO97jxI73ALA5kyiYN5/C+YvobmnhyDtG2DXaB2wwEMDT0z0wQBsmUHN3dWFzJg3ozqaoKrtefo7dLz8PqmJ8iSlK6DtOQYm6D8X4iguvr8VuH1BWen4hnU2NvPf04zhT041gMDWNpNQ0nGnp2F2uSNg14KWM4Yd/PAdf8XTQqOs67u4uulua6WppCr3vFgwIkosWLCYpNZ2Kg/tIycomOSsbq90x6XWLFk/bbDLLi/UBUCzFa8gazyd1sSxr7R13owWDbH/uKfo6Olhw9bWc2PEe+1/70wUN4AM+H211NbRUn6Wl+iytoWVXcxMAZ/bu4szeXZHHH3h9Iwde34jV4SApPRNXegau9AyS0jNwpWfiyui/npSefk77gK7rBPw+/G43Prcbn8eNz92Hz+MmPb+Q2SsvZ/tzT1F99DBZxSVUHTlEa/VZHCmpHNj8auSz7lz1dXVycuf7Q+5Pzso2wqHCIjILZ4Suz8CZmhbXrRni+TsvlnWLZb2CAT+XfvRG3F1dbH/uKdrr61i8fgNl27dx+O3NXPax21h2/S0E/H5MZvOYJ/6x/C6Ip/earuv43G7cXZ1G8NrdRXJGFiVLlrP9uafY8fzT6LpOekERNceP8vQ//wN+rxe/xx1aGgHQWM7s28WZff2fQxUH9lJxYO+E1jPa4P8/n/LK9++hfP+eyO1wuGy2WHGkpOJIScGZkoojOQVH6Id2R4px3ZGcwiVrrybg8w14DbY9/Th7/vQCM5euoLOxgSe+/Xe01lYR9PuHrUNqTi5ZxaVkl8wku3gmWcWllG1/lx3PP43JbCYYCLBo/XXkzppDa3UVrbVVtFZX4e7uojPUS2KkoCj843pPWxtr7riLA69vZM+fX2TVJz7F8htuxdvXi6IoKKqKoqjG+UX4etR+Eb2va0ENbC52v/wcO1985oJ8DgUDfjw9PcZ5VU+3cb27C09Pt3He29NN5oySAcfLF3sYBKDo+nl8W05DXV1dpKam0tnZSUrKhRvvxe/389prr3HzzTdjsVjOq6wtv3mUQ2+9jqKq6JrGJWuvZuE1H8FiNQIfY2m0kDFbbZitVkzmgdnf1//ydbZWb+WOlstI3t2CYlLRgxpr77yHtZ/8DO6ebtxdXZFfzsJL48M+fJ9x29PTPWad7a5kHMnJ2JNTjA/D6EtKCo7kVByu5ND1FGxJSex6+Tm2P/dU5EPsik9/ljW330XA5zN+OQj9euD3efF7vP33eT2R24Go24f/8oaR1KsqH/vGt0OhTy42Z9K4tvtIBycj3e/3emg4fZKasqPUlh2j7mQZfo97QJnh17Bg3gIKLlnA2cMHaa4sx5WRidlqNVpM9fYyHSiKiiMlJRIQGa3K0nCmplF/6gSn9+xg8UduoMPqINXTw9F33mLhuo8wb82VBAMBgn7/wGXAjxYIEPD70QJ+goH+vzecOUXz2QoURQkdZBSSlpuPrmlomga6sQzf1iMXHV0L9t+na/R1deHt7YmsR3JmNlkzirE6nFidTqwOJzaHM3Tb0X/d4cTm7L9utdvZ+fKzA94L53pAO9Z7bc0dn2Hh1dfSFQqDu1qa6W5tjtzubmkm4PdN+DW0J7lIDoVDKVnZJGeGllk5pGRlk5SeHtkvx7sfjHtd7/wsa+74DDtf+uOkbLOpKi/g9+Pt7WHXK89z4PU/M/+q9XTZksixqBzcvHHC9Yp1UKLrOu//8Q/sfuV5LrliHZesuYpTe3Zw/L2tLPnojay48WOR7xFz6DtltBOfwdtnqrf/ZNRttLJW3vpJFq37CJ6eHtw9XYMOPEOXbmPp7u3B09094NfbaI6UVFwZmSRnZJKcmWUELZlZJGdkGfdnZmJ1OCe03dbeeQ/zr1hnBD9V/cFPe0MduqYNWw9XRiY97W1GuKIoZOQX0tPehs/dN+7tZU9yoZhMuLs6ySopJeBMxuZz03jmFBmFM3BlZBrBjycc/vThc7tHrNO4hX5cCn8XRb6XQktHqMVzUmoaR97Zwq6Xn4sccyy4ej05M2fTVldDW20NbbXVo/4AZUtKIqOgiIDfT3NlOfOvvIY1n7yLD996nQOvb2TZ9bew+CPXG99LwWDke0mL+k4aeL/xt1O7PuDUru3MXrmG0mWXcWb/bir276Hk0hXMWLjY+P/g4EtgmPuM+1trqmmvrzV+CNJ1MgpnkF08E5PZjGq2hJYmTOHrJnPoPmMZfd+Zfbs5ufN95l91DfMuv5KyD7Zxcuf7obquCH2XB9DC3+nB4IDv9/6/GZfWmqoBdcsuKaVg3vxIi3Djs8gW+YFz4HFv/2M+3PIae/78ImvvvIc1n7yLD/74BLv/9AJLPnoj81avDZ349UR++PT0dOONXO+/L/pHyDHfaqqK1e4ItVx3RFqsW+x2rFHXm89WUFt2jJJLl9NndeLSfFTs38Pc1Vcwb82VqCYTismEyWRGVVVUsxlVDd83cHnordfZ/9qfWXnr7az82CfZt+mVyEn6qo/fEfrBj9BJOaEf/pRBPxAaFxTY9dJzbH/+Ka648x6WXn8LO1/8Iwc2b+SSK9YxY+ES4xyguzPyo2T4PMDd1UkwEDi/fTWKOdzi32bHGu4FYLdRdfQwhFrczF1z1Xk/z6md70da8My9/MqBfxzh9Fhn+PtP795B+JTalZllbJMRgptRhd77o7HYHWQXzyS7xAh9jPCnZMj5zHi/8/q6Oo3vgpoqWmuqaa05GwmKYmVwUKQFg2hR7xmbMwlnWjpmsxmT1Wp8/lgsmC2WyPWht62YLRZqjh2h8tB+Zl22mqIFizmzdxe1ZUfJLComKS0Nd+h72NPTM+Q8bCwms5lvPPVKzLbDhTSRzEMCoQskVoFQrA5oj7ce5/9v787jmyrz/YF/zsme7qU7W1kLiEWhFAu4IMiig4PixvAbkfHqy7nF0en1XgdnBvDqHXDmjttLB68zo87v5yiKCCKXRcABHXYoq+yIbKUbbWmbtmmSc35/nOY0aUuTwklzaD5vXnklOQnfPifJk5zzyXOevPzaExh+Ih6FA6pwYMBlZJ+Iw/AT8UibmIeZj/866Foetxv1NdXYvmwJ9q9fDdFggOTx4ObJU3HL9EdgjYqGaGg9cqQz1rNlPd9wqbMPfZI8HmVDoGkE0YVjh+GoqgzujwtCU6jWMlCL8QvWTu3egYNffwXRaITkdmPEj6Zh+OR7mz6kZOUzRpYhy1LT542s3OZzWbkuY//6NX7PZ7+cW5DefyAclyubhtkrw+4dl6vQoOGHxvXMbLMBMtDo84ETndgNcSmpEEVD04adqG7sCQYDRFFUdrBFA0SDCNFghGgwoPjUcRQdO4IeQ4YiJbMffthfiIoL52CyWIP6Jg0AohISEdtNCXhqKy6h6PgRCKIBsuRBWr+BsMfFKYHSpbKggkdBFBHTLQmyLKOmvAzdBw1Bj8E34tzhAyg6dgSpffsjqWemEt65lBDP7VIuS2433D7LPa7myy6n02/Hz2gywxodDYPZDKPJ3LQTYFLCCJNybjSZlJBCvWzBhaOHcebgXvTLGYWBo8bg5O4dOLFjC7LybkXW6FuVx1gUlQ0TUWzzsiga1GUHN67F3rWrMPzue3HD7RNQuGYlvtu0AQNyR6PHkBvRWOdAQ50DjXUOOB0OOOvr4HTUwllXB2edA846R/sbhIKA2KRkxCanIC45FbHJKYhNTkVc03lMt6RW751XE5Q0NtTjcmkJqstKcLm0+eS93pEde6XZok9ApDwHJp/QqOZSGSqLLqiBbVr/geieNbh5Z9Pgs7Op7mSa/HY4DQYjjm79Ft9t3oDs8ZORfdcU7F+/Bgc3rsUNt0/AoDG3KTuTnqadSo+naSfToy5XlzXthEpuNy4cO4zik8fVtiX17oOkHr3UHXFJ8jTvjPvunHs8fjvpsiTBUVmh2QazIIiQ5Y6HH2abvSkcSlLDo9Izp/H9np3InjAF/XJyUfi/K3Hm4F5ExSegwVF7xdekNSoaSb0y0a1nbyT17I2knr2Q1DMTe9d92ebnZ2N9HWorK+GovITaygrUVlYolyu8l5XzKwVeHWGyWGG22WC22WCyKudmqw1mmx3Htn6jftkzJb/AL/yxxcQGtf3RkR2nyqILSkhUpIREFRfO43JpyVU9f3QdEARY7VGwREfjckmxutgaHQOXs+Hqdvq7KKPF0tTv4mCPjUVtZYXy5V3Tl5/9RoxCVt5YGK1WmC02mKzeqR5szVNAmC1tzhGqxXZ8qOq1VeuW+x+Bq6HeJzirVkdPqSOp1OvKbW19FiekZyCpVyaSe/VBUm/lPC45JeA8qlp8qdJWUHT+8KGreox0RRBgjYqGNToatuhYWKOjYY2OaTopcyyd3rtb3f+5XkcIMRBqx/UcCGn5jenf//pfKP5qmxoGeQ07EYebryIU8rah9913wH7rENR9exhnVm/S5JvXQMs7Wk8vx4PKsozLJcW4cOww1i1+A7KsTJQ94V/y1ZFS3tOVDsfy1Rnffl+pluTxNM/L0HRy+Fz2Xi/74Xv1/yR276kk/E07g+qOoMkE0WiC0efbSvV+JhMMBiPOH/0OZw7sbd7IyBmFfjmj/HbmBUHw2eH3CQKahrR6r3/3zdc49PVX6ht/1uhbkZk9HI31dXDWK99SN/qcO+vqmq7XwVlfj8Y6R1CTj2vNaLEgtmnkTkxSshr8eEf0RCd2g7HpvSaY59NZV4eaS22POKouL0NtRXlY1rOrMNvssERFBTy815cSwCWrAVFscgriUlJx7vBBfLdpA/Ie+AlGP/gTbPn0Q2xftgRDbh2HjKzBrQKfYEILe1x80zwqyiZBYkYP5QcJGhuVk9PJHd4gCILYvHEZEwNbdIyy4RnTvNFpUzc8Y9TRs4Wrv8BWn2H9uT9+AFmjb0Nt5SXUXrqEmopy1FZcQs0l5by24pLffHsdYTRblHkienmDH+UUlZDYauTXtX6uyLIMZ51DCYcqKlBbeQnr3nlD/WGIsY882jTK0hvwKOcmm/eyHSar5Yqff1rs1GmxzeFubERVcREuXTiPiiIlJDq6ZbN6uy0mtvlzx2BoFUC3XK5+QeDz+XV6f6E6OiJr9G0QDQblJBogGg1+Xzp4R5Wo9/E5nd5XiFO7t6tfDvQdnoveNw6Dp+kbe+9o3OaQtfVIHjWIbbpedPwoAGUEWe8bb2oOeQ0Gv5FHviGwd5SR7+0/7N+Dk7ua29Y7ezi6Zw32+3EUda7MFnNm+p63FUKarDZ1J1A5j4HF73p00/UY9XZrVDQsdjsEUbzia03yeJrmvalXRqc31DePYG8xH45yXu83ah2CgL4358DjdkOWPPC4PUro7PHA41HO1RFekvIceQNrJfiWNAldryQ+Lb35EKemoMf/sKfmw598JyYO5zZpZ9bTspbb5cKWT/4fdn/5+TWHEaGY069VH3hwJm65/2HIsqyMcpQlQGq+LMty8wh972VZGa1fuGYlCld/AYgiIEm4cfxkDBl7B9yuRr8vDd2ull8wNvpcdzdfd7lwfOfWpvdIEXkPzGgV9CjhT4zap9tbR73tM16NjmQenEPoOiJLUpsvSO/1YIdWeyQPvj33LWoG1PqFQQCwv+l6zLlv8YjkgSFACAE0d57jQ1z4AH8DlOlyMHpIBtDGcZ2BeNcz976HsKt4F8rqypBsT0bufQ+ptwfLd5i8cUx/rP5+NZLH9Eee/JM2jzntTIIgID4tHUe2bIIsS+obrKOqAtnjJ3WoVltvWG0dkx+qWqLBoM4h0V7dsh++V9/8B4257ao/yM8c2NvqzTq1b/+r+iA/9PVXrWp169Er6FreX/PzBki7v1yOAxvWqB/mg8bcjgGjRisjDJo28HyH8CsbgG7IkqRuEEo+G4J7165Sw8J7/+3XagBkjYoOaqLCYJ9Pi90Oi13ZMWyLJHngqKpsDozKy/DtR39T25b74weah/H6Bnk+w3vVkE8d9qvcZ/+GNdizaoU6su3myVNxwx0T4G5shMfVFEh4zxudcDe64G50KhsLjU64Xc3XXY2NyrwfTRvaPQcP9Tsko+VhhMplzxWWKyffHe+0/gNhsUc1neywREUrhxHao2CNilLO7VEw2+2wRkU3HXZogyga1OfC2wdypt6PAbl5uFxWiurSElSXleJymRLkVJeVwuN2N10uAXCw9XPbYo62w9/+A4e//Uebz581KhqxKamIS0lVRiE1XfaOTNq9arnfht6gsbf79QFZliF53E07Yt6QqEE5hFcNjpSdsWPb/4lTu3eogW2PITciY0BWi8NHfA4b8bTY2fS93eNG5cUitR0J6RnKKDqjEQaDodXhLKLBoLzGDIam+3hvU5ZfPH4U548cUtuWmT0cfW4e4bcT7t1Rb7lzru6kC8rlI1s24btNG9S+njvtQYx9+KcBv7lt9Twu+xhbfX7Ryvs6MVos7b4PNTbUtwqJai6Vq+FR6elTAJTPmtEP/R81+IlLSQ2qjVp8rgjeb2KjotGtRy91RwRNj7/H7cJNE+8O6nEK1D61fwXRLl9abFsZzWYk9cpEUq9MtW0A1P5085Sp1zya4fS+PWq9xO49rvrz89Tu7a0es7T+A65pdETR8SNq27oPGnLVbTu5q3Xbug8ajNt+8liHasmShK1L/47tn3+ifq6MvPf+ax4BcqXXmvczoSP1ZFlWPwvS+g/UbnSKz066OjpckpVDnXxGgStnEiArh0F5X+e7v/wcu1YuU+sNue1OTULWztwmvV7btmvlZ9j95efX/J4GoN2wR8sQDYJSryNHgmxb9jEKV3+BW6bPQLklGknOWmxf9jFiunW7pn5wfMcW9XULAbh58tQO19Dy+byeMBC6jmjVuQtLC7Glz4Ur3q6EQpex7MQyjO0+FgnWBNiMtive/1TFSewdUIX9mf7h0rbMi3C4YpFacRJ5QbdOWc8NZzZg0rJJKKkrUZen2lPxq9xfYULvCUHXkiUJaRPzME9+DyXr/GvNnjjuquYn8EgeFJYWqkHV8JThQQVnbWlrZFW4NmhDUcuree6b5jf/rvJBLghC02EzZuzfsAYHNqxp9YF5LRvvvmFh2Znv0T9nVIdqaPV8iqIBMYnK/CUZAwe3apvBZLrqddyzakWrx8wWG3vV9Y5vk9V29Ryaremw8r7DR17TxlTLDSCzzdZmPVmS4KiqVMKiMt+wqNQvMPIyWaxK2OMb9DSdB5orLZgda0EQmoI+E9DOfo+yw7mjVa1eQ7Nxawd36nzb1jyvy7hr2mA8f+RQq7ZlDBp8VTs8323a0DrEMZs77T3NbLWpv3zVVt3S06fUx02WJfQfeUuH1lHrzwKtPgd8a2nxWdBpO05hrheKnR29tm378k+w/fNPNHkOQhVIhKIftNxJ76htyz7GrpXLdBGyhqKWntum5zAiVNveOfc+gNWrVyP3vocgGtqeHPpq2qeH1+31hoFQBCqrC+6QhZe2v6RethqsSLAmKCeLch5viUe8JR7/N3otqge0PiRBhowDA6pRYv8GM4IcbQQAG85sQMGmglYTt5XWlaJgUwFevePVoEOhutxUvLLpFch1rWu9YvwEr+a+GlQd37Yt2rnomoMqQNuRVd4N2rbCqqv9VkGLWoC2b/56/SAHQv8t1tV+wGm9s6Nl2/T6mGld72r6gCCKiE7shujEbuieNbh1zc8+wtalH6mjU0beOx15D1z7Ovq2Jdzflmr5fOp1PUMZwOvpvUPrnQC9brjreTSDnj/z9LxjHaq2XWs/0PNrTcv3Dq23YfTaNr2+p3n/dii2vV0+82/p4X0oFNvL1wsGQhEo2Z4c1P3iLfFwuBxwSS40eBpw0XERFx0XO/S3ZMgorivG9JXTkR6djhhTDGLMMYg2RyPGHINYcyyiTcrlGHMM7CY7/mvHf7U5i78MGQIEvLLzFYzrOS5gwOSRPFi0c5EmtQBtgypA+5FVWoZVWtbyPQRwZ9FO7G/cj5SSlKs6BDAUwVdbruaNX++HOmo1sk3Ltul5JyBU66nZBlAbhxhdzbfCeg1Z9bxTp2WtUI9O8a0Tzm+Zte4Det1w1/NohlB95umtbVo/B6Fq27X2Az2/1qjj9PqeBug3RAP4utUKJ5XuJFr+7Py18kgeTFo2CaV1pW2GJQIEpNpTsXb6WoiCCIfLgUpnJSobKlHlrEJFQwUqGypR6azEwbKD2F2yu9PXIdWeCrvJDhHKpIsGwQABAgyCMu+DCKXdJ6pOBKz1wMAHkJWQBbvJDpvRBrvR3uqyWTTj/pX3+wUkvnwfs2B2sr3PgVb1rhRWCVDmmOlIWKVlLd+aegyrAG0PAdSqbVuX/h2nq3/A+7H/aFVrdvU49InN7NBkgFo+Zlq3DdDmOfBOoJh730Otau1c/mmHJ1AM1XruLNqJ9dvW4668u5Cbkdvh9bzSBIfX88SHbQnFhJiR4Hp43PS0PUQULuwHFOnYB0KLvzLWDgZCCu9OPwC/Hf+O7vTvKt6Fn637WcD75Q/LR2pUKmpdtahprFFPLa9XNFSgzt2xn0DWk35x/RBniYNBNEAUlKCqrfOqhirsLNkZsN7dmXeje0x3GEWj+v8NosGvngABb+17C9WNV/4loW7Wbvhg8geIMkXBYrTAZrDBKBpbTUqsdVAF6Dus0jqo0uN6huIx0/NzoMfnU8u2aR18eWkZjOq1lt7bpiW9rqcWoShRV6C3/QKizsY+EFoMhNrBQKhZWzsoafY0PJ/7fNA7KB0ZbRTMRl+wAdOvRv4KWYlZkGQJHtkDSZbUk0f2QJZlHKs8hsX7FwesNTpjNKJMUahz1aHeXY86d12ry22t2/XOIBhgNVphNVhhNVphM9rgltz4ofqHgP/3zp53Ii0qDaKg/FKNIAgQ0fST7oIAAQJEQYQsy1hybAkcriv/PHKcOQ7P5z4Pq9EKk2iCSTTBbDCrl00G5dwgGvDYmsdQVt/2HFjhHFWlZZCm11qhqKfX4EvP6+mtp+UoOT2HcpGwnoA+RyrquZaXnoMvBpnhpefnANDnfgFRZ2IfCC0GQu1gIORPiw84rUYbedujVcCkVS1ZlrG1aCue2vBUwPbnD8tH3/i+fkGV37mknP9w+Qd8fOzjgPUm9JqAFHsKPLKnuY7k8bt+oeYCDl06FLCWxWCBS3JBkrv28bQpthTEWmJhNphhMVhgFs0wG3xOohI2rT69ut3RaFGmKDyS9QgkSOrz5pE9fo+/93JZXRl2lewK2LbspGwkWBOUvtE0OEto+gcowVplQyUKSwsD1hqeMhzxlnj1ta38pGzTz8c2LatsqMTB8tY/V97S0KShiLfEq+3x8o4g8y6raqjC/vL9Aevd2+9e9InrA4vB0nwyWmARmy+bRBN+8fUvcKnhUps1QhV8SZBQ21iLWlctHC4Hahpr4HA5lOuNDtS4anCi8gRWn14dcD0fHPggBiUOQpQpCtGmaNhNdkSbohFlilIvGwUjJn8+Wdfhkh5DuUhZT289PY5s02st35p6DKsiKcgE9BlW6fk5ALQdKafn4EuvtfTcNj2vp9b0um/cVTAQagcDodDQYrSRby2tAiatamk9EkrLesGOqnpv0nvISc2BW3Kj3lOPBncDGtwNqHfXw+lxosHdgAPlB/BG4RsBa/2o74+QHpWuRA+yDAkSIAOSLEGGrIZO31/+HluLtgas5z3UziW50OhphEtytbrc4G6AS3IFrEVdi1k0qwGSUTDCKDafTKIJRtGIBncDTl0+FbCWSTR1+mtIhKj0jwByUnOQbE+GUTCqh4X6HiJqEAwQBAFLjy9td8RdjDkGPx/2c4iCqI7UEyCoo/fUkXwQIEPGH3f/sd3DTeMt8Xhh1Av+deATFArKuSzLWLBtAaqcVVeslWhNxJvj3oTJYPJbP6NgVOeCM4pGQAYeWvVQu6MBU+wpWDltpTISsel9CID6/uO7zO1x48FVD16xHgCk2FPw+dTPYTQYmx+3Fo+XKIiQZEm3o8f0Orowkg5FjqQg01tTb2GVnp8Dbz29PWZ6bxvXM/zrCej78GE9h3LhwkCoHQyEQifUQ96vJWDSopaWQZWW9fQ4qsqrI2HVyLSRmtSamzsXfeP7otHTqJ6cHidckgtOjxONnkZ8V/4d1p9dH7DWmIwx6Bff74o76N7r52rO4eOjgUd8zb5hNjLjMv12XtURPk3LTl8+jQ+PfBiw1k8H/xSZcZmtdtB9r5++fBrvf/d+wFo/G/oz9Inr49cOX942fl/1Pf52+G8B643rOQ5xljg43U44PU44JSecbqf6XDg9TlQ5q9oND0LNZrSpo3miTdGINker1x0uBzac3RCwRl56HmxGGxxuBxyNDv/zdkIb6vrSotIQa45tdeir78koGrHh7AbUu+uvWMdutGNqv6mQZdlvtKnviFNJluCW3aior8CB8gMB2zY0aSgSLAl+gZcoiOohwKIgorK+Mqh57sZkjEGyPdlvZGFL5fXl+PbCtwFrje85HunR6Wq71FDOJ9z0BoAfHv4Qta7aK9aKNcfiF8N/AZNo8pu/z3vyXhcgYN7WeQGDzNfueA0G0aCO6FTfZ4XmUZ4SJORvyL/iqEcASLYlY8k9S2AxWvwCUe+8g76uNkhTXyNNI1jdkhuNnkY8vOphzQ65BvQZVvEwaX0EX3qtpee26Xk9vfUiIfgKxSjKcGEg1A4GQtcPPaa9WgZVWtbT46gqQL9hlZZBldZt02stresF+xwsGrsIg5MGwy252z7Jbhy+dBhv73s7YK1XbnsFYzLGIMoUpYxECeF6SrKEenc9/nn+n3jum+cCtu0ng36CHjE9lJ17yd3m4Yknq04GtWM9LGkY0qLTIMty8yg+n1Ez3lE0pXWlOFZ5LGC9PrF9kGBNUK+3HJEjQ0ZlQyXO1ZwLWCvBkgCzwayuk1t2q4fCumXlOSWKRAIEv4BIluWgfmTDarACANyyGx7J0+Z7VrCsBiuizdGwGW3K3IIG5bzlfIMWgwXLTixrN/iONceiYESB+h7Z1uHIgPIlxO93/b7dkYqx5lg8NUw5bN/vUPwWh9CfrzmPtT+sDbiet3W/DUn2JL/3SKB5m8e7vLy+HNsvbg9Y786edyIjOkP9pVuj4P9DIN7w8S8H/9JukBlvicfvxv5OnUfRdySs77kAAY/87yMBRz0u/dFSyJD9PlO8rxPfc5fHhYJNBah0Vl6xXoIlAf855j+b5470fhHV4tByWZbxwj9faLeWN2T1/mCKN2RtGf5KkPDEuifaDVlT7ClYce8KmI1miILy2Lf8wRQvvY58ZJCpj+ArFKMow4mBUDsYCNG10uvxvXocVeWtpbewSuugRMu26bmWlvX0HHwB+lxPrYPMcIzgC6bWjos78C9f/UvAWm/d+RZGpI7wGxXnHVWizs0lAHuK9+CJ9U8ErPfOhHcwPHW4f5AGSbnedLmwpBC/3PTLgLWeH/k8+sX3Uw95dUkuuDz+5wfLDwY1V9X4nuORlZil7GC2+JVJURDVnaqz1WeDGhH4+NDH1ZGKkiy1WkdJlnDm8pmg5rmbPmA6esT0aPc+52vOY9mJZQFreQ9F9m2T98civCGmt23biwPvpA9JHIJke3Lr+fyk5h+iqGiowPna8wFrJVgSYDfZm18bPuEqmuZua3A3oMZVE7AWEYWWGsa1GNXtkT3tBo9eceY4NZT1ziPpfW/0nRM0mMPB7UY7rEar3+Hgvoe+GwQD6t31+P7y9wFrjUwdiSRbEiAo69jykGbv5fL6cmw+vzlgvXv63IPuMd3VQ9Jbjsw0CMpj8O6Bd9t9b4sxx+Cp7KcgCELz+yLg/xna9B7+/qH32w1FY0wxeCL7Cb+w0Hd0p3eZ9/n5w64/4HLj5SvWi7fE49ejfu0fQrfcFmua8uJ3O353xVpXsx0ZbgyE2sFAiLoyPY6qAvQZVmkdlGjZNj3X0rKenoMvb009raeeR3zptZae28aRih2vBeg3yAy21l8n/hUjUkeoh3O1HLnhvb63dC9+veXXAestGrsIN6fe7L/z6zPSyCAYUFhSiMe/ejxgrd+N/R0GJgxEvbseDZ4Gv7kGfZcdvnQ4qB3OrIQspNhT/J53v9eADJTVleF41fGAtbKTstWd17YCUYNgQGldKb4681XAWvf1vw89Y3r67SS2NUfauZpz+PT4pwHr3dPnHqRFpamHb/oGj94RTGerzwb1gxEZURmwm+xwSS64JWX0jncUj1t2q8s7wm9uOtGg/HKrz+vF6XGivL48YJ3u0d0RZ4lrdWi5bwBQ3ViNi46LAWslWhJhM9n8guiWo1kbPA3tHlJL1NmC/TzWAwZC7WAgRBQeevxVDa2DEi3bpudaWtbTc/AF6G899TriS8+19No2PY9s03MtvYZVkRJkAvoN5fT8HGi5njsv7gwq4PvzXX/GqPRRVzyEKhRtC0etdya8g5tSboJbcqshnDdslSRJDVv3l+3Hgm0LAtZbkLcANybfqIyYEUV15Izv6UDZAfzb5n8LWOvlMS9jcLfBfnN6eQ939y4L9rD3GYNmoFdML7/QrOUIHFmWca7mHL449UXAehN6TUCSLclvBKbvZe9hmPvK9gWslZ2Uje7R3ZvnVfOZow5Qll2ovYDdJbsD1rop5Sblh2tk/7Z419UjeyDLMkrrSnGi6kTAepmxmehm66Zeb+vw1Uv1l4IapfXKra/g7r53B7yfHjAQagcDIaLw0WM/6Cq/JnA903PwpSWtQlG9jvjScy29tk3PI9v0XkuPYVUkBJmAvsMqvT4Hen7M9No2rmfHa2ldT69hod7bpgcMhNrBQIgofNgPKNJp1Qf0OuJLz7X02jY9j2wLRS2tRorqOazq6kGmt5YewypvPT0+B3p/zPTYNq4ng8zrsW16wECoHQyEiMKH/YAiHfsAtUXPI9u0pmUf0HPw1dWDTEC/YRWg3+dAz4+ZXtvG9WSQeT22LdwYCLWDgRBR+LAfUKRjH6BIxz7Qteg1rNIzPc6pGIp6eq2l57bpdT0jIfgKRdvCiYFQOxgIEYUP+wFFOvYBinTsA0TsB3T90evhw6FoW1cIpjuSeRg7qU1EREREREREdJ0xiAbNJlQ2iAbkpOag1FyKnNScaw5ctG7b9TJxtFbEcDeAiIiIiIiIiIg6FwMhIiIiIiIiIqIIw0CIiIiIiIiIiCjCMBAiIiIiIiIiIoowDISIiIiIiIiIiCKMLgKht99+G5mZmbBarRg1ahR27tzZ7v2XLl2KQYMGwWq14sYbb8Tq1as7qaVERERERERERNe/sAdCn3zyCQoKCjB//nwUFhZi2LBhmDRpEkpLS9u8/9atWzFjxgw8/vjj2Lt3L6ZNm4Zp06bh0KFDndxyIiIiIiIiIqLrU9gDoVdffRVPPPEEZs+ejSFDhuCdd96B3W7He++91+b933jjDUyePBn//u//jsGDB+Oll17C8OHD8dZbb3Vyy4mIiIiIiIiIrk/GcP7xxsZG7NmzB3PnzlWXiaKICRMmYNu2bW3+n23btqGgoMBv2aRJk7BixYo27+90OuF0OtXr1dXVAACXywWXy3WNaxA879/qzL9JpDfsBxTp2Aco0rEPELEfELEPhFZHHtewBkLl5eXweDxITU31W56amoqjR4+2+X+Ki4vbvH9xcXGb91+4cCFefPHFVsu/+uor2O32q2z51Vu/fn2n/00ivWE/oEjHPkCRjn2AiP2AiH0gNOrq6oK+b1gDoc4wd+5cvxFF1dXV6NmzJyZOnIjY2NhOa4fL5cL69etx1113wWQyddrfJdIT9gOKdOwDFOnYB4jYD4jYB0LLe1RUMMIaCCUlJcFgMKCkpMRveUlJCdLS0tr8P2lpaR26v8VigcViabXcZDKF5cUXrr9LpCfsBxTp2Aco0rEPELEfELEPhEZHHtOwTiptNpsxYsQIbNy4UV0mSRI2btyIvLy8Nv9PXl6e3/0BZajZle5PRERERERERET+wn7IWEFBAWbNmoWcnBzk5ubi9ddfh8PhwOzZswEAjz76KLp3746FCxcCAJ555hncfvvt+OMf/4h77rkHS5Yswe7du/Huu++GczWIiIiIiIiIiK4bYQ+EHn74YZSVlWHevHkoLi7GTTfdhLVr16oTR589exai2DyQafTo0fjoo4/wm9/8Bi+88AIGDBiAFStWYOjQoeFaBSIiIiIiIiKi60rYAyEAmDNnDubMmdPmbZs2bWq17MEHH8SDDz4Y4lYREREREREREXVNYZ1DiIiIiIiIiIiIOh8DISIiIiIiIiKiCMNAiIiIiIiIiIgowjAQIiIiIiIiIiKKMLqYVLozybIMAKiuru7Uv+tyuVBXV4fq6mqYTKZO/dtEesF+QJGOfYAiHfsAEfsBEftAaHmzDm/20Z6IC4RqamoAAD179gxzS4iIiIiIiIiItFdTU4O4uLh27yPIwcRGXYgkSSgqKkJMTAwEQei0v1tdXY2ePXvi3LlziI2N7bS/S6Qn7AcU6dgHKNKxDxCxHxCxD4SWLMuoqalBRkYGRLH9WYIiboSQKIro0aNH2P5+bGwsX/QU8dgPKNKxD1CkYx8gYj8gYh8InUAjg7w4qTQRERERERERUYRhIEREREREREREFGEYCHUSi8WC+fPnw2KxhLspRGHDfkCRjn2AIh37ABH7ARH7gH5E3KTSRERERERERESRjiOEiIiIiIiIiIgiDAMhIiIiIiIiIqIIw0CIiIiIiIiIiCjCMBAiIiIiIiIiIoowDIQ6ydtvv43MzExYrVaMGjUKO3fuDHeTiELim2++wdSpU5GRkQFBELBixQq/22VZxrx585Ceng6bzYYJEybgxIkT4WksUQgsXLgQI0eORExMDFJSUjBt2jQcO3bM7z4NDQ3Iz89Ht27dEB0djenTp6OkpCRMLSbS3uLFi5GdnY3Y2FjExsYiLy8Pa9asUW9nH6BIs2jRIgiCgGeffVZdxn5AXd2CBQsgCILfadCgQert7APhx0CoE3zyyScoKCjA/PnzUVhYiGHDhmHSpEkoLS0Nd9OINOdwODBs2DC8/fbbbd7++9//Hm+++Sbeeecd7NixA1FRUZg0aRIaGho6uaVEobF582bk5+dj+/btWL9+PVwuFyZOnAiHw6He55e//CW+/PJLLF26FJs3b0ZRURHuv//+MLaaSFs9evTAokWLsGfPHuzevRt33nknfvzjH+O7774DwD5AkWXXrl34n//5H2RnZ/stZz+gSHDDDTfg4sWL6umf//ynehv7gA7IFHK5ublyfn6+et3j8cgZGRnywoULw9gqotADIC9fvly9LkmSnJaWJv/hD39Ql1VVVckWi0X++OOPw9BCotArLS2VAcibN2+WZVl5zZtMJnnp0qXqfY4cOSIDkLdt2xauZhKFXEJCgvyXv/yFfYAiSk1NjTxgwAB5/fr18u233y4/88wzsizzs4Aiw/z58+Vhw4a1eRv7gD5whFCINTY2Ys+ePZgwYYK6TBRFTJgwAdu2bQtjy4g63+nTp1FcXOzXH+Li4jBq1Cj2B+qyLl++DABITEwEAOzZswcul8uvHwwaNAi9evViP6AuyePxYMmSJXA4HMjLy2MfoIiSn5+Pe+65x+/1DvCzgCLHiRMnkJGRgb59+2LmzJk4e/YsAPYBvTCGuwFdXXl5OTweD1JTU/2Wp6am4ujRo2FqFVF4FBcXA0Cb/cF7G1FXIkkSnn32WYwZMwZDhw4FoPQDs9mM+Ph4v/uyH1BXc/DgQeTl5aGhoQHR0dFYvnw5hgwZgn379rEPUERYsmQJCgsLsWvXrla38bOAIsGoUaPwwQcfICsrCxcvXsSLL76IW2+9FYcOHWIf0AkGQkRERCGSn5+PQ4cO+R0vTxQpsrKysG/fPly+fBmfffYZZs2ahc2bN4e7WUSd4ty5c3jmmWewfv16WK3WcDeHKCymTJmiXs7OzsaoUaPQu3dvfPrpp7DZbGFsGXnxkLEQS0pKgsFgaDVbeklJCdLS0sLUKqLw8L7m2R8oEsyZMwerVq3CP/7xD/To0UNdnpaWhsbGRlRVVfndn/2Auhqz2Yz+/ftjxIgRWLhwIYYNG4Y33niDfYAiwp49e1BaWorhw4fDaDTCaDRi8+bNePPNN2E0GpGamsp+QBEnPj4eAwcOxMmTJ/lZoBMMhELMbDZjxIgR2Lhxo7pMkiRs3LgReXl5YWwZUefr06cP0tLS/PpDdXU1duzYwf5AXYYsy5gzZw6WL1+Or7/+Gn369PG7fcSIETCZTH794NixYzh79iz7AXVpkiTB6XSyD1BEGD9+PA4ePIh9+/app5ycHMycOVO9zH5Akaa2thanTp1Ceno6Pwt0goeMdYKCggLMmjULOTk5yM3Nxeuvvw6Hw4HZs2eHu2lEmqutrcXJkyfV66dPn8a+ffuQmJiIXr164dlnn8XLL7+MAQMGoE+fPvjtb3+LjIwMTJs2LXyNJtJQfn4+PvroI3zxxReIiYlRj4OPi4uDzWZDXFwcHn/8cRQUFCAxMRGxsbF4+umnkZeXh1tuuSXMrSfSxty5czFlyhT06tULNTU1+Oijj7Bp0yasW7eOfYAiQkxMjDp3nFdUVBS6deumLmc/oK7uueeew9SpU9G7d28UFRVh/vz5MBgMmDFjBj8LdIKBUCd4+OGHUVZWhnnz5qG4uBg33XQT1q5d22piXaKuYPfu3Rg3bpx6vaCgAAAwa9YsfPDBB/iP//gPOBwOPPnkk6iqqsLYsWOxdu1aHl9PXcbixYsBAHfccYff8vfffx+PPfYYAOC1116DKIqYPn06nE4nJk2ahD/96U+d3FKi0CktLcWjjz6KixcvIi4uDtnZ2Vi3bh3uuusuAOwDRAD7AXV958+fx4wZM3Dp0iUkJydj7Nix2L59O5KTkwGwD+iBIMuyHO5GEBERERERERFR5+EcQkREREREREREEYaBEBERERERERFRhGEgREREREREREQUYRgIERERERERERFFGAZCREREREREREQRhoEQEREREREREVGEYSBERERERERERBRhGAgREREREREREUUYBkJEREREOiAIAlasWBHuZhAREVGEYCBEREREEe+xxx6DIAitTpMnTw5304iIiIhCwhjuBhARERHpweTJk/H+++/7LbNYLGFqDREREVFocYQQEREREZTwJy0tze+UkJAAQDmca/HixZgyZQpsNhv69u2Lzz77zO//Hzx4EHfeeSdsNhu6deuGJ598ErW1tX73ee+993DDDTfAYrEgPT0dc+bM8bu9vLwc9913H+x2OwYMGICVK1eqt1VWVmLmzJlITk6GzWbDgAEDWgVYRERERMFiIEREREQUhN/+9reYPn069u/fj5kzZ+KRRx7BkSNHAAAOhwOTJk1CQkICdu3ahaVLl2LDhg1+gc/ixYuRn5+PJ598EgcPHsTKlSvRv39/v7/x4osv4qGHHsKBAwdw9913Y+bMmaioqFD//uHDh7FmzRocOXIEixcvRlJSUuc9AERERNSlCLIsy+FuBBEREVE4PfbYY/jwww9htVr9lr/wwgt44YUXIAgCnnrqKSxevFi97ZZbbsHw4cPxpz/9CX/+85/x/PPP49y5c4iKigIArF69GlOnTkVRURFSU1PRvXt3zJ49Gy+//HKbbRAEAb/5zW/w0ksvAVBCpujoaKxZswaTJ0/Gvffei6SkJLz33nshehSIiIgoknAOISIiIiIA48aN8wt8ACAxMVG9nJeX53dbXl4e9u3bBwA4cuQIhg0bpoZBADBmzBhIkoRjx45BEAQUFRVh/Pjx7bYhOztbvRwVFYXY2FiUlpYCAH7+859j+vTpKCwsxMSJEzFt2jSMHj36qtaViIiIiIEQEREREZQApuUhXFqx2WxB3c9kMvldFwQBkiQBAKZMmYIzZ85g9erVWL9+PcaPH4/8/Hz893//t+btJSIioq6PcwgRERERBWH79u2trg8ePBgAMHjwYOzfvx8Oh0O9fcuWLRBFEVlZWYiJiUFmZiY2btx4TW1ITk7GrFmz8OGHH+L111/Hu+++e031iIiIKHJxhBARERERAKfTieLiYr9lRqNRnbh56dKlyMnJwdixY/H3v/8dO3fuxF//+lcAwMyZMzF//nzMmjULCxYsQFlZGZ5++mn89Kc/RWpqKgBgwYIFeOqpp5CSkoIpU6agpqYGW7ZswdNPPx1U++bNm4cRI0bghhtugNPpxKpVq9RAioiIiKijGAgRERERAVi7di3S09P9lmVlZeHo0aMAlF8AW7JkCf71X/8V6enp+PjjjzFkyBAAgN1ux7p16/DMM89g5MiRsNvtmD59Ol599VW11qxZs9DQ0IDXXnsNzz33HJKSkvDAAw8E3T6z2Yy5c+fihx9+gM1mw6233oolS5ZosOZEREQUifgrY0REREQBCIKA5cuXY9q0aeFuChEREZEmOIcQEREREREREVGEYSBERERERERERBRhOIcQERERUQA8wp6IiIi6Go4QIiIiIiIiIiKKMAyEiIiIiIiIiIgiDAMhIiIiIiIiIqIIw0CIiIiIiIiIiCjCMBAiIiIiIiIiIoowDISIiIiIiIiIiCIMAyEiIiIiIiIiogjDQIiIiIiIiIiIKML8fzIn72e9qAMDAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2mhG7y6ErI5E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}